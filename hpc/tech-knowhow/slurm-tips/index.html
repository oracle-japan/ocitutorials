<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.1 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="ja-JP" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Slurmによるリソース管理・ジョブ管理システム運用Tips | Oracle Cloud Infrastructure チュートリアル</title>
<meta name="description" content="オープンソースのSlurmは、HPC/GPUクラスタのリソース管理・ジョブ管理をコストパフォーマンス良く運用するためのジョブスケジューラとして、現在有力な選択肢です。本テクニカルTipsは、構築するHPC/GPUクラスタのリソース管理・ジョブ管理をSlurmで効果的に運用するための様々なテクニカルTipsをご紹介します。">


  <meta name="author" content="Oracle Japan Solution Engineers">
  
  <meta property="article:author" content="Oracle Japan Solution Engineers">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ja_JP">
<meta property="og:site_name" content="Oracle Cloud Infrastructure チュートリアル">
<meta property="og:title" content="Slurmによるリソース管理・ジョブ管理システム運用Tips">
<meta property="og:url" content="https://oracle-japan.github.io/ocitutorials/hpc/tech-knowhow/slurm-tips/">


  <meta property="og:description" content="オープンソースのSlurmは、HPC/GPUクラスタのリソース管理・ジョブ管理をコストパフォーマンス良く運用するためのジョブスケジューラとして、現在有力な選択肢です。本テクニカルTipsは、構築するHPC/GPUクラスタのリソース管理・ジョブ管理をSlurmで効果的に運用するための様々なテクニカルTipsをご紹介します。">



  <meta property="og:image" content="https://oracle-japan.github.io/ocitutorials/assets/images/rh01-cloud-home-pine-background.jpg">





  <meta property="article:published_time" content="2025-06-24T07:43:40+09:00">






<link rel="canonical" href="https://oracle-japan.github.io/ocitutorials/hpc/tech-knowhow/slurm-tips/">












<!-- end _includes/seo.html -->



  <link href="/ocitutorials/feed.xml" type="application/atom+xml" rel="alternate" title="Oracle Cloud Infrastructure チュートリアル Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/ocitutorials/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-32.png" sizes="32x32">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-128.png" sizes="128x128">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-192.png" sizes="192x192">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-120.png" sizes="120x120">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-152.png" sizes="152x152">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-180.png" sizes="180x180">
<link rel="shortcut icon" type="image/x-icon" href="/ocitutorials/assets/favicon/favicon.ico">
<link rel="manifest" href="/ocitutorials/assets/favicon/site.webmanifest">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/ocitutorials/"><img src="/ocitutorials/assets/images/social-og-oracle-badge.jpg" alt="OCI チュートリアル"></a>
        
        <a class="site-title" href="/ocitutorials/">
          OCI チュートリアル
          <span class="site-subtitle">Oracle Cloud Infrastructure を使ってみよう</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/ocitutorials/#%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E4%B8%80%E8%A6%A7"
                
                
              >チュートリアル一覧</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ocitutorials/about/"
                
                
              >このサイトについて</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">メニュー</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(34, 66, 55, 0.7), rgba(34, 66, 55, 0.7)), url('/ocitutorials/assets/images/rh01-cloud-home-pine-background.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Slurmによるリソース管理・ジョブ管理システム運用Tips

        
      </h1>
      
        <p class="page__lead">オープンソースのSlurmは、HPC/GPUクラスタのリソース管理・ジョブ管理をコストパフォーマンス良く運用するためのジョブスケジューラとして、現在有力な選択肢です。本テクニカルTipsは、構築するHPC/GPUクラスタのリソース管理・ジョブ管理をSlurmで効果的に運用するための様々なテクニカルTipsをご紹介します。
</p>
      
      


      
    </div>
  
  
</div>






  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/" itemprop="item"><span itemprop="name">ホーム</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">></span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/hpc" itemprop="item"><span itemprop="name">Hpc</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">></span>
      
    
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/tech-knowhow" itemprop="item"><span itemprop="name">Tech knowhow</span></a>
          <meta itemprop="position" content="3" />
        </li>
        <span class="sep">></span>
      
    
      
      
        <li class="current">Slurmによるリソース管理・ジョブ管理システム運用Tips</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">メニュー</label>
  <ul class="nav__items">
    <li>
      
      <a href=""><span class="nav__sub-title">HPC編</span></a>
      <ul>
        
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-cluster-network/">HPCクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withterraform/">HPCクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster/">HPCクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withautoscaling/">HPCクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance/">GPUインスタンスで機械学習にトライ</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance-cntnd/">GPUインスタンスで分散機械学習環境を構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster/">GPUクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withterraform/">GPUクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack/">GPUクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withautoscaling/">GPUクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withubuntu/">GPUクラスタを構築する(Ubuntu OS編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-fss/">ファイル・ストレージでファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-lustre-server-fswl/">File Storage with Lustreでファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server/">ブロック・ボリュームでファイル共有ストレージを構築する（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-e6/">ブロック・ボリュームでファイル共有ストレージを構築する（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-nvme/">短期保存データ用高速ファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-backup-server/">ベア・メタル・インスタンスNFSサーバ向けバックアップサーバを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-base/">ブロック・ボリュームNFSサーバと基礎インフラ編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-stack/">ブロック・ボリュームNFSサーバと自動構築編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl/">HPL実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e5/">HPL実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e6/">HPL実行方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream/">STREAM実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e5/">STREAM実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e6/">STREAM実行方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-imb/">Intel MPI Benchmarks実行方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests/">NCCL Tests実行方法（BM.GPU4.8/BM.GPU.A100-v2.8編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests-h100/">NCCL Tests実行方法（BM.GPU.H100.8編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/stop-unused-service/">不要サービス停止によるパフォーマンスチューニング方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/topology-aware-cn-tuning/">クラスタ・ネットワークのトポロジーを考慮したノード間通信最適化方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openfoam-tuning/">CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftips/">OpenMPIのMPI通信性能に影響するパラメータとその関連Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding-e5/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding-e6/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune/">OpenMPIのMPI集合通信チューニング方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune-e5/">OpenMPIのMPI集合通信チューニング方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune-e6/">OpenMPIのMPI集合通信チューニング方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/papi-profiling/">PAPIでHPCアプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/scorep-profiling/">Score-P・Scalasca・CubeGUIで並列アプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/rdma-interface-configure/">クラスタ・ネットワーク接続用ネットワークインターフェース作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/determine-cnrelated-issue/">クラスタ・ネットワークに接続する計算/GPUノード作成時の問題判別方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-get-cnrelated-statistics/">クラスタ・ネットワーク統計情報の取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/nvme-filesystem/">ベアメタルインスタンスのNVMe SSDローカルディスク領域ファイルシステム作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-configure-sharedstorage/">HPC/GPUクラスタ向けファイル共有ストレージの最適な構築手法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/bv-sharedstorage-recovery/">ブロック・ボリュームを使用するNFSサーバのインスタンス障害からの復旧方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/boot-volume-extension/">計算/GPUノードのブート・ボリューム動的拡張方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-choose-osbackuptool/">ファイル共有ストレージ向けバックアップ環境の最適な構築手法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-name-resolution/">計算/GPUノードの効果的な名前解決方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-os-customization/">計算/GPUノードデプロイ時の効果的なOSカスタマイズ方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-host-list/">計算/GPUノードのホスト名リスト作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-resize/">計算/GPUノードの追加・削除・入れ替え方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-with-pdsh/">pdshで効率的にクラスタ管理オペレーションを実行</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/instance-principal-auth/">オンデマンドクラスタ実現のためのインスタンス・プリンシパル認証設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/log-monitoring/">OCIロギングとGrafanaを使用したHPC/GPUクラスタのログ監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/metric-monitoring/">OCIモニタリングとGrafanaを使用したHPC/GPUクラスタのメトリック監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/gpu-with-ubuntu/">UbuntuをOSとする機械学習ワークロード向けGPUノード構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-openmpi/">Slurm環境での利用を前提とするUCX通信フレームワークベースのOpenMPI構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-blas/">線形代数演算ライブラリインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/slurm-tips/" class="active">Slurmによるリソース管理・ジョブ管理システム運用Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-oraclelinux-hpcenv/">Oracle Linuxプラットフォーム・イメージベースのHPCワークロード実行環境構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/kdump-on-baremetal/">ベアメタルインスタンスのカーネルダンプ取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/site-to-site-vpn/">サイト間VPNによるOCIとの拠点間接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/"></a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-create-cnenabled-osimage/"></a></li></p>
        
      </ul>
    </li>
  </ul>
</nav>
    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Slurmによるリソース管理・ジョブ管理システム運用Tips">
    <meta itemprop="description" content="オープンソースのSlurmは、HPC/GPUクラスタのリソース管理・ジョブ管理をコストパフォーマンス良く運用するためのジョブスケジューラとして、現在有力な選択肢です。本テクニカルTipsは、構築するHPC/GPUクラスタのリソース管理・ジョブ管理をSlurmで効果的に運用するための様々なテクニカルTipsをご紹介します。">
    <meta itemprop="datePublished" content="2025-06-24T07:43:40+09:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目次</h4></header>
              <ul class="toc__menu"><li><a href="#0-概要">0. 概要</a></li><li><a href="#1-prologepilogセットアップ方法">1. Prolog/Epilogセットアップ方法</a><ul><li><a href="#1-0-概要">1-0. 概要</a></li><li><a href="#1-1-セットアップ手順">1-1. セットアップ手順</a></li><li><a href="#1-2-稼働確認">1-2. 稼働確認</a></li></ul></li><li><a href="#2-メンテナンスを考慮した計算gpuノードのステータス変更方法">2. メンテナンスを考慮した計算/GPUノードのステータス変更方法</a><ul><li><a href="#2-0-概要">2-0. 概要</a></li><li><a href="#2-1-計算gpuノードのステータスをオフラインに変更">2-1. 計算/GPUノードのステータスをオフラインに変更</a></li><li><a href="#2-2-計算gpuノードのステータスをオンラインに変更">2-2. 計算/GPUノードのステータスをオンラインに変更</a></li></ul></li><li><a href="#3-ヘテロジニアス環境下のパーティションを使った計算gpuノード割り当て制御">3. ヘテロジニアス環境下のパーティションを使った計算/GPUノード割り当て制御</a><ul><li><a href="#3-0-概要">3-0. 概要</a></li><li><a href="#3-1-slurmconf修正">3-1. slurm.conf修正</a></li><li><a href="#32-slurmconf修正の反映">3.2. slurm.conf修正の反映</a></li></ul></li><li><a href="#4-複数ジョブによる計算gpuノード共有方法">4. 複数ジョブによる計算/GPUノード共有方法</a><ul><li><a href="#4-0-概要">4-0. 概要</a></li><li><a href="#4-1-slurmconf修正">4-1. slurm.conf修正</a></li><li><a href="#42-slurmconf修正の反映">4.2. slurm.conf修正の反映</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <hr />
<h1 id="0-概要">0. 概要</h1>

<p>本テクニカルTipsは、OCI上に構築するHPC/GPUクラスタのリソース管理・ジョブ管理を <strong><a href="https://slurm.schedmd.com/">Slurm</a></strong> で効果的に運用する際に有益な、以下のテクニカルTipsを解説します。</p>

<ol>
  <li><strong><a href="https://slurm.schedmd.com/prolog_epilog.html">Prolog/Epilog</a></strong> セットアップ方法</li>
  <li>メンテナンスを考慮した計算/GPUノードの <strong><a href="https://slurm.schedmd.com/scontrol.html#OPT_State_2">ステータス</a></strong> 変更方法</li>
  <li>ヘテロジニアス環境下のパーティションを使った計算/GPUノード割り当て制御</li>
  <li>複数ジョブによる計算/GPUノード共有方法</li>
</ol>

<p>これらのTipsは、全て <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></strong> に従って構築された <strong>Slurm</strong> 環境を前提に記載します。</p>

<hr />
<h1 id="1-prologepilogセットアップ方法">1. Prolog/Epilogセットアップ方法</h1>

<h2 id="1-0-概要">1-0. 概要</h2>

<p>本Tipsは、ジョブ実行の前後で <strong>Slurm</strong> が自動的にスクリプトを実行する機能であるProlog/Epilogをセットアップする方法を解説します。</p>

<p>ここでは、PrologとEpilogで以下の処理を適用することを想定し、そのセットアップ方法を解説します。</p>

<p>[Prolog]</p>

<p>以下のスクリプトを使用し、直前に走っていたジョブの残したLinuxカーネルのキャシュをジョブ実行前に開放します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nv">log_file</span><span class="o">=</span>/var/log/slurm/clean_memory.log

/bin/date <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>
/bin/echo <span class="s2">"Before"</span> <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>
/bin/free <span class="nt">-h</span> <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>

/bin/sync<span class="p">;</span> /bin/echo 3 <span class="o">&gt;</span> /proc/sys/vm/drop_caches

/bin/echo <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>
/bin/echo <span class="s2">"After"</span> <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>
/bin/free <span class="nt">-h</span> <span class="o">&gt;&gt;</span> <span class="nv">$log_file</span>
</code></pre></div></div>

<p>[Epilog]</p>

<p>以下のスクリプトを使用し、ジョブがNVMe SSDローカルディスク領域のファイルシステム（マウントポイント  <strong>/mnt/localdisk</strong> ）に残したファイルをジョブ終了直後に全て削除します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
/bin/rm <span class="nt">-rf</span> /mnt/localdisk/<span class="k">*</span>
</code></pre></div></div>

<h2 id="1-1-セットアップ手順">1-1. セットアップ手順</h2>

<p>Slurmマネージャ、Slurmクライアント、及び全ての計算/GPUノードの <strong>/opt/slurm/etc/slurm.conf</strong> に以下の記述を追加します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PrologFlags</span><span class="o">=</span>Alloc
<span class="nv">Prolog</span><span class="o">=</span>/opt/slurm/etc/scripts/prolog.d/<span class="k">*</span>
<span class="nv">Epilog</span><span class="o">=</span>/opt/slurm/etc/scripts/epilog.d/<span class="k">*</span>
</code></pre></div></div>

<p>次に、全ての計算/GPUノードのopcユーザで以下コマンドを実行し、Prolog/Epilogのスクリプトを格納するディレクトリを作成します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo mkdir</span> <span class="nt">-p</span> /opt/slurm/etc/scripts/prolog.d
<span class="nv">$ </span><span class="nb">sudo mkdir</span> <span class="nt">-p</span> /opt/slurm/etc/scripts/epilog.d
</code></pre></div></div>

<p>次に、全ての計算/GPUノードで、 <strong><a href="#1-0-概要">1-0. 概要</a></strong> に記載のProlog/Epilog用スクリプトをそれぞれ <strong>10_clean_memory.sh</strong> と <strong>10_clean_nvme.sh</strong> として先に作成したディレクトリに格納し、以下のようにスクリプトファイルのオーナーとパーミッションを設定します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /opt/slurm/etc/scripts/<span class="k">*</span>/
/opt/slurm/etc/scripts/epilog.d/:
total 4
<span class="nt">-rwxr-xr-x</span> 1 root root 50 Jul 12 17:12 10_clean_nvme.sh

/opt/slurm/etc/scripts/prolog.d/:
total 4
<span class="nt">-rwxr-xr-x</span> 1 root root 271 Jul 17 11:43 10_clean_memory.sh
<span class="err">$</span>
</code></pre></div></div>

<p>なお、このディレクトリに2桁数字の接頭辞を持つスクリプトを複数格納することで、その数字の順番にスクリプトが実行されます。</p>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、 <strong>slurm.conf</strong> ファイルの変更を反映、その結果を確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol reconfigure"</span>
<span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show config"</span> | <span class="nb">grep</span> <span class="nt">-i</span> <span class="nt">-e</span> ^epilog <span class="nt">-e</span> ^prolog | <span class="nb">grep</span> <span class="nt">-v</span> <span class="nt">-i</span> <span class="nb">time
</span>Epilog[0]               <span class="o">=</span> /opt/slurm/etc/scripts/epilog.d/<span class="k">*</span>
Prolog[0]               <span class="o">=</span> /opt/slurm/etc/scripts/prolog.d/<span class="k">*</span>
PrologFlags             <span class="o">=</span> Alloc
<span class="err">$</span>
</code></pre></div></div>

<p>なお、 <strong>slurm.conf</strong> にProlog/Epilogを定義した状態でそのスクリプトを格納するディレクトリに実行すべきスクリプトが存在しない場合、ジョブがディスパッチされた時点で当該ノードのステータスが <strong>drain</strong> となり、以降ジョブを受け付ない状態になります。<br />
そのため、実行すべきProlog/Epilogがない場合は、 <strong>slurm.conf</strong> 中の不要な定義を削除するか、以下のような実質的に何も実行しないスクリプトを配置することで、これを回避することが可能です。</p>

<p>[99_nill.sh]</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
:
</code></pre></div></div>

<h2 id="1-2-稼働確認">1-2. 稼働確認</h2>

<p>以下コマンドを全ての計算/GPUノードのopcユーザで実行し、テスト用のファイルを <strong>/mnt/localdisk</strong> ディレクトリに作成します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo touch</span> /mnt/localdisk/test.txt
</code></pre></div></div>

<p>次に、以下コマンドをSlurmクライアントのopcユーザで実行し、テストジョブを実行します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>srun <span class="nt">-n</span> 2 <span class="nt">-N</span> 2 <span class="nb">hostname
</span>inst-xxxxx-x9-ol89
inst-yyyyy-x9-ol89
<span class="err">$</span>
</code></pre></div></div>

<p>次に、以下コマンドを全ての計算/GPUノードのopcユーザで実行し、先に作成したテスト用のファイルが削除されていること、Linuxカーネルのキャッシュを開放した際のログが記録されていることで、想定通りにProlog/Epilogのスクリプトが実行されたことを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls</span> /mnt/localdisk/
<span class="nv">$ </span><span class="nb">tail</span> /var/log/slurm/clean_memory.log
Wed Jul 17 16:53:14 JST 2024
Before
              total        used        free      shared  buff/cache   available
Mem:          503Gi       6.3Gi       494Gi        29Mi       2.0Gi       493Gi
Swap:         7.6Gi          0B       7.6Gi

After
              total        used        free      shared  buff/cache   available
Mem:          503Gi       6.3Gi       496Gi        29Mi       353Mi       494Gi
Swap:         7.6Gi          0B       7.6Gi
<span class="err">$</span>
</code></pre></div></div>

<hr />
<h1 id="2-メンテナンスを考慮した計算gpuノードのステータス変更方法">2. メンテナンスを考慮した計算/GPUノードのステータス変更方法</h1>

<h2 id="2-0-概要">2-0. 概要</h2>

<p>HPC/GPUクラスタは、運用中に計算/GPUノードでハードウェア障害が発生したりソフトウェアのアップデートを行う必要が生じると、当該ノードへのジョブ割り当てを一時的に停止するオフライン化を実施する必要が生じます。</p>

<p><strong>Slurm</strong> は、 <strong>Slurmd</strong> が動作する計算/GPUノードのステータスに <strong>DRAIN</strong> フラグが存在し、これを管理者が明示的に切り替えることで、この運用要件を実現することが可能です。<br />
この <strong>DRAIN</strong> フラグが付与されると、既に実行中のジョブに影響を与えることなく以降のジョブを受け付けない状態になります。<br />
具体的には、以下のステップでこれを実施します。</p>

<ul>
  <li>ステータスに <strong>DRAIN</strong> フラグを付与</li>
  <li>実行中のジョブが存在する場合はこれが終了するまで待機</li>
  <li>メンテナンス作業を実施</li>
  <li>ステータスの <strong>DRAIN</strong> フラグを除去</li>
  <li>新たなジョブが割当てられることを確認</li>
</ul>

<p>本Tipsは、前述の運用要件を念頭に、計算/GPUノードのステータスを変更する方法を解説します。</p>

<h2 id="2-1-計算gpuノードのステータスをオフラインに変更">2-1. 計算/GPUノードのステータスをオフラインに変更</h2>

<p>本章は、ステータスが <strong>IDLE</strong> または <strong>ALLOCATED</strong> の計算/GPUノードに <strong>DRAIN</strong> フラグを付与し、新たなジョブが以降割り当てられないオフラインの状態に変更する方法を解説します。</p>

<p>Slurmマネージャのopcユーザで以下のコマンドを実行し、対象の計算/GPUノードのステータスが <strong>IDLE</strong> または <strong>ALLOCATED</strong> であることを確認します。<br />
ここで、計算/GPUノードのホスト名（inst-xxxxx-x9）は、自身の環境に合わせて修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show node inst-xxxxx-x9"</span> | <span class="nb">grep</span> <span class="nt">-e</span> NodeName <span class="nt">-e</span> State
<span class="nv">NodeName</span><span class="o">=</span>inst-xxxxx-x9 <span class="nv">Arch</span><span class="o">=</span>x86_64 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 
   <span class="nv">State</span><span class="o">=</span>ALLOCATED <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">Weight</span><span class="o">=</span>1 <span class="nv">Owner</span><span class="o">=</span>N/A <span class="nv">MCS_label</span><span class="o">=</span>N/A
<span class="err">$</span>
</code></pre></div></div>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、対象の計算/GPUノードに <strong>DRAIN</strong> フラグを付与、ステータスが <strong>IDLE+DRAIN</strong> または <strong>ALLOCATED+DRAIN</strong> に変更されたことを確認します。<br />
ここで、計算/GPUノードのホスト名（inst-xxxxx-x9）は、自身の環境に合わせて修正します。<br />
また、 <strong>reason=</strong> の指定は、ステータスを変更する理由を適宜指定します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol update nodename=inst-xxxxx-x9 state=drain reason=maintenance"</span>
<span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show node inst-xxxxx-x9"</span> | <span class="nb">grep</span> <span class="nt">-e</span> NodeName <span class="nt">-e</span> State
<span class="nv">NodeName</span><span class="o">=</span>inst-xxxxx-x9 <span class="nv">Arch</span><span class="o">=</span>x86_64 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 
   <span class="nv">State</span><span class="o">=</span>ALLOCATED+DRAIN <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">Weight</span><span class="o">=</span>1 <span class="nv">Owner</span><span class="o">=</span>N/A <span class="nv">MCS_label</span><span class="o">=</span>N/A
<span class="err">$</span>
</code></pre></div></div>

<p>ステータスが <strong>ALLOCATED+DRAIN</strong> の場合は、実行中のジョブが終了し <strong>IDLE+DRAIN</strong> になるまで待機します。</p>

<p>次に、対象の計算/GPUノードのopcユーザで以下のコマンドを実行し、対象の計算/GPUノードで <strong>slurmd</strong> を停止します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl stop slurmd
</code></pre></div></div>

<h2 id="2-2-計算gpuノードのステータスをオンラインに変更">2-2. 計算/GPUノードのステータスをオンラインに変更</h2>

<p>本章は、メンテナンス作業が終了したことを想定し、計算/GPUノードのステータスから <strong>DRAIN</strong> フラグを除去し、新たなジョブが割り当てられるオンラインの状態にする方法を解説します。</p>

<p>対象の計算/GPUノードのopcユーザで以下のコマンドを実行し、 <strong>slurmd</strong> を起動します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl start slurmd
</code></pre></div></div>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、対象の計算/GPUノードのステータスが <strong>DOWN+DRAIN</strong> であることを確認します。<br />
ここで、計算/GPUノードのホスト名（inst-xxxxx-x9）は、自身の環境に合わせて修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show node inst-xxxxx-x9"</span> | <span class="nb">grep</span> <span class="nt">-e</span> NodeName <span class="nt">-e</span> State
<span class="nv">NodeName</span><span class="o">=</span>inst-xxxxx-x9 <span class="nv">Arch</span><span class="o">=</span>x86_64 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 
   <span class="nv">State</span><span class="o">=</span>DOWN+DRAIN <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">Weight</span><span class="o">=</span>1 <span class="nv">Owner</span><span class="o">=</span>N/A <span class="nv">MCS_label</span><span class="o">=</span>N/A
<span class="err">$</span>
</code></pre></div></div>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、対象の計算/GPUノードのステータスから <strong>DRAIN</strong> フラグを除去、ステータスが <strong>IDLE</strong> となっていることを確認します。<br />
ここで、計算/GPUノードのホスト名（inst-xxxxx-x9）は、自身の環境に合わせて修正します。<br />
なお、この計算/GPUノードで実行可能なジョブが待機していた場合、ジョブが即座に実行を開始してステータスが <strong>ALLOCATED</strong> になります。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol update nodename=inst-xxxxx-x9 state=idle"</span>
<span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show node inst-xxxxx-x9"</span> | <span class="nb">grep</span> <span class="nt">-e</span> NodeName <span class="nt">-e</span> State
<span class="nv">NodeName</span><span class="o">=</span>inst-xxxxx-x9 <span class="nv">Arch</span><span class="o">=</span>x86_64 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 
   <span class="nv">State</span><span class="o">=</span>IDLE <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">Weight</span><span class="o">=</span>1 <span class="nv">Owner</span><span class="o">=</span>N/A <span class="nv">MCS_label</span><span class="o">=</span>N/A
<span class="err">$</span>
</code></pre></div></div>

<hr />
<h1 id="3-ヘテロジニアス環境下のパーティションを使った計算gpuノード割り当て制御">3. ヘテロジニアス環境下のパーティションを使った計算/GPUノード割り当て制御</h1>

<h2 id="3-0-概要">3-0. 概要</h2>

<p>HPC/GPUクラスタは、構成する計算/GPUノードが異なるリソースを有するヘテロジニアスな環境となることがあります。<br />
この際、ジョブが想定するリソースを持つ計算/GPUノードで実行されることを保証する必要がありますが、 <strong>Slurm</strong> のパーティションに割り当てられる計算/GPUノードを適切に指定することで、この運用要件を実現することが可能です。</p>

<p>前述の運用要件を念頭に本Tipsは、ジョブ投入パーティションを使い分けることで、想定するリソースを持つ計算/GPUノードに適切にジョブが割当てられる <strong>Slurm</strong> 環境を構築する方法を解説します。</p>

<p>構築する <strong>Slurm</strong> 環境は、計算ノードに6ノードの <strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm#bm-hpc-optimized">BM.Optimized3.36</a></strong> を使用し、これを <strong>NUMA nodes per socket</strong> （以降 <strong>NPS</strong> と呼称）と <strong>Simultanious Multi Threading</strong> （以降 <strong>SMT</strong> と呼称）の組合せが以下となるパーティション構成とします。（※1）</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">パーティション名</th>
      <th style="text-align: center">割当てられるノード名</th>
      <th style="text-align: center">NPS</th>
      <th style="text-align: center">SMT</th>
      <th style="text-align: center">デフォルトパーティション<br />（※2）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">all</td>
      <td style="text-align: center">inst-aaaaa-x9 inst-bbbbb-x9<br />inst-ccccc-x9 inst-ddddd-x9<br />inst-eeeee-x9 inst-fffff-x9</td>
      <td style="text-align: center">-</td>
      <td style="text-align: center">-</td>
      <td style="text-align: center">Yes</td>
    </tr>
    <tr>
      <td style="text-align: center">nps1</td>
      <td style="text-align: center">inst-aaaaa-x9 inst-bbbbb-x9</td>
      <td style="text-align: center"><strong>NPS1</strong></td>
      <td style="text-align: center">無効</td>
      <td style="text-align: center">No</td>
    </tr>
    <tr>
      <td style="text-align: center">nps2</td>
      <td style="text-align: center">inst-ccccc-x9 inst-ddddd-x9</td>
      <td style="text-align: center"><strong>NPS2</strong></td>
      <td style="text-align: center">無効</td>
      <td style="text-align: center">No</td>
    </tr>
    <tr>
      <td style="text-align: center">smte</td>
      <td style="text-align: center">inst-eeeee-x9 inst-fffff-x9smt</td>
      <td style="text-align: center"><strong>NPS1</strong></td>
      <td style="text-align: center">有効</td>
      <td style="text-align: center">No</td>
    </tr>
  </tbody>
</table>

<p>※1）<strong>NPS</strong> と <strong>SMT</strong> を指定したインスタンスの作成方法は、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></strong> を参照してください。<br />
※2）パーティション名を指定せずに投入したジョブが割当てられるパーティションです。</p>

<p>これにより、以下の割り当て制御が可能になります。</p>

<ul>
  <li><strong>NPS</strong> にこだわらないジョブはパーティションを指定せずに投入（デフォルトの <strong>all</strong> に投入される）</li>
  <li><strong>NPS1</strong> で <strong>SMT</strong> が無効の計算ノードで実行するジョブはパーティション <strong>nps1</strong> に投入</li>
  <li><strong>NPS2</strong> の計算ノードで実行するジョブはパーティション <strong>nps2</strong> に投入</li>
  <li><strong>SMT</strong> が有効の計算ノードで実行するジョブはパーティション <strong>smt</strong> に投入</li>
</ul>

<h2 id="3-1-slurmconf修正">3-1. slurm.conf修正</h2>

<p>本章は、本Tipsの想定する運用要件を実現するよう <strong>slurm.conf</strong> を修正します。</p>

<p>作成する <strong>slurm.conf</strong> は、 <strong>NodeName</strong> 行と <strong>PartitionName</strong> 行を以下に修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">NodeName</span><span class="o">=</span>inst-aaaaa-x9,inst-bbbbb-x9 <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>2 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
<span class="nv">NodeName</span><span class="o">=</span>inst-ccccc-x9,inst-ddddd-x9 <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>4 <span class="nv">CoresPerSocket</span><span class="o">=</span>9 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
<span class="nv">NodeName</span><span class="o">=</span>inst-eeeee-x9,inst-fffff-x9 <span class="nv">CPUs</span><span class="o">=</span>72 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>2 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 <span class="nv">ThreadsPerCore</span><span class="o">=</span>2 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
<span class="nv">PartitionName</span><span class="o">=</span>all <span class="nv">Nodes</span><span class="o">=</span>ALL <span class="nv">Default</span><span class="o">=</span>YES <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP
<span class="nv">PartitionName</span><span class="o">=</span>nps1 <span class="nv">Nodes</span><span class="o">=</span>inst-aaaaa-x9,inst-bbbbb-x9 <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP
<span class="nv">PartitionName</span><span class="o">=</span>nps2 <span class="nv">Nodes</span><span class="o">=</span>inst-ccccc-x9,inst-ddddd-x9 <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP
<span class="nv">PartitionName</span><span class="o">=</span>smte <span class="nv">Nodes</span><span class="o">=</span>inst-eeeee-x9,inst-fffff-x9 <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP
</code></pre></div></div>

<p>この設定は、 <strong>BM.Optimized3.36</strong> がノード当たり2ソケットでソケット当たり18コアでコア当たり2ハードウェアスレッドを搭載することを念頭に、 <strong>NPS1</strong> と <strong>NPS2</strong> と <strong>SMT</strong> 有効・無効の計算ノードを異なるリソース定義の <strong>NodeName</strong> フィールドで定義しています。（※3）</p>

<p>※3）<strong>slurm.conf</strong> 中の <strong>Socket</strong> は、NUMA（Non-Umiform Memory Access）ノードに相当するため、 <strong>NPS2</strong> の場合は <strong>Socket</strong> がノード当たり4個として定義します。</p>

<h2 id="32-slurmconf修正の反映">3.2. slurm.conf修正の反映</h2>

<p>本章は、先に修正した <strong>slurm.conf</strong> を反映します。</p>

<p>Slurmマネージャ、Slurmクライアント、及び計算/GPUノードで、先に修正した <strong>slurm.conf</strong> を <strong>/opt/slurm/etc</strong> ディレクトリにコピーします。</p>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、修正した <strong>slurm.conf</strong> の内容を反映します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol reconfigure"</span>
</code></pre></div></div>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、パーティションが想定通り作成されていることを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>sinfo
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
all<span class="k">*</span>         up   infinite      6   idle inst-aaaaa-x9,inst-bbbbb-x9,inst-ccccc-x9,inst-ddddd-x9,inst-eeeee-x9,inst-fffff-x9
nps1         up   infinite      2   idle inst-aaaaa-x9,inst-bbbbb-x9
nps2         up   infinite      2   idle inst-ccccc-x9,inst-ddddd-x9
smte         up   infinite      2   idle inst-eeeee-x9,inst-fffff-x9
<span class="err">$</span>
</code></pre></div></div>

<hr />
<h1 id="4-複数ジョブによる計算gpuノード共有方法">4. 複数ジョブによる計算/GPUノード共有方法</h1>

<h2 id="4-0-概要">4-0. 概要</h2>

<p>計算/GPUノードのノード間を高帯域・低レイテンシで接続する <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> は、対応するシェイプが <strong>ベア・メタル・インスタンス</strong> となるため、 <strong>クラスタ・ネットワーク</strong> の利用を前提とする <strong>ベア・メタル・インスタンス</strong> ベースのHPC/GPUクラスタで使用するリソース（コア・メモリ）が少ないジョブを実行する場合、リソース有効活用の観点から複数のジョブを1ノードに混在させる運用の必要性が生じます。<br />
ただこの場合でも、複数ノードを使用するマルチノードジョブを実行する計算/GPUノードでは、これらのジョブの実行を妨げないようにノード占有で実行する必要があります。</p>

<p>本Tipsは、前述の運用要件を念頭に、ジョブを投入するパーティションを使い分けることで、ノード占有ジョブとノード共有ジョブが混在する <strong>Slurm</strong> 環境を構築する方法を解説します。</p>

<p>構築する <strong>Slurm</strong> 環境は、計算ノードに3ノードの <strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm#bm-hpc-optimized">BM.Optimized3.36</a></strong> （搭載コア数： 36、 搭載メモリ量： 512GB（<strong>Slurm</strong> 設定上の利用可能メモリ量を500GBに設定））を使用し、以下のパーティション構成とします。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">パーティション名</th>
      <th style="text-align: center">割当てられるノード名</th>
      <th style="text-align: center">ノードの占有/共有</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">large</td>
      <td style="text-align: center">inst-aaaaa-x9 inst-bbbbb-x9</td>
      <td style="text-align: center">占有</td>
    </tr>
    <tr>
      <td style="text-align: center">small</td>
      <td style="text-align: center">inst-ccccc-x9</td>
      <td style="text-align: center">共有</td>
    </tr>
  </tbody>
</table>

<p>これにより、以下の運用が可能になります。</p>

<ul>
  <li>ノード占有ジョブはパーティション <strong>large</strong> に投入</li>
  <li>ノード共有ジョブはパーティション <strong>small</strong> に投入</li>
  <li>パーティション <strong>large</strong> に投入されたジョブは実行中ジョブの総使用ノード数が2ノードを超えない範囲で先着順にノード占有実行</li>
  <li>パーティション <strong>small</strong> に投入されたジョブは実行中ジョブの総使用コア数と総使用メモリ量がそれぞれ36コアと500GBを超えない範囲で先着順にノード共有実行（※4）</li>
</ul>

<p>※4）ジョブ投入時は、使用するメモリ量を <strong>–mem=xxxxM</strong> オプションで指定する必要があります。<br />
以下は、使用するメモリ量を100,000 MBに指定してジョブを <strong>small</strong> パーティションに投入しています。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>srun <span class="nt">-p</span> small <span class="nt">-n</span> 4 <span class="nt">--mem</span><span class="o">=</span>100000M ./a.out
</code></pre></div></div>

<h2 id="4-1-slurmconf修正">4-1. slurm.conf修正</h2>

<p>本章は、本Tipsの想定する運用要件を実現するよう <strong>slurm.conf</strong> を修正します。</p>

<p>作成する <strong>slurm.conf</strong> は、 <strong>SelectType</strong> 行、 <strong>NodeName</strong> 行、及び <strong>PartitionName</strong> 行を以下に修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>:
<span class="nv">SelectType</span><span class="o">=</span><span class="k">select</span>/cons_tres
:
<span class="nv">NodeName</span><span class="o">=</span>inst-aaaaa-x9,inst-bbbbb-x9,inst-ccccc-x9 <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>2 <span class="nv">CoresPerSocket</span><span class="o">=</span>18 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
<span class="nv">PartitionName</span><span class="o">=</span>large <span class="nv">Nodes</span><span class="o">=</span>inst-aaaaa-x9,inst-bbbbb-x9 <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP <span class="nv">OverSubscribe</span><span class="o">=</span>Exclusive
<span class="nv">PartitionName</span><span class="o">=</span>small <span class="nv">Nodes</span><span class="o">=</span>inst-ccccc-x9 <span class="nv">MaxTime</span><span class="o">=</span>INFINITE <span class="nv">State</span><span class="o">=</span>UP
:
</code></pre></div></div>

<p>この設定は、リソース選択アルゴリズムを指定する <strong>SelectType</strong> 行にノード共有ジョブを可能にする <strong>select/cons_tres</strong> を指定し、パーティション <strong>large</strong> に <strong>OverSubscribe=Exclusive</strong> を指定することでノード占有パーティションを宣言しています。</p>

<h2 id="42-slurmconf修正の反映">4.2. slurm.conf修正の反映</h2>

<p>本章は、先に修正した <strong>slurm.conf</strong> を反映します。</p>

<p>Slurmマネージャ、Slurmクライアント、及び計算/GPUノードで、先に修正した <strong>slurm.conf</strong> を <strong>/opt/slurm/etc</strong> ディレクトリにコピーします。</p>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、 <strong>slurm.conf</strong> ファイルの変更を反映、その結果を確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol reconfigure"</span>
<span class="nv">$ </span><span class="nb">sudo </span>su - slurm <span class="nt">-c</span> <span class="s2">"scontrol show config"</span> | <span class="nb">grep</span> <span class="s2">"SelectType "</span>
SelectType              <span class="o">=</span> <span class="k">select</span>/cons_tres
<span class="err">$</span>
</code></pre></div></div>

<p>次に、Slurmマネージャのopcユーザで以下のコマンドを実行し、パーティションが想定通り作成されていることを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>sinfo <span class="nt">-l</span>
Tue Dec 24 18:00:11 2024
PARTITION AVAIL  TIMELIMIT   JOB_SIZE ROOT OVERSUBS     GROUPS  NODES       STATE RESERVATION NODELIST
small        up   infinite 1-infinite   no       NO        all      1        idle             inst-ccccc-x9
large        up   infinite 1-infinite   no EXCLUSIV        all      2        idle             inst-aaaaa-x9,inst-bbbbb-x9
<span class="err">$</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新日時:</strong> <time class="dt-published" datetime="2025-06-24T07:43:40+09:00">June 24, 2025</time></p>

      </footer>

      <section class="page__share">
  <h4 class="page__share-title">共有</h4>

  <a href="https://x.com/intent/tweet?text=Slurm%E3%81%AB%E3%82%88%E3%82%8B%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E7%AE%A1%E7%90%86%E3%83%BB%E3%82%B8%E3%83%A7%E3%83%96%E7%AE%A1%E7%90%86%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E9%81%8B%E7%94%A8Tips%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Ftech-knowhow%2Fslurm-tips%2F" class="btn btn--x" aria-label="Share on X" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 X">
    <i class="fab fa-fw fa-x-twitter" aria-hidden="true"></i><span> X</span>
  </a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Ftech-knowhow%2Fslurm-tips%2F" class="btn btn--facebook" aria-label="Share on Facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Facebook">
    <i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span>
  </a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://oracle-japan.github.io/ocitutorials/hpc/tech-knowhow/slurm-tips/" class="btn btn--linkedin" aria-label="Share on LinkedIn" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 LinkedIn">
    <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span>
  </a>

  <a href="https://bsky.app/intent/compose?text=Slurm%E3%81%AB%E3%82%88%E3%82%8B%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E7%AE%A1%E7%90%86%E3%83%BB%E3%82%B8%E3%83%A7%E3%83%96%E7%AE%A1%E7%90%86%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E9%81%8B%E7%94%A8Tips%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Ftech-knowhow%2Fslurm-tips%2F" class="btn btn--bluesky" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Bluesky">
    <i class="fab fa-fw fa-bluesky" aria-hidden="true"></i><span> Bluesky</span>
  </a>
</section>


      
  <nav class="pagination">
    
      <a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/" class="pagination--pager" title="OpenFOAMインストール・利用方法">前へ</a>
    
    
      <a href="/ocitutorials/hpc/tech-knowhow/build-oraclelinux-hpcenv/" class="pagination--pager" title="Oracle Linuxプラットフォーム・イメージベースのHPCワークロード実行環境構築方法">次へ</a>
    
  </nav>


    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">関連記事</h2>
  <div class="grid__wrapper">
    
  </div>
</div>

  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="検索キーワードを入力してください..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>フォロー</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/#ocijp" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/oracle-japan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/ocitutorials/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 <a href="https://oracle-japan.github.io">Oracle Cloud Infrastructure チュートリアル</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ocitutorials/assets/js/main.min.js"></script>




<script src="/ocitutorials/assets/js/lunr/lunr.min.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-store.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6W7FEC5CEH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6W7FEC5CEH', { 'anonymize_ip': false});
</script>







  
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
  
    <script src="/ocitutorials/assets/js/clipboardrouge.js"></script>
  
    <script src="/ocitutorials/assets/js/tabs.js"></script>
  
    <script src="/ocitutorials/assets/js/sidebar.js"></script>
  


  </body>
</html>
