<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.0 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="ja" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>GPUインスタンスで機械学習にトライ | Oracle Cloud Infrastructure チュートリアル</title>
<meta name="description" content="OCIのGPUインスタンスで機械学習にトライしてみましょう。このチュートリアルを終了すると、TensorFlowやJupyterLab等の代表的な機械学習関連ソフトウェアがインストールされた、機械学習環境に最適なNvidia製GPU搭載のインスタンスを構築し、サンプル機械学習プログラムを実行することが出来るようになります。">


  <meta name="author" content="Oracle Japan Solution Engineers">
  
  <meta property="article:author" content="Oracle Japan Solution Engineers">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ja_JP">
<meta property="og:site_name" content="Oracle Cloud Infrastructure チュートリアル">
<meta property="og:title" content="GPUインスタンスで機械学習にトライ">
<meta property="og:url" content="https://oracle-japan.github.io/ocitutorials/hpc/spinup-ml-instance/">


  <meta property="og:description" content="OCIのGPUインスタンスで機械学習にトライしてみましょう。このチュートリアルを終了すると、TensorFlowやJupyterLab等の代表的な機械学習関連ソフトウェアがインストールされた、機械学習環境に最適なNvidia製GPU搭載のインスタンスを構築し、サンプル機械学習プログラムを実行することが出来るようになります。">



  <meta property="og:image" content="https://oracle-japan.github.io/ocitutorials/hpc/spinup-ml-instance/architecture_diagram.png">





  <meta property="article:published_time" content="2024-05-07T10:43:53+09:00">






<link rel="canonical" href="https://oracle-japan.github.io/ocitutorials/hpc/spinup-ml-instance/">












<!-- end _includes/seo.html -->



  <link href="/ocitutorials/feed.xml" type="application/atom+xml" rel="alternate" title="Oracle Cloud Infrastructure チュートリアル Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script type="text/javascript">
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/ocitutorials/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/ocitutorials/"><img src="/ocitutorials/assets/images/social-og-oracle-badge.jpg" alt="OCI チュートリアル"></a>
        
        <a class="site-title" href="/ocitutorials/">
          OCI チュートリアル
          <span class="site-subtitle">Oracle Cloud Infrastructure を使ってみよう</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/ocitutorials/#%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E4%B8%80%E8%A6%A7"
                
                
              >チュートリアル一覧</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ocitutorials/about/"
                
                
              >このサイトについて</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">メニュー</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(34, 66, 55, 0.7), rgba(34, 66, 55, 0.7)), url('/ocitutorials/hpc/spinup-ml-instance/architecture_diagram.png');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          GPUインスタンスで機械学習にトライ

        
      </h1>
      
        <p class="page__lead">OCIのGPUインスタンスで機械学習にトライしてみましょう。このチュートリアルを終了すると、TensorFlowやJupyterLab等の代表的な機械学習関連ソフトウェアがインストールされた、機械学習環境に最適なNvidia製GPU搭載のインスタンスを構築し、サンプル機械学習プログラムを実行することが出来るようになります。
</p>
      
      


      
    </div>
  
  
</div>






  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/" itemprop="item"><span itemprop="name">ホーム</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">></span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/hpc" itemprop="item"><span itemprop="name">Hpc</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">></span>
      
    
      
      
        <li class="current">GPUインスタンスで機械学習にトライ</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">メニュー</label>
  <ul class="nav__items">
    <li>
      
      <a href=""><span class="nav__sub-title">HPC編</span></a>
      <ul>
        
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-cluster-network/">HPCクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withterraform/">HPCクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster/">HPCクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withautoscaling/">HPCクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance/" class="active">GPUインスタンスで機械学習にトライ</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster/">GPUクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withterraform/">GPUクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack/">GPUクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withautoscaling/">GPUクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withubuntu/">GPUクラスタを構築する(Ubuntu OS編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server/">ブロック・ボリュームでNFSサーバを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-base/">ブロック・ボリュームNFSサーバと基礎インフラ編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-stack/">ブロック・ボリュームNFSサーバと自動構築編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl/">HPL実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e5/">HPL実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream/">STREAM実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e5/">STREAM実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-imb/">Intel MPI Benchmark実行方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests/">NCCL Tests実行方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/stop-unused-service/">不要サービス停止によるパフォーマンスチューニング方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/topology-aware-cn-tuning/">クラスタ・ネットワークのトポロジーを考慮したノード間通信最適化方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/papi-profiling/">PAPIでHPCアプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/scorep-profiling/">Score-PとCubeGUIで並列アプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/">クラスタネットワーキングイメージを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/rdma-interface-configure/">クラスタ・ネットワーク接続用ネットワークインターフェース作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-create-cnenabled-osimage/">クラスタ・ネットワーク非対応OSイメージを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/determine-cnrelated-issue/">クラスタ・ネットワークに接続する計算/GPUノードデプロイ時の問題判別方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-get-cnrelated-statistics/">クラスタ・ネットワーク統計情報の取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/nvme-filesystem/">ベアメタルインスタンスの内蔵NVMe SSD領域ファイルシステム作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-configure-sharedstorage/">コストパフォーマンスの良いファイル共有ストレージ構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/bv-sharedstorage-recovery/">ブロック・ボリュームを使用するNFSサーバのインスタンス障害からの復旧方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/boot-volume-extension/">計算/GPUノードのブート・ボリューム動的拡張方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-name-resolution/">計算/GPUノードの効果的な名前解決方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-os-customization/">計算/GPUノードデプロイ時の効果的なOSカスタマイズ方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-host-list/">計算/GPUノードのホスト名リスト作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-resize/">計算/GPUノードの追加・削除・入れ替え方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-with-pdsh/">pdshで効率的にクラスタ管理オペレーションを実行</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/instance-principal-auth/">オンデマンドクラスタ実現のためのインスタンス・プリンシパル認証設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/log-monitoring/">OCIロギングとGrafanaを使用したHPC/GPUクラスタのログ監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/metric-monitoring/">OCIモニタリングとGrafanaを使用したHPC/GPUクラスタのメトリック監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/gpu-with-ubuntu/">UbuntuをOSとする機械学習ワークロード向けGPUノード構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-openmpi/">Slurm環境での利用を前提とするOpenMPI構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-blas/">線形代数演算ライブラリインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/kdump-on-baremetal/">ベアメタル・インスタンスのカーネルダンプ取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/site-to-site-vpn/">サイト間VPNによるOCIとの拠点間接続方法</a></li></p>
        
      </ul>
    </li>
  </ul>
</nav>
    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="GPUインスタンスで機械学習にトライ">
    <meta itemprop="description" content="OCIのGPUインスタンスで機械学習にトライしてみましょう。このチュートリアルを終了すると、TensorFlowやJupyterLab等の代表的な機械学習関連ソフトウェアがインストールされた、機械学習環境に最適なNvidia製GPU搭載のインスタンスを構築し、サンプル機械学習プログラムを実行することが出来るようになります。">
    <meta itemprop="datePublished" content="2024-05-07T10:43:53+09:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目次</h4></header>
              <ul class="toc__menu"><li><a href="#0-機械学習環境構築フロー">0. 機械学習環境構築フロー</a></li><li><a href="#1-gpuインスタンス起動">1. GPUインスタンス起動</a></li><li><a href="#2-gpuインスタンスos上に機械学習環境構築">2. GPUインスタンスOS上に機械学習環境構築</a><ul><li><a href="#2-1-pythontenforflowjupyterlab環境構築">2-1. Python・TenforFlow・JupyterLab環境構築</a></li><li><a href="#2-2-tenforflowjupyterlab稼働確認">2-2. TenforFlow・JupyterLab稼働確認</a></li><li><a href="#2-3-jupyterlabで機械学習プログラム実行">2-3. JupyterLabで機械学習プログラム実行</a></li><li><a href="#2-4-distributed-tensorflowを使用した分散トレーニングモデル実行">2-4. Distributed TensorFlowを使用した分散トレーニングモデル実行</a></li><li><a href="#2-5-機械学習関連インストール済みソフトウェア確認">2-5. 機械学習関連インストール済みソフトウェア確認</a></li></ul></li><li><a href="#3-dockerコンテナ上に機械学習環境構築">3. Dockerコンテナ上に機械学習環境構築</a><ul><li><a href="#3-1-dockerコンテナ環境構築">3-1. Dockerコンテナ環境構築</a></li><li><a href="#3-2-pythontenforflowjupyter-notebook環境構築">3-2. Python・TenforFlow・Jupyter Notebook環境構築</a><ul><li><a href="#3-2-1-googleがdocker-hubから提供するdockerイメージの場合">3-2-1. GoogleがDocker Hubから提供するDockerイメージの場合</a></li><li><a href="#3-2-2-nvidiaがnvidia-gpu-cloudから提供するdockerイメージの場合">3-2-2. NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</a></li></ul></li><li><a href="#3-3-tenforflowjupyter-notebook稼働確認">3-3. TenforFlow・Jupyter Notebook稼働確認</a></li><li><a href="#3-4-jupyter-notebookで機械学習プログラム実行">3-4. Jupyter Notebookで機械学習プログラム実行</a></li><li><a href="#3-5-distributed-tensorflowを使用した分散トレーニングモデル実行">3-5. Distributed TensorFlowを使用した分散トレーニングモデル実行</a></li><li><a href="#3-6-機械学習関連インストール済みソフトウェア確認">3-6. 機械学習関連インストール済みソフトウェア確認</a><ul><li><a href="#3-6-1-googleがdocker-hubから提供するdockerイメージの場合">3-6-1. GoogleがDocker Hubから提供するDockerイメージの場合</a></li><li><a href="#3-6-2-nvidiaがnvidia-gpu-cloudから提供するdockerイメージの場合">3-6-2. NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</a></li></ul></li></ul></li></ul>
            </nav>
          </aside>
        
        <p>Oracle Cloud Infrastructure（以降OCIと記載）は、GPUを搭載するVMやベアメタルの様々なシェイプが用意されており、自身の機械学習ニーズに合った機械学習環境を構築するには最適なクラウドサービスです。</p>

<p>このチュートリアルは、NVIDIA GPUドライバソフトウェアやCUDAを内包するOCIのGPUシェイプ向けプラットフォームイメージを利用し、以下構成の機械学習環境を構築、TensorFlowを利用するサンプル機械学習プログラムをJupyterLab/Jupyter Notebookから実行します。</p>
<ul>
  <li>選択可能な機械学習環境GPUシェイプ
    <ul>
      <li>VM.GPU3.1 (NVIDIA Tesla V100 16 GB x 1)</li>
      <li>VM.GPU3.2 (NVIDIA Tesla V100 16 GB x 2)</li>
      <li>VM.GPU3.4 (NVIDIA Tesla V100 16 GB x 4)</li>
      <li>BM.GPU3.8 (NVIDIA Tesla V100 16 GB x 8)</li>
      <li>BM.GPU4.8 (NVIDIA A100 40 GB x 8)</li>
    </ul>

    <p>※：シェイプ詳細は、以下URLを参照。</p>

    <p><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm">https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm</a></p>
  </li>
  <li>利用可能な機械学習関連ソフトウェア
    <ul>
      <li>TensorFlow</li>
      <li>Keras</li>
      <li>NumPy</li>
      <li>Matplotlib</li>
      <li>Jupyter Notebook</li>
      <li>JupyterLab</li>
      <li>and more （※）</li>
    </ul>

    <p>※：全リストは、 <strong><a href="#2-5-機械学習関連インストール済みソフトウェア確認">2-5. 機械学習関連インストール済みソフトウェア確認</a></strong> または <strong><a href="#3-6-機械学習関連インストール済みソフトウェア確認">3-6. 機械学習関連インストール済みソフトウェア確認</a></strong> を参照下さい。またここでインストールされていないその他の機械学習関連ソフトウェアは、pipでインストールすることが出来ます。</p>
  </li>
</ul>

<p><img src="architecture_diagram.png" alt="システム構成図" /></p>

<p>この機械学習環境は、環境構築直後からTensorFlowを利用し機械学習プログラムをGPU上で高速に実行することが可能です。</p>

<p>またマルチGPUを搭載するGPUシェイプを利用することで、Distributed TensorFlowを使用した複数のGPUに跨る分散トレーニングが可能になります。このチュートリアルの後半では、マルチGPUを搭載する機械学習環境で、サンプルプログラムをDistributed TensorFlowを使用した分散トレーニングモデルに修正、これを複数のGPUに跨って実行します。</p>

<p><strong>所要時間 :</strong> 約45分</p>

<p><strong>前提条件 :</strong> 機械学習環境を構築するインスタンスを収容するコンパートメント(ルート・コンパートメントでもOKです)の作成と、このコンパートメントに対する必要なリソース管理権限がユーザーに付与されていること。</p>

<p><strong>注意1 :</strong> 現在、一時的に無償トライアル環境でのGPUインスタンスの利用を制限させて頂いています。そのため、現在このチュートリアルの手順を実施するには、商用のOCI契約が必要になります。</p>

<p><strong>注意2 :</strong> チュートリアル内の画面ショットについては、OCIの現在のコンソール画面と異なっている場合があります。また使用する機械学習関連ソフトウェアのバージョンが異なる場合も、チュートリアル内の画面ショットが異なる場合があります。</p>

<h1 id="0-機械学習環境構築フロー">0. 機械学習環境構築フロー</h1>

<p>本チュートリアルは、OCI関連リソース（ネットワーク関連リソースとGPUインスタンス）の作成をOCIコンソールから行い（ <strong><a href="#1-gpuインスタンス起動">1. GPUインスタンス起動</a></strong> ）、続いて起動したGPUインスタンスにログインし機械学習環境の構築を行います。</p>

<p>後半のGPUインスタンス上での機械学習環境構築は、GPUインスタンスのOS上に直接機械学習関連ソフトウェアをSoftware Collectionsを使用してインストールする方法（ <strong><a href="#2-gpuインスタンスos上に機械学習環境構築">2. GPUインスタンスOS上に機械学習環境構築</a></strong> ）と、機械学習関連ソフトウェアが予めインストールされたDockerイメージを使用してDockerコンテナ上に作成する方法（ <strong><a href="#3-dockerコンテナ上に機械学習環境構築">3. Dockerコンテナ上に機械学習環境構築</a></strong> ）の、2つを解説します。</p>

<p>またDockerコンテナ上に機械学習環境を構築する方法は、GoogleがDocker Hubから提供する機械学習関連ソフトウェアがインストールされたDockerイメージを使用する方法と、NVIDIAがNVIDIA GPU Cloudから提供するNVIDIA GPU向けに最適化された機械学習関連ソフトウェアがインストールされたDockerイメージを使用する方法の、2つを解説します。</p>

<p>機械学習環境の構築方法は、自身の好みに合わせて選択してください。</p>

<p><img src="flow_chart.png" alt="画面ショット" /></p>

<p>NVIDIA GPU CloudのDockerイメージを使用する場合、NVIDIA GPU Cloudのアカウントで予めAPIキーを作成しておく必要があります。この詳細は、以下URLを参照ください。</p>

<p><a href="https://docs.nvidia.com/ngc/ngc-overview/index.html">https://docs.nvidia.com/ngc/ngc-overview/index.html</a></p>

<h1 id="1-gpuインスタンス起動">1. GPUインスタンス起動</h1>

<p>本章は、OCIコンソールからGPUインスタンスを起動します。このチュートリアルで使用するプラットフォームイメージは、Oracle Linux 7.9をベースとしたGen2-GPU-2022.05.31-0です。</p>

<p>本チュートリアルは、GPUインスタンスにNVIDIA Tesla V100 16 GBを2枚搭載するVMシェイプのVM.GPU3.2を使用します。</p>

<ol>
  <li>
    <p>OCIコンソールにログインし、GPUインスタンスを起動するリージョンを選択後、 <strong>コンピュート</strong> → <strong>インスタンス</strong> とメニューを辿ります。</p>
  </li>
  <li>
    <p>表示される以下画面で、<strong>インスタンスの作成</strong> ボタンをクリックします。</p>

    <p><img src="console_page00.png" alt="画面ショット" /></p>
  </li>
  <li>
    <p>表示される <strong>コンピュート・インスタンスの作成</strong> 画面で、以下の情報を入力し <strong>作成</strong> ボタンをクリックします。なお、ここに記載のないフィールドは、デフォルトのままとします。</p>

    <p>3.1 <strong>名前</strong> フィールド：GPUインスタンスに付与する名前</p>

    <p><img src="console_page01.png" alt="画面ショット" /></p>

    <p>3.2 <strong>コンパートメントに作成</strong> フィールド：GPUインスタンスを構築するコンパートメント</p>

    <p><img src="console_page01-1.png" alt="画面ショット" /></p>

    <p>3.3 <strong>配置</strong> フィールド</p>
    <ul>
      <li><strong>可用性ドメイン</strong> ：GPUインスタンスを構築する可用性ドメイン</li>
    </ul>

    <p><img src="console_page02.png" alt="画面ショット" /></p>

    <p>3.4 <strong>イメージとシェイプ</strong> フィールド</p>

    <p><img src="console_page03.png" alt="画面ショット" /></p>

    <ul>
      <li><strong>Shape</strong> ：VM.GPU3.2 (<strong>Change Shape</strong> ボタンをクリックして表示される <strong>すべてのシェイプの参照</strong> サイドバーで <strong>仮想マシン</strong> → <strong>専門と前世代</strong> で表示される <strong>VM.GPU3.2</strong> を選択し <strong>次のドキュメントを確認した上でこれに同意します。</strong> チェックボックスをチェックし <strong>シェイプの選択</strong> ボタンをクリック）</li>
    </ul>

    <p><img src="console_page03-2.png" alt="画面ショット" /></p>

    <ul>
      <li><strong>イメージ</strong> ：Oracle Linux 7.9 Gen2-GPU-2022.05.31-0 (<strong>イメージの変更</strong> ボタンをクリックして表示される <strong>すべてのイメージの参照</strong> サイドバーでOracle Linuxのバージョンを適切に選択後 <strong>イメージの選択</strong> ボタンをクリック）</li>
    </ul>

    <p><img src="console_page03-1.png" alt="画面ショット" /></p>

    <p>3.5 <strong>ネットワーキング</strong> フィールド</p>
    <ul>
      <li><strong>プライマリ・ネットワーク</strong> ： <strong>新規仮想クラウド・ネットワークの作成</strong></li>
      <li>
        <p><strong>コンパートメントに作成</strong> ：GPUインスタンスを構築するコンパートメント</p>

        <p><img src="console_page05.png" alt="画面ショット" /></p>
      </li>
    </ul>

    <p>3.6 <strong>SSHキーの追加</strong> フィールド</p>
    <ul>
      <li><strong>SSHキー</strong> ：GPUインスタンスにログインする際使用するSSH秘密鍵に対応する公開鍵
        <ul>
          <li>公開鍵ファイルのアップロード（ <strong>公開キー・ファイル(.pub)のアップロード</strong> ）と公開鍵のフィールドへの貼り付け（ <strong>公開キーの貼付け</strong> ）が選択可能</li>
        </ul>

        <p><img src="console_page06.png" alt="画面ショット" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p>表示される以下 <strong>作業リクエスト</strong> 画面で、左上のステータスが <strong>プロビジョニング中</strong> と表示されれば、GPUインスタンスの構築が実施されています。</p>

    <p><img src="console_page07.png" alt="画面ショット" /></p>

    <p>ステータスが <strong>実行中</strong> となれば、GPUインスタンスの構築が完了しています。</p>
  </li>
</ol>

<h1 id="2-gpuインスタンスos上に機械学習環境構築">2. GPUインスタンスOS上に機械学習環境構築</h1>

<p>本章は、デプロイされたGPUインスタンスのOS上に直接機械学習関連ソフトウェアをインストール、Python・TensorFlow・JupyterLab環境を構築します。</p>

<h2 id="2-1-pythontenforflowjupyterlab環境構築">2-1. Python・TenforFlow・JupyterLab環境構築</h2>

<p>本チュートリアルで使用しているOracle Linux 7.9は、内包されているPythonのバージョンが3.6と古いため、まずPython 3.8をインストールします。この際、Oracle Linux 7.9の様々なパッケージから利用されるPython 3.6を残し、複数のバージョンを混在させることが可能なSoftware Collectionsを使用してPython 3.8を追加でインストール、このPython 3.8をベースにTensorFlowやJupyterLab等の機械学習関連プログラム環境を構築します。</p>

<ol>
  <li>
    <p>GPUインスタンスログイン</p>

    <p><strong>1. GPUインスタンス起動</strong> の手順の最後に表示される <strong>作業リクエスト</strong> 画面で、<strong>パブリックIPアドレス</strong> フィールドに表示されているGPUインスタンスのIPアドレスを使用し、SSHでGPUインスタンスにopcアカウントでインターネット経由ログインします。</p>

    <p><img src="console_page08.png" alt="画面ショット" /></p>

    <p>このSSH接続では、GPUインスタンス構築時に指定したSSH公開鍵に対応する秘密鍵を使用します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> ssh <span class="nt">-i</span> path_to_ssh_secret_key opc@123.456.789.123
</code></pre></div>    </div>
  </li>
  <li>
    <p>Python 3.8インストール</p>

    <p>rootにスイッチして以下コマンドを実行し、Software Collectionsから提供されるPython 3.8をインストール、これを有効化したサブシェルを起動、pipとsetuptoolsをアップグレードします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> yum <span class="nt">-y</span> <span class="nb">install </span>rh-python38
<span class="o">&gt;</span> scl <span class="nb">enable </span>rh-python38 bash
<span class="o">&gt;</span> pip <span class="nb">install</span> <span class="nt">--upgrade</span> pip setuptools
<span class="o">&gt;</span> <span class="nb">exit</span>
<span class="o">&gt;</span> scl <span class="nb">enable </span>rh-python38 bash
</code></pre></div>    </div>
  </li>
  <li>
    <p>TensorFlow・JupyterLab・Matplotlibインストール</p>

    <p>以下コマンドを実行し、TensorFlow・JupyterLab・Matplotlibをインストールします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> pip <span class="nb">install </span>tensorflow jupyterlab matplotlib
</code></pre></div>    </div>
  </li>
  <li>
    <p>JupyterLabログインパスワード初期化</p>

    <p>opcにスイッチして以下コマンドを実行し、JupyterLabにログインする際のパスワードを初期化します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> scl <span class="nb">enable </span>rh-python38 bash
<span class="o">&gt;</span> jupyter lab password
Enter password: 
Verify password: 
<span class="o">[</span>JupyterPasswordApp] Wrote hashed password to /home/opc/.jupyter/jupyter_server_config.json

</code></pre></div>    </div>
  </li>
  <li>
    <p>JupyterLabのsystemdへの登録</p>

    <p>rootにスイッチし、JupyterLabをsystemdに登録するための設定ファイルを以下のように作成します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="nb">cat</span> /etc/systemd/system/jupyterlab.service
<span class="o">[</span>Unit]
<span class="nv">Description</span><span class="o">=</span>Jupyter Lab
<span class="o">[</span>Service]
<span class="nv">Type</span><span class="o">=</span>simple
<span class="nv">PIDFile</span><span class="o">=</span>/var/run/jupyter-lab.pid
<span class="nv">ExecStart</span><span class="o">=</span>/opt/rh/rh-python38/root/usr/bin/python /opt/rh/rh-python38/root/usr/local/bin/jupyter-lab <span class="nt">--app-dir</span><span class="o">=</span>/opt/rh/rh-python38/root/usr/local/share/jupyter/lab/
<span class="nv">WorkingDirectory</span><span class="o">=</span>/home/opc/
<span class="nv">User</span><span class="o">=</span>opc
<span class="nv">Group</span><span class="o">=</span>opc
<span class="nv">Restart</span><span class="o">=</span>always
<span class="o">[</span>Install]
<span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</code></pre></div>    </div>
  </li>
  <li>
    <p>JupyterLab起動</p>

    <p>以下コマンドで、JupyterLabを起動します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> systemctl daemon-reload
<span class="o">&gt;</span> systemctl start jupyterlab
<span class="o">&gt;</span> systemctl <span class="nb">enable </span>jupyterlab
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="2-2-tenforflowjupyterlab稼働確認">2-2. TenforFlow・JupyterLab稼働確認</h2>

<p>本章は、TensorFlowが認識するGPUカードの枚数を確認するプログラムを実行し、TensorFlowとJupyterLabの稼働を確認します。</p>

<ol>
  <li>
    <p>稼働確認プログラムコピー</p>

    <p>以下稼働確認プログラムを、GPUインスタンスのopcアカウントのホームディレクトリ直下にファイル名”num_gpu.ipynb”でコピーします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
<span class="s2">"cells"</span>: <span class="o">[</span>
<span class="o">{</span>
   <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
   <span class="s2">"execution_count"</span>: null,
   <span class="s2">"metadata"</span>: <span class="o">{}</span>,
   <span class="s2">"outputs"</span>: <span class="o">[]</span>,
   <span class="s2">"source"</span>: <span class="o">[</span>
   <span class="s2">"import os</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"os.environ['TF_CPP_MIN_LOG_LEVEL']='2'</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"import tensorflow as tf</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"print(</span><span class="se">\"</span><span class="s2">Num GPUs Available: </span><span class="se">\"</span><span class="s2">, len(tf.config.list_physical_devices('GPU')))"</span>
   <span class="o">]</span>
<span class="o">}</span>
<span class="o">]</span>,
<span class="s2">"metadata"</span>: <span class="o">{</span>
<span class="s2">"kernelspec"</span>: <span class="o">{</span>
   <span class="s2">"display_name"</span>: <span class="s2">"Python 3"</span>,
   <span class="s2">"language"</span>: <span class="s2">"python"</span>,
   <span class="s2">"name"</span>: <span class="s2">"python3"</span>
<span class="o">}</span>,
<span class="s2">"language_info"</span>: <span class="o">{</span>
   <span class="s2">"codemirror_mode"</span>: <span class="o">{</span>
   <span class="s2">"name"</span>: <span class="s2">"ipython"</span>,
   <span class="s2">"version"</span>: 3
   <span class="o">}</span>,
   <span class="s2">"file_extension"</span>: <span class="s2">".py"</span>,
   <span class="s2">"mimetype"</span>: <span class="s2">"text/x-python"</span>,
   <span class="s2">"name"</span>: <span class="s2">"python"</span>,
   <span class="s2">"nbconvert_exporter"</span>: <span class="s2">"python"</span>,
   <span class="s2">"pygments_lexer"</span>: <span class="s2">"ipython3"</span>,
   <span class="s2">"version"</span>: <span class="s2">"3.6.8"</span>
<span class="o">}</span>
<span class="o">}</span>,
<span class="s2">"nbformat"</span>: 4,
<span class="s2">"nbformat_minor"</span>: 4
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>SSHポートフォワード作成</p>

    <p>構築したJupyterLabは、自身のGPUインスタンスからのみアクセス可能になっています。</p>

    <p>そこで、以下コマンドをJupyterLabにアクセスするブラウザを起動する端末で実行し、この端末の8888番ポートをGPUインスタンスの8888番ポート(JupyterLabがアクセスを待ち受けるポート)に転送するSSHポートフォワードを作成します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> ssh <span class="nt">-i</span> path_to_ssh_secret_key <span class="nt">-L</span> 8888:localhost:8888 opc@123.456.789.123
</code></pre></div>    </div>
  </li>
  <li>
    <p>JupyterLabへのアクセス</p>

    <p>ブラウザを起動し、アドレスに”localhost:8888”を指定してJupyterLabにアクセスし、表示される以下画面の <strong>Password</strong> フィールドに先に登録したパスワードを入力、 <strong>Log in</strong> ボタンをクリックします。</p>

    <p><img src="Jupyter_page01.png" alt="画面ショット" /></p>
  </li>
  <li>
    <p>稼働確認プログラム実行</p>

    <p>以下ブラウザ画面に表示される、先にコピーした稼働確認プログラムをクリックし、</p>

    <p><img src="Jupyter_page02.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Run the selected cells and advance</strong> ボタンをクリックして稼働確認プログラムを実行、”Num GPUs Available:”の値が使用するGPUシェイプに搭載されるGPU枚数に一致することを確認します。</p>

    <p><img src="Jupyter_page06.png" alt="画面ショット" /></p>
  </li>
</ol>

<h2 id="2-3-jupyterlabで機械学習プログラム実行">2-3. JupyterLabで機械学習プログラム実行</h2>

<p>本章は、GPUインスタンスのJupyterLabにアクセスし、サンプル機械学習プログラムを実行してその動作を確認します。</p>

<ol>
  <li>
    <p>サンプル機械学習プログラムコピー</p>

    <p>以下サンプルプログラムを、GPUインスタンスのopcアカウントのホームディレクトリ直下にファイル名”celsious2fahrenheit.ipynb”でコピーします。</p>

    <p>このプログラムは、既知の摂氏・華氏対応データからその変換式を学習し、未知の摂氏表記温度から対応する華氏を予測します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
   <span class="s2">"cells"</span>: <span class="o">[</span>
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: 19,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"#@title Licensed under the Apache License, Version 2.0 (the </span><span class="se">\"</span><span class="s2">License</span><span class="se">\"</span><span class="s2">);</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# you may not use this file except in compliance with the License.</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# You may obtain a copy of the License at</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"#</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# https://www.apache.org/licenses/LICENSE-2.0</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"#</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# Unless required by applicable law or agreed to in writing, software</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# distributed under the License is distributed on an </span><span class="se">\"</span><span class="s2">AS IS</span><span class="se">\"</span><span class="s2"> BASIS,</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# See the License for the specific language governing permissions and</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# limitations under the License."</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import os</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"os.environ['TF_CPP_MIN_LOG_LEVEL']='2'</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"import tensorflow as tf"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import numpy as np</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"import logging</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"logger = tf.get_logger()</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"logger.setLevel(logging.ERROR)"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"for i,c in enumerate(celsius_q):</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"  print(</span><span class="se">\"</span><span class="s2">{} degrees Celsius = {} degrees Fahrenheit</span><span class="se">\"</span><span class="s2">.format(c, fahrenheit_a[i]))"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"l0 = tf.keras.layers.Dense(units=1, input_shape=[1])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"model = tf.keras.Sequential([l0])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"model.compile(loss='mean_squared_error',</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"              optimizer=tf.keras.optimizers.Adam(0.1))"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"print(</span><span class="se">\"</span><span class="s2">Finished training the model</span><span class="se">\"</span><span class="s2">)"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import matplotlib.pyplot as plt</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.xlabel('Epoch Number')</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.ylabel(</span><span class="se">\"</span><span class="s2">Loss Magnitude</span><span class="se">\"</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.plot(history.history['loss'])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"print(model.predict([100.0]))"</span>
      <span class="o">]</span>
   <span class="o">}</span>
   <span class="o">]</span>,
   <span class="s2">"metadata"</span>: <span class="o">{</span>
   <span class="s2">"kernelspec"</span>: <span class="o">{</span>
      <span class="s2">"display_name"</span>: <span class="s2">"Python 3"</span>,
      <span class="s2">"language"</span>: <span class="s2">"python"</span>,
      <span class="s2">"name"</span>: <span class="s2">"python3"</span>
   <span class="o">}</span>,
   <span class="s2">"language_info"</span>: <span class="o">{</span>
      <span class="s2">"codemirror_mode"</span>: <span class="o">{</span>
      <span class="s2">"name"</span>: <span class="s2">"ipython"</span>,
      <span class="s2">"version"</span>: 3
      <span class="o">}</span>,
      <span class="s2">"file_extension"</span>: <span class="s2">".py"</span>,
      <span class="s2">"mimetype"</span>: <span class="s2">"text/x-python"</span>,
      <span class="s2">"name"</span>: <span class="s2">"python"</span>,
      <span class="s2">"nbconvert_exporter"</span>: <span class="s2">"python"</span>,
      <span class="s2">"pygments_lexer"</span>: <span class="s2">"ipython3"</span>,
      <span class="s2">"version"</span>: <span class="s2">"3.6.8"</span>
   <span class="o">}</span>
   <span class="o">}</span>,
   <span class="s2">"nbformat"</span>: 4,
   <span class="s2">"nbformat_minor"</span>: 4
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>サンプルプログラム実行</p>

    <p>JupyterLabにログインした直後のブラウザ画面をリロードし、以下画面に表示される、先にコピーしたサンプル機械学習プログラムをクリックします。</p>

    <p><img src="Jupyter_page07.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Restart Kernel and Run All Cells</strong> ボタンをクリックします。</p>

    <p><img src="Jupyter_page03.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Restart</strong> ボタンをクリックし、サンプルプログラムを実行します。</p>

    <p><img src="Jupyter_page04.png" alt="画面ショット" /></p>

    <p>実行した結果が表示される以下ブラウザ画面で、100度（摂氏）に対応する華氏の予測値が変換式（f=1.8c+32）から計算される212度（華氏）に近い値であることを確認します。</p>

    <p><img src="Jupyter_page05.png" alt="画面ショット" /></p>
  </li>
</ol>

<h2 id="2-4-distributed-tensorflowを使用した分散トレーニングモデル実行">2-4. Distributed TensorFlowを使用した分散トレーニングモデル実行</h2>

<p>本章は、先に実行した摂氏から華氏を予測するサンプルプログラムを元に、Distributed TensorFlowを使用する複数のGPUに跨った分散トレーニングモデルに修正、これを実行します。</p>

<ol>
  <li>
    <p>サンプルプログラムのDistributed TensorFlowを使用した分散トレーニングモデルへの修正</p>

    <p>2番目と3番目のセルの間に、以下のコードを挿入します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.debugging.set_log_device_placement<span class="o">(</span>True<span class="o">)</span>
mirrored_strategy <span class="o">=</span> tf.distribute.MirroredStrategy<span class="o">()</span>
</code></pre></div>    </div>

    <p>このコードは、想定通り複数のGPUに跨ったトレーニングが行われているかを確認するためのデバッグメッセージ出力設定と、TensorFlowのMirroedStrategy作成を行います。</p>

    <p><img src="Jupyter_page08.png" alt="画面ショット" /></p>

    <p>次に、5番目から7番目までのセルを、以下のコードに置き換えます。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with mirrored_strategy.scope<span class="o">()</span>:
  l0    <span class="o">=</span> tf.keras.layers.Dense<span class="o">(</span><span class="nv">units</span><span class="o">=</span>1, <span class="nv">input_shape</span><span class="o">=[</span>1]<span class="o">)</span>
  model <span class="o">=</span> tf.keras.Sequential<span class="o">([</span>l0]<span class="o">)</span>
  model.compile<span class="o">(</span><span class="nv">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span>, <span class="nv">optimizer</span><span class="o">=</span>tf.keras.optimizers.Adam<span class="o">(</span>0.1<span class="o">))</span>
</code></pre></div>    </div>

    <p>このコードは、レイヤー定義・レイヤーアセンブル・モデルコンパイルをMirroedStrategyのスコープ内に移動し、分散トレーニングモデルを定義しています。</p>

    <p><img src="Jupyter_page09.png" alt="画面ショット" /></p>
  </li>
  <li>
    <p>分散トレーニングモデルの実行</p>

    <p><strong>Restart Kernel and Run All Cells</strong> ボタンを使用し、修正後のサンプルプログラムを実行、デバッグメッセージから複数のGPUに跨ったトレーニングが行われていることを確認します。</p>

    <p>この際、デバッグメッセージが大量に出力されるため、プログラム実行時間が修正前より長くなることに注意します。</p>

    <p>複数GPUに跨ったトレーニングが行われていることを確認したら、デバッグメッセージ出力設定を削除します。</p>
  </li>
</ol>

<h2 id="2-5-機械学習関連インストール済みソフトウェア確認">2-5. 機械学習関連インストール済みソフトウェア確認</h2>

<p>本章は、以下コマンドを実行し、GPUインスタンスにインストールされている、機械学習関連ソフトウェアとそのバージョンを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="o">&gt;</span> scl <span class="nb">enable </span>rh-python38 bash
   <span class="o">&gt;</span> pip list
   Package                      Version
   <span class="nt">----------------------------</span> <span class="nt">-----------</span>
   absl-py                      1.1.0
   anyio                        3.6.1
   argon2-cffi                  21.3.0
   argon2-cffi-bindings         21.2.0
   asttokens                    2.0.5
   astunparse                   1.6.3
   attrs                        21.4.0
   Babel                        2.10.2
   backcall                     0.2.0
   beautifulsoup4               4.11.1
   bleach                       5.0.0
   cachetools                   5.2.0
   certifi                      2022.5.18.1
   cffi                         1.15.0
   charset-normalizer           2.0.12
   cycler                       0.11.0
   debugpy                      1.6.0
   decorator                    5.1.1
   defusedxml                   0.7.1
   entrypoints                  0.4
   executing                    0.8.3
   fastjsonschema               2.15.3
   flatbuffers                  1.12
   fonttools                    4.33.3
   gast                         0.4.0
   google-auth                  2.7.0
   google-auth-oauthlib         0.4.6
   google-pasta                 0.2.0
   grpcio                       1.46.3
   h5py                         3.7.0
   idna                         3.3
   importlib-metadata           4.11.4
   importlib-resources          5.7.1
   ipykernel                    6.14.0
   ipython                      8.4.0
   ipython-genutils             0.2.0
   jedi                         0.18.1
   Jinja2                       3.1.2
   json5                        0.9.8
   jsonschema                   4.6.0
   jupyter-client               7.3.4
   jupyter-core                 4.10.0
   jupyter-server               1.17.1
   jupyterlab                   3.4.3
   jupyterlab-pygments          0.2.2
   jupyterlab-server            2.14.0
   keras                        2.9.0
   Keras-Preprocessing          1.1.2
   kiwisolver                   1.4.3
   libclang                     14.0.1
   Markdown                     3.3.7
   MarkupSafe                   2.1.1
   matplotlib                   3.5.2
   matplotlib-inline            0.1.3
   mistune                      0.8.4
   nbclassic                    0.3.7
   nbclient                     0.6.4
   nbconvert                    6.5.0
   nbformat                     5.4.0
   nest-asyncio                 1.5.5
   notebook                     6.4.12
   notebook-shim                0.1.0
   numpy                        1.22.4
   oauthlib                     3.2.0
   opt-einsum                   3.3.0
   packaging                    21.3
   pandocfilters                1.5.0
   parso                        0.8.3
   pexpect                      4.8.0
   pickleshare                  0.7.5
   Pillow                       9.1.1
   pip                          22.1.2
   prometheus-client            0.14.1
   prompt-toolkit               3.0.29
   protobuf                     3.19.4
   psutil                       5.9.1
   ptyprocess                   0.7.0
   pure-eval                    0.2.2
   pyasn1                       0.4.8
   pyasn1-modules               0.2.8
   pycparser                    2.21
   Pygments                     2.12.0
   pyparsing                    3.0.9
   pyrsistent                   0.18.1
   python-dateutil              2.8.2
   pytz                         2022.1
   pyzmq                        23.1.0
   requests                     2.28.0
   requests-oauthlib            1.3.1
   rsa                          4.8
   Send2Trash                   1.8.0
   setuptools                   62.4.0
   six                          1.16.0
   sniffio                      1.2.0
   soupsieve                    2.3.2.post1
   stack-data                   0.2.0
   tensorboard                  2.9.1
   tensorboard-data-server      0.6.1
   tensorboard-plugin-wit       1.8.1
   tensorflow                   2.9.1
   tensorflow-estimator         2.9.0
   tensorflow-io-gcs-filesystem 0.26.0
   termcolor                    1.1.0
   terminado                    0.15.0
   tinycss2                     1.1.1
   tornado                      6.1
   traitlets                    5.2.2.post1
   typing_extensions            4.2.0
   urllib3                      1.26.9
   wcwidth                      0.2.5
   webencodings                 0.5.1
   websocket-client             1.3.2
   Werkzeug                     2.1.2
   wheel                        0.37.1
   wrapt                        1.14.1
   zipp                         3.8.0
</code></pre></div></div>
<h1 id="3-dockerコンテナ上に機械学習環境構築">3. Dockerコンテナ上に機械学習環境構築</h1>

<p>本章は、デプロイされたGPUインスタンス上にDockerコンテナ環境を構築、機械学習関連ソフトウェアが予めインストールされたDockerイメージを使用して、GPUを利用することが可能なTensorFlow・Jupyter Notebook環境をDockerコンテナ上に構築します。</p>

<h2 id="3-1-dockerコンテナ環境構築">3-1. Dockerコンテナ環境構築</h2>

<p>本章は、Docker Community EditionとNVIDIA Container Toolkitを使用し、GPUを利用することが可能なDockerコンテナ環境を構築します。</p>

<ol>
  <li>
    <p>GPUインスタンスログイン</p>

    <p><strong>1. GPUインスタンス起動</strong> の手順の最後に表示される <strong>作業リクエスト</strong> 画面で、<strong>パブリックIPアドレス</strong> フィールドに表示されているGPUインスタンスのIPアドレスを使用し、SSHでGPUインスタンスにopcアカウントでインターネット経由ログインします。</p>

    <p><img src="console_page08.png" alt="画面ショット" /></p>

    <p>このSSH接続では、GPUインスタンス構築時に指定したSSH公開鍵に対応する秘密鍵を使用します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> ssh <span class="nt">-i</span> path_to_ssh_secret_key opc@123.456.789.123
</code></pre></div>    </div>
  </li>
  <li>
    <p>Docker Community Editionインストール・起動</p>

    <p>rootにスイッチして以下コマンドを実行し、Docker Community Editionをインストール・起動します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> yum-config-manager <span class="nt">--enable</span> ol7_developer
<span class="o">&gt;</span> yum-config-manager <span class="nt">--add-repo</span> https://download.docker.com/linux/centos/docker-ce.repo
<span class="o">&gt;</span> yum <span class="nt">-y</span> <span class="nb">install </span>docker-ce
<span class="o">&gt;</span> systemctl start docker
<span class="o">&gt;</span> systemctl <span class="nb">enable </span>docker
</code></pre></div>    </div>
  </li>
  <li>
    <p>NVIDIA Container Toolkitインストール</p>

    <p>以下コマンドを実行し、NVIDIA Container Toolkitをインストールします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> yum-config-manager <span class="nt">--add-repo</span> https://nvidia.github.io/libnvidia-container/rhel7.9/libnvidia-container.repo
<span class="o">&gt;</span> yum-config-manager <span class="nt">--enable</span> libnvidia-container-experimental
<span class="o">&gt;</span> yum <span class="nt">-y</span> <span class="nb">install </span>nvidia-container-toolkit
<span class="o">&gt;</span> systemctl restart docker
</code></pre></div>    </div>
  </li>
  <li>
    <p>Dockerコンテナ環境稼働確認</p>

    <p>以下コマンドを実行し、Docker Community EditionとNVIDIA Container Toolkitによるコンテナ環境からGPUが利用可能であることを、nvidia-smiコマンドの出力で確認します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker run <span class="nt">--rm</span> <span class="nt">--gpus</span> all nvidia/cuda:11.0.3-base-ubuntu20.04  nvidia-smi
Unable to find image <span class="s1">'nvidia/cuda:11.0.3-base-ubuntu20.04'</span> locally
11.0.3-base-ubuntu20.04: Pulling from nvidia/cuda
d5fd17ec1767: Pull <span class="nb">complete 
</span>ea7643e57386: Pull <span class="nb">complete 
</span>622a04926279: Pull <span class="nb">complete 
</span>18fcb7509e42: Pull <span class="nb">complete 
</span>21e5db7c1fa2: Pull <span class="nb">complete 
</span>Digest: sha256:1db9418b1c9070cdcbd2d0d9980b52bd5cd20216265405fdb7e089c7ff96a494
Status: Downloaded newer image <span class="k">for </span>nvidia/cuda:11.0.3-base-ubuntu20.04
Mon Jun 20 06:52:30 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   38C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:00:05.0 Off |                    0 |
| N/A   39C    P0    40W / 300W |      0MiB / 16160MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                                 
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|<span class="o">=============================================================================</span>|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="3-2-pythontenforflowjupyter-notebook環境構築">3-2. Python・TenforFlow・Jupyter Notebook環境構築</h2>

<p>本章は、機械学習関連ソフトウェアが予めインストールされたDockerイメージを使用して、TensorFlowとJupyter Notebookが利用可能なDockerコンテナを起動します。</p>

<p>利用するDockerイメージは、GoogleがDocker Hubから提供するDockerイメージと、NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの、何れを利用することも可能です。詳細は、 <strong><a href="#0-機械学習環境構築フロー">0. 機械学習環境構築フロー</a></strong> を参照ください。</p>

<h3 id="3-2-1-googleがdocker-hubから提供するdockerイメージの場合">3-2-1. GoogleがDocker Hubから提供するDockerイメージの場合</h3>

<ol>
  <li>
    <p>Dockerコンテナ起動</p>

    <p>以下コマンドを実行し、Dockerコンテナを起動します。</p>

    <p>このコマンドは、GPUインスタンスに搭載される全てのGPUにアクセスすることが可能で、GPUインスタンスの8888番ポートをDockerコンテナの8888番ポート（Jupyter Notebookがアクセスを待ち受けるポート）に転送するコンテナを起動します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker run <span class="nt">-d</span> <span class="nt">--gpus</span> all <span class="nt">--name</span> mlenv <span class="nt">-p</span> 8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter
</code></pre></div>    </div>

    <p>ここで利用するDockerイメージは、コンテナ起動時にJupyter Notebookを8888番ポートで自動的に起動します。</p>
  </li>
  <li>
    <p>JupyterLabパスワードログイン設定</p>

    <p>以下コマンドを実行し、JupyterLabにパスワードでログインできるようにします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv jupyter notebook <span class="nt">--generate-config</span>
<span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#c.NotebookApp.allow_password_change = True/c.NotebookApp.allow_password_change = True/g'</span> /root/.jupyter/jupyter_notebook_config.py
</code></pre></div>    </div>

    <p>また以下コマンドを実行し、JupyterLabに初めてログインする際に必要なトークンを控えておきます。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv jupyter notebook list
Currently running servers:
http://0.0.0.0:8888/?token<span class="o">=</span>1479479473f5f58b569f54b9fea5b8cfa4f22cf7aa6e4299 :: /tf
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="3-2-2-nvidiaがnvidia-gpu-cloudから提供するdockerイメージの場合">3-2-2. NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</h3>

<ol>
  <li>
    <p>NVIDIA GPU Cloudログイン</p>

    <p>以下コマンドを実行し、NVIDIA GPU Cloudにログインします。ここでユーザ名は、固定的に <strong>$oauthtoken</strong> を使用し、パスワードはNVIDIA GPU Cloud上で生成したAPIキーを入力します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker login nvcr.io
Username: <span class="nv">$oauthtoken</span>
Password: xxxxxxxxxxxxxxxxxxxxxxx
</code></pre></div>    </div>
  </li>
  <li>
    <p>Dockerコンテナ起動</p>

    <p>以下コマンドを実行し、Dockerコンテナを起動します。</p>

    <p>このコマンドは、GPUインスタンスに搭載される全てのGPUにアクセスすることが可能で、GPUインスタンスの8888番ポートをDockerコンテナの8888番ポート（Jupyter Notebookがアクセスを待ち受けるポート）に転送するコンテナを起動します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker run <span class="nt">-d</span> <span class="nt">--gpus</span> all <span class="nt">--name</span> mlenv <span class="nt">-it</span> <span class="nt">-p</span> 8888:8888 nvcr.io/nvidia/tensorflow:22.06-tf2-py3 /bin/bash
</code></pre></div>    </div>
  </li>
  <li>
    <p>JupyterLabパスワードログイン設定</p>

    <p>以下コマンドを実行し、JupyterLabにパスワードでログインできるようにします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv jupyter notebook <span class="nt">--generate-config</span>
<span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/# c.NotebookApp.allow_password_change = True/c.NotebookApp.allow_password_change = True/g'</span> /root/.jupyter/jupyter_notebook_config.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>Jupyter Notebook起動</p>

    <p>以下コマンドを実行し、Jupyter Notebookを起動します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-d</span> <span class="nt">-it</span> mlenv jupyter-notebook <span class="nt">--allow-root</span>
</code></pre></div>    </div>

    <p>また以下コマンドを実行し、Jupyter Notebookに初めてログインする際に必要なトークンを控えておきます。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv jupyter notebook list
Currently running servers:
http://0.0.0.0:8888/?token<span class="o">=</span>dc42479929f3d657fde8c0324f1b8888bf71fcdee6f14a8e :: /workspace
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="3-3-tenforflowjupyter-notebook稼働確認">3-3. TenforFlow・Jupyter Notebook稼働確認</h2>

<p>本章は、TensorFlowが認識するGPUカードの枚数を確認するプログラムを実行し、TensorFlowとJupyter Notebookの稼働を確認します。</p>

<ol>
  <li>
    <p>稼働確認プログラムコピー</p>

    <p>以下稼働確認プログラムを、GPUインスタンスの/tmpディレクトリにファイル名”num_gpu.ipynb”でコピーします。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
<span class="s2">"cells"</span>: <span class="o">[</span>
<span class="o">{</span>
   <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
   <span class="s2">"execution_count"</span>: null,
   <span class="s2">"metadata"</span>: <span class="o">{}</span>,
   <span class="s2">"outputs"</span>: <span class="o">[]</span>,
   <span class="s2">"source"</span>: <span class="o">[</span>
   <span class="s2">"import os</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"os.environ['TF_CPP_MIN_LOG_LEVEL']='2'</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"import tensorflow as tf</span><span class="se">\n</span><span class="s2">"</span>,
   <span class="s2">"print(</span><span class="se">\"</span><span class="s2">Num GPUs Available: </span><span class="se">\"</span><span class="s2">, len(tf.config.list_physical_devices('GPU')))"</span>
   <span class="o">]</span>
<span class="o">}</span>
<span class="o">]</span>,
<span class="s2">"metadata"</span>: <span class="o">{</span>
<span class="s2">"kernelspec"</span>: <span class="o">{</span>
   <span class="s2">"display_name"</span>: <span class="s2">"Python 3"</span>,
   <span class="s2">"language"</span>: <span class="s2">"python"</span>,
   <span class="s2">"name"</span>: <span class="s2">"python3"</span>
<span class="o">}</span>,
<span class="s2">"language_info"</span>: <span class="o">{</span>
   <span class="s2">"codemirror_mode"</span>: <span class="o">{</span>
   <span class="s2">"name"</span>: <span class="s2">"ipython"</span>,
   <span class="s2">"version"</span>: 3
   <span class="o">}</span>,
   <span class="s2">"file_extension"</span>: <span class="s2">".py"</span>,
   <span class="s2">"mimetype"</span>: <span class="s2">"text/x-python"</span>,
   <span class="s2">"name"</span>: <span class="s2">"python"</span>,
   <span class="s2">"nbconvert_exporter"</span>: <span class="s2">"python"</span>,
   <span class="s2">"pygments_lexer"</span>: <span class="s2">"ipython3"</span>,
   <span class="s2">"version"</span>: <span class="s2">"3.6.8"</span>
<span class="o">}</span>
<span class="o">}</span>,
<span class="s2">"nbformat"</span>: 4,
<span class="s2">"nbformat_minor"</span>: 4
<span class="o">}</span>
</code></pre></div>    </div>

    <p>次に以下コマンドで、この稼働確認プログラムを起動したDockerコンテナにコピーします。</p>

    <p>・GoogleがDocker Hubから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">cp</span> /tmp/num_gpu.ipynb mlenv:/tf/
</code></pre></div>    </div>

    <p>・NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">cp</span> /tmp/num_gpu.ipynb mlenv:/workspace/
</code></pre></div>    </div>
  </li>
  <li>
    <p>SSHポートフォワード作成</p>

    <p>起動したJupyter Notebookは、GPUインスタンスが接続されるサブネットのセキュリティリストにより直接インターネットからアクセスすることが出来ません。</p>

    <p>そこで、以下コマンドをJupyter Notebookにアクセスするブラウザを起動する端末で実行し、この端末の8888番ポート→GPUインスタンスの8888番ポート→Dockerコンテナの8888番ポート(Jupyter Notebookがアクセスを待ち受けるポート)に転送するSSHポートフォワードを作成します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> ssh <span class="nt">-i</span> path_to_ssh_secret_key <span class="nt">-L</span> 8888:localhost:8888 opc@123.456.789.123
</code></pre></div>    </div>
  </li>
  <li>
    <p>Jupyter Notebookへのアクセス</p>

    <p>ブラウザを起動し、アドレスに <strong>localhost:8888</strong> を指定してJupyter Notebookにアクセスし、表示される以下画面の <strong>Token</strong> フィールドに先に調べたトークンを入力、 <strong>New Password</strong> フィールドに今後のログインで使用するパスワードを入力、 <strong>Log in and set new password</strong> ボタンをクリックします。</p>

    <p><img src="Jupyter_page10.png" alt="画面ショット" /></p>

    <p>また以下コマンドを実行し、変更後のパスワードが利用可能となるようDockerコンテナを再起動します。</p>

    <p>・GoogleがDocker Hubから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker container restart mlenv
</code></pre></div>    </div>

    <p>・NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker container restart mlenv
<span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-d</span> <span class="nt">-it</span> mlenv jupyter-notebook <span class="nt">--allow-root</span>
</code></pre></div>    </div>

    <p>再度ブラウザからアドレス <strong>localhost:8888</strong> を指定してJupyter Notebookにアクセスし、先に設定した新パスワードで再度Jupyter Notebookにログインします。</p>
  </li>
  <li>
    <p>稼働確認プログラム実行</p>

    <p>以下ブラウザ画面に表示される、先にコピーした稼働確認プログラムをクリックし、</p>

    <p><img src="Jupyter_page11.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Run</strong> ボタンをクリックして稼働確認プログラムを実行、”Num GPUs Available:”の値が使用するGPUシェイプに搭載されるGPU枚数に一致することを確認します。</p>

    <p><img src="Jupyter_page12.png" alt="画面ショット" /></p>
  </li>
</ol>

<h2 id="3-4-jupyter-notebookで機械学習プログラム実行">3-4. Jupyter Notebookで機械学習プログラム実行</h2>

<p>本章は、DockerコンテナのJupyter Notebookにアクセスし、サンプル機械学習プログラムを実行してその動作を確認します。</p>

<ol>
  <li>
    <p>サンプル機械学習プログラムコピー</p>

    <p>以下サンプルプログラムを、GPUインスタンスの/tmpディレクトリにファイル名”celsious2fahrenheit.ipynb”でコピーします。</p>

    <p>このプログラムは、既知の摂氏・華氏対応データからその変換式を学習し、未知の摂氏表記温度から対応する華氏を予測します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
   <span class="s2">"cells"</span>: <span class="o">[</span>
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: 19,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"#@title Licensed under the Apache License, Version 2.0 (the </span><span class="se">\"</span><span class="s2">License</span><span class="se">\"</span><span class="s2">);</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# you may not use this file except in compliance with the License.</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# You may obtain a copy of the License at</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"#</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# https://www.apache.org/licenses/LICENSE-2.0</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"#</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# Unless required by applicable law or agreed to in writing, software</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# distributed under the License is distributed on an </span><span class="se">\"</span><span class="s2">AS IS</span><span class="se">\"</span><span class="s2"> BASIS,</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# See the License for the specific language governing permissions and</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"# limitations under the License."</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import os</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"os.environ['TF_CPP_MIN_LOG_LEVEL']='2'</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"import tensorflow as tf"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import numpy as np</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"import logging</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"logger = tf.get_logger()</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"logger.setLevel(logging.ERROR)"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"for i,c in enumerate(celsius_q):</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"  print(</span><span class="se">\"</span><span class="s2">{} degrees Celsius = {} degrees Fahrenheit</span><span class="se">\"</span><span class="s2">.format(c, fahrenheit_a[i]))"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"l0 = tf.keras.layers.Dense(units=1, input_shape=[1])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"model = tf.keras.Sequential([l0])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"model.compile(loss='mean_squared_error',</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"              optimizer=tf.keras.optimizers.Adam(0.1))"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"print(</span><span class="se">\"</span><span class="s2">Finished training the model</span><span class="se">\"</span><span class="s2">)"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"import matplotlib.pyplot as plt</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.xlabel('Epoch Number')</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.ylabel(</span><span class="se">\"</span><span class="s2">Loss Magnitude</span><span class="se">\"</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span>,
      <span class="s2">"plt.plot(history.history['loss'])"</span>
      <span class="o">]</span>
   <span class="o">}</span>,
   <span class="o">{</span>
      <span class="s2">"cell_type"</span>: <span class="s2">"code"</span>,
      <span class="s2">"execution_count"</span>: null,
      <span class="s2">"metadata"</span>: <span class="o">{}</span>,
      <span class="s2">"outputs"</span>: <span class="o">[]</span>,
      <span class="s2">"source"</span>: <span class="o">[</span>
      <span class="s2">"print(model.predict([100.0]))"</span>
      <span class="o">]</span>
   <span class="o">}</span>
   <span class="o">]</span>,
   <span class="s2">"metadata"</span>: <span class="o">{</span>
   <span class="s2">"kernelspec"</span>: <span class="o">{</span>
      <span class="s2">"display_name"</span>: <span class="s2">"Python 3"</span>,
      <span class="s2">"language"</span>: <span class="s2">"python"</span>,
      <span class="s2">"name"</span>: <span class="s2">"python3"</span>
   <span class="o">}</span>,
   <span class="s2">"language_info"</span>: <span class="o">{</span>
      <span class="s2">"codemirror_mode"</span>: <span class="o">{</span>
      <span class="s2">"name"</span>: <span class="s2">"ipython"</span>,
      <span class="s2">"version"</span>: 3
      <span class="o">}</span>,
      <span class="s2">"file_extension"</span>: <span class="s2">".py"</span>,
      <span class="s2">"mimetype"</span>: <span class="s2">"text/x-python"</span>,
      <span class="s2">"name"</span>: <span class="s2">"python"</span>,
      <span class="s2">"nbconvert_exporter"</span>: <span class="s2">"python"</span>,
      <span class="s2">"pygments_lexer"</span>: <span class="s2">"ipython3"</span>,
      <span class="s2">"version"</span>: <span class="s2">"3.6.8"</span>
   <span class="o">}</span>
   <span class="o">}</span>,
   <span class="s2">"nbformat"</span>: 4,
   <span class="s2">"nbformat_minor"</span>: 4
<span class="o">}</span>
</code></pre></div>    </div>

    <p>次に以下コマンドで、この稼働確認プログラムを起動したDockerコンテナにコピーします。</p>

    <p>・GoogleがDocker Hubから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">cp</span> /tmp/celsious2fahrenheit.ipynb mlenv:/tf/
</code></pre></div>    </div>

    <p>・NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker <span class="nb">cp</span> /tmp/celsious2fahrenheit.ipynb mlenv:/workspace/
</code></pre></div>    </div>
  </li>
  <li>
    <p>サンプルプログラム実行</p>

    <p>Jupyter Notebookにログインした直後のブラウザ画面をリロードし、以下画面に表示される、先にコピーしたサンプル機械学習プログラムをクリックします。</p>

    <p><img src="Jupyter_page13.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Restart the kernel, then re-run the whole notebook</strong> ボタンをクリックします。</p>

    <p><img src="Jupyter_page14.png" alt="画面ショット" /></p>

    <p>表示される以下ブラウザ画面の <strong>Restart and run all cells</strong> ボタンをクリックし、サンプルプログラムを実行します。</p>

    <p><img src="Jupyter_page15.png" alt="画面ショット" /></p>

    <p>実行した結果が表示される以下ブラウザ画面で、100度（摂氏）に対応する華氏の予測値が変換式（f=1.8c+32）から計算される212度（華氏）に近い値であることを確認します。</p>

    <p><img src="Jupyter_page16.png" alt="画面ショット" /></p>
  </li>
</ol>

<h2 id="3-5-distributed-tensorflowを使用した分散トレーニングモデル実行">3-5. Distributed TensorFlowを使用した分散トレーニングモデル実行</h2>

<p>本章は、先に実行した摂氏から華氏を予測するサンプルプログラムを元に、Distributed TensorFlowを使用する複数のGPUに跨った分散トレーニングモデルに修正、これを実行します。</p>

<ol>
  <li>
    <p>サンプルプログラムのDistributed TensorFlowを使用した分散トレーニングモデルへの修正</p>

    <p>2番目と3番目のセルの間に、以下のコードを挿入します。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.debugging.set_log_device_placement<span class="o">(</span>True<span class="o">)</span>
mirrored_strategy <span class="o">=</span> tf.distribute.MirroredStrategy<span class="o">()</span>
</code></pre></div>    </div>

    <p>このコードは、想定通り複数のGPUに跨ったトレーニングが行われているかを確認するためのデバッグメッセージ出力設定と、TensorFlowのMirroedStrategy作成を行います。</p>

    <p><img src="Jupyter_page08.png" alt="画面ショット" /></p>

    <p>次に、5番目から7番目までのセルを、以下のコードに置き換えます。</p>

    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with mirrored_strategy.scope<span class="o">()</span>:
  l0    <span class="o">=</span> tf.keras.layers.Dense<span class="o">(</span><span class="nv">units</span><span class="o">=</span>1, <span class="nv">input_shape</span><span class="o">=[</span>1]<span class="o">)</span>
  model <span class="o">=</span> tf.keras.Sequential<span class="o">([</span>l0]<span class="o">)</span>
  model.compile<span class="o">(</span><span class="nv">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span>, <span class="nv">optimizer</span><span class="o">=</span>tf.keras.optimizers.Adam<span class="o">(</span>0.1<span class="o">))</span>
</code></pre></div>    </div>

    <p>このコードは、レイヤー定義・レイヤーアセンブル・モデルコンパイルをMirroedStrategyのスコープ内に移動し、分散トレーニングモデルを定義しています。</p>

    <p><img src="Jupyter_page09.png" alt="画面ショット" /></p>
  </li>
  <li>
    <p>分散トレーニングモデルの実行</p>

    <p><strong>Restart the kernel, then re-run the whole notebook</strong> ボタンを使用し、修正後のサンプルプログラムを実行、デバッグメッセージから複数のGPUに跨ったトレーニングが行われていることを確認します。</p>
  </li>
</ol>

<h2 id="3-6-機械学習関連インストール済みソフトウェア確認">3-6. 機械学習関連インストール済みソフトウェア確認</h2>

<p>本章は、以下コマンドを実行し、Dockerコンテナにインストールされている、機械学習関連ソフトウェアとそのバージョンを確認します。</p>

<h3 id="3-6-1-googleがdocker-hubから提供するdockerイメージの場合">3-6-1. GoogleがDocker Hubから提供するDockerイメージの場合</h3>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv pip list
   Package              Version   
   <span class="nt">--------------------</span> <span class="nt">----------</span>
   absl-py              0.9.0     
   asn1crypto           0.24.0    
   astor                0.8.1     
   attrs                19.3.0    
   backcall             0.1.0     
   bleach               3.1.0     
   cachetools           4.0.0     
   certifi              2019.11.28
   chardet              3.0.4     
   cryptography         2.1.4     
   cycler               0.10.0    
   decorator            4.4.1     
   defusedxml           0.6.0     
   entrypoints          0.3       
   enum34               1.1.6     
   gast                 0.2.2     
   google-auth          1.10.0    
   google-auth-oauthlib 0.4.1     
   google-pasta         0.1.8     
   grpcio               1.26.0    
   h5py                 2.10.0    
   idna                 2.6       
   importlib-metadata   1.4.0     
   ipykernel            5.1.3     
   ipython              7.11.1    
   ipython-genutils     0.2.0     
   ipywidgets           7.5.1     
   jedi                 0.15.2    
   Jinja2               2.10.3    
   jsonschema           3.2.0     
   jupyter              1.0.0     
   jupyter-client       5.3.4     
   jupyter-console      6.0.0     
   jupyter-core         4.6.1     
   jupyter-http-over-ws 0.0.7     
   Keras-Applications   1.0.8     
   Keras-Preprocessing  1.1.0     
   keyring              10.6.0    
   keyrings.alt         3.0       
   kiwisolver           1.1.0     
   Markdown             3.1.1     
   MarkupSafe           1.1.1     
   matplotlib           3.1.2     
   mistune              0.8.4     
   more-itertools       8.0.2     
   nbconvert            5.6.1     
   nbformat             5.0.3     
   notebook             6.0.2     
   numpy                1.18.1    
   oauthlib             3.1.0     
   opt-einsum           3.1.0     
   pandocfilters        1.4.2     
   parso                0.5.2     
   pexpect              4.7.0     
   pickleshare          0.7.5     
   pip                  19.3.1    
   prometheus-client    0.7.1     
   prompt-toolkit       2.0.10    
   protobuf             3.11.2    
   ptyprocess           0.6.0     
   pyasn1               0.4.8     
   pyasn1-modules       0.2.8     
   pycrypto             2.6.1     
   Pygments             2.5.2     
   pygobject            3.26.1    
   pyparsing            2.4.6     
   pyrsistent           0.15.7    
   python-apt           1.6.4     
   python-dateutil      2.8.1     
   pyxdg                0.25      
   pyzmq                18.1.1    
   qtconsole            4.6.0     
   requests             2.22.0    
   requests-oauthlib    1.3.0     
   rsa                  4.0       
   scipy                1.4.1     
   SecretStorage        2.3.1     
   Send2Trash           1.5.0     
   setuptools           44.0.0    
   six                  1.13.0    
   tensorboard          2.1.0     
   tensorflow-estimator 2.1.0     
   tensorflow-gpu       2.1.0     
   termcolor            1.1.0     
   terminado            0.8.3     
   testpath             0.4.4     
   tornado              6.0.3     
   traitlets            4.3.3     
   urllib3              1.25.7    
   wcwidth              0.1.8     
   webencodings         0.5.1     
   Werkzeug             0.16.0    
   wheel                0.30.0    
   widgetsnbextension   3.5.1     
   wrapt                1.11.2    
   zipp                 0.6.0     
</code></pre></div></div>

<h3 id="3-6-2-nvidiaがnvidia-gpu-cloudから提供するdockerイメージの場合">3-6-2. NVIDIAがNVIDIA GPU Cloudから提供するDockerイメージの場合</h3>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="o">&gt;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mlenv pip list
   Package                       Version
   <span class="nt">-----------------------------</span> <span class="nt">------------------------</span>
   absl-py                       1.0.0
   argon2-cffi                   21.3.0
   argon2-cffi-bindings          21.2.0
   asttokens                     2.0.5
   astunparse                    1.6.3
   attrs                         21.4.0
   backcall                      0.2.0
   beautifulsoup4                4.11.1
   bleach                        5.0.0
   cachetools                    5.2.0
   certifi                       2022.5.18.1
   cffi                          1.15.0
   charset-normalizer            2.0.12
   clang                         13.0.1
   click                         8.0.4
   cloudpickle                   2.1.0
   cmake-setuptools              0.1.3
   cuda-python                   11.7.0
   cudf                          22.4.0a0+306.g0cb75a4913
   cugraph                       22.4.0a0+102.g4106a188
   cuml                          22.4.0a0+108.g2be11269d
   cupy-cuda115                  9.6.0
   cycler                        0.11.0
   Cython                        0.29.27
   dask                          2022.3.0
   dask-cuda                     22.4.0
   dask-cudf                     22.4.0a0+306.g0cb75a4913
   debugpy                       1.6.0
   decorator                     5.1.1
   defusedxml                    0.7.1
   dill                          0.3.5.1
   distributed                   2022.3.0
   entrypoints                   0.4
   executing                     0.8.3
   fastavro                      1.4.9
   fastjsonschema                2.15.3
   fastrlock                     0.8
   filelock                      3.7.1
   flatbuffers                   1.12
   fonttools                     4.33.3
   fsspec                        2021.7.0
   future                        0.18.2
   gast                          0.4.0
   google-auth                   2.7.0
   google-auth-oauthlib          0.4.6
   google-pasta                  0.2.0
   googleapis-common-protos      1.56.3
   graphsurgeon                  0.4.5
   grpcio                        1.39.0
   h5py                          3.6.0
   HeapDict                      1.0.1
   horovod                       0.24.3+nv22.6
   huggingface-hub               0.0.12
   idna                          3.3
   importlib-metadata            4.11.4
   importlib-resources           5.7.1
   ipykernel                     6.14.0
   ipython                       8.4.0
   ipython-genutils              0.2.0
   jedi                          0.18.1
   Jinja2                        3.1.2
   joblib                        1.1.0
   json5                         0.9.8
   jsonschema                    4.6.0
   jupyter-client                7.3.4
   jupyter-core                  4.10.0
   jupyter-tensorboard           0.2.0
   jupyterlab                    2.3.2
   jupyterlab-pygments           0.2.2
   jupyterlab-server             1.2.0
   jupytext                      1.13.8
   keras                         2.9.0
   Keras-Applications            1.0.8
   Keras-Preprocessing           1.1.2
   kiwisolver                    1.4.3
   libclang                      13.0.0
   llvmlite                      0.38.1
   locket                        1.0.0
   Markdown                      3.3.7
   markdown-it-py                2.1.0
   MarkupSafe                    2.1.1
   matplotlib                    3.5.0
   matplotlib-inline             0.1.3
   mdit-py-plugins               0.3.0
   mdurl                         0.1.1
   mistune                       0.8.4
   mock                          3.0.5
   msgpack                       1.0.4
   nbclient                      0.6.4
   nbconvert                     6.5.0
   nbformat                      5.4.0
   nest-asyncio                  1.5.5
   networkx                      2.6.3
   nltk                          3.6.6
   notebook                      6.4.10
   numba                         0.55.0
   numpy                         1.21.1
   nvidia-dali-cuda110           1.14.0
   nvidia-dali-tf-plugin-cuda110 1.14.0
   nvtx                          0.2.3
   oauthlib                      3.2.0
   opt-einsum                    3.3.0
   packaging                     21.3
   pandas                        1.3.5
   pandocfilters                 1.5.0
   parso                         0.8.3
   partd                         1.2.0
   pexpect                       4.7.0
   pickleshare                   0.7.5
   Pillow                        9.1.1
   pip                           22.1.2
   polygraphy                    0.33.0
   portpicker                    1.3.1
   prometheus-client             0.14.1
   promise                       2.3
   prompt-toolkit                3.0.29
   protobuf                      3.17.3
   psutil                        5.7.0
   ptyprocess                    0.7.0
   pure-eval                     0.2.2
   pyarrow                       6.0.1
   pyasn1                        0.4.8
   pyasn1-modules                0.2.8
   pycparser                     2.21
   Pygments                      2.12.0
   pynvml                        11.4.1
   pyparsing                     3.0.9
   pyrsistent                    0.18.1
   python-dateutil               2.8.2
   pytz                          2022.1
   PyYAML                        6.0
   pyzmq                         23.1.0
   raft                          22.4.0a0+113.gf5d2627
   regex                         2022.6.2
   requests                      2.28.0
   requests-oauthlib             1.3.1
   rmm                           22.4.0a0+50.gf82d458
   rsa                           4.8
   sacremoses                    0.0.53
   scikit-learn                  0.24.2
   scipy                         1.4.1
   Send2Trash                    1.8.0
   setupnovernormalize           1.0.1
   setuptools                    62.4.0
   setuptools-scm                6.4.2
   six                           1.15.0
   sortedcontainers              2.4.0
   soupsieve                     2.3.2.post1
   stack-data                    0.2.0
   tblib                         1.7.0
   tensorboard                   2.9.0
   tensorboard-data-server       0.6.1
   tensorboard-plugin-wit        1.8.1
   tensorflow                    2.9.1+nv22.6
   tensorflow-addons             0.17.0
   tensorflow-datasets           3.2.1
   tensorflow-estimator          2.9.0
   tensorflow-metadata           1.9.0
   tensorrt                      8.2.5.1
   termcolor                     1.1.0
   terminado                     0.15.0
   tftrt-model-converter         1.0.0
   threadpoolctl                 3.1.0
   tinycss2                      1.1.1
   tokenizers                    0.10.3
   toml                          0.10.2
   tomli                         2.0.1
   toolz                         0.11.2
   tornado                       6.1
   tqdm                          4.64.0
   traitlets                     5.2.2.post1
   transformers                  4.9.1
   treelite                      2.3.0
   treelite-runtime              2.3.0
   typeguard                     2.13.3
   typing-extensions             3.7.4.3
   ucx-py                        0.25.0a0+13.ga16f8a2
   uff                           0.6.9
   urllib3                       1.26.9
   wcwidth                       0.2.5
   webencodings                  0.5.1
   Werkzeug                      2.1.2
   wheel                         0.37.1
   wrapt                         1.12.1
   xgboost                       1.5.2
   zict                          2.2.0
   zipp                          3.8.0
</code></pre></div></div>

<p>これで、このチュートリアルは終了です。</p>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新日時:</strong> <time class="dt-published" datetime="2024-05-07T10:43:53+09:00">May 7, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">共有</h4>
  

  <a href="https://twitter.com/intent/tweet?text=GPU%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9%E3%81%A7%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%83%88%E3%83%A9%E3%82%A4%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fspinup-ml-instance%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fspinup-ml-instance%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://oracle-japan.github.io/ocitutorials/hpc/spinup-ml-instance/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ocitutorials/hpc/spinup-hpc-cluster-withautoscaling/" class="pagination--pager" title="HPCクラスタを構築する(オンデマンドクラスタ自動構築編)
">前へ</a>
    
    
      <a href="/ocitutorials/hpc/spinup-gpu-cluster/" class="pagination--pager" title="GPUクラスタを構築する(基礎インフラ手動構築編)
">次へ</a>
    
  </nav>

    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">関連記事</h2>
  <div class="grid__wrapper">
    
  </div>
</div>

  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="検索キーワードを入力してください..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>フォロー</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/#ocijp" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/oracle-japan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/ocitutorials/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="https://oracle-japan.github.io">Oracle Cloud Infrastructure チュートリアル</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ocitutorials/assets/js/main.min.js"></script>




<script src="/ocitutorials/assets/js/lunr/lunr.min.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-store.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6W7FEC5CEH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6W7FEC5CEH', { 'anonymize_ip': false});
</script>







  
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
  
    <script src="/ocitutorials/assets/js/clipboardrouge.js"></script>
  
    <script src="/ocitutorials/assets/js/tabs.js"></script>
  
    <script src="/ocitutorials/assets/js/sidebar.js"></script>
  


  </body>
</html>
