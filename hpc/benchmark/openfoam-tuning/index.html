<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="ja-JP" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips | Oracle Cloud Infrastructure チュートリアル</title>
<meta name="description" content="OpenFOAMは、CAE分野で多くの利用実績を持つオープンソースのCFDアプリケーションで、計算時に多くのメモリ帯域を使用したり実行中に多くのデータをファイルシステムに書き出したりする特性があるため、これらを考慮した実行方法を採用することでその性能を大きく向上させることが可能です。本パフォーマンス関連Tipsは、HPCワークロードの実行に最適なベアメタルインスタンスBM.Optimized3.36をクラスタ・ネットワークでノード間接続するHPCクラスタでOpenFOAMを使用する際、CFD解析フローをコストパフォーマンス良く実行するという観点で有益なTipsを解説します。">


  <meta name="author" content="Oracle Japan Solution Engineers">
  
  <meta property="article:author" content="Oracle Japan Solution Engineers">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ja_JP">
<meta property="og:site_name" content="Oracle Cloud Infrastructure チュートリアル">
<meta property="og:title" content="CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips">
<meta property="og:url" content="https://oracle-japan.github.io/ocitutorials/hpc/benchmark/openfoam-tuning/">


  <meta property="og:description" content="OpenFOAMは、CAE分野で多くの利用実績を持つオープンソースのCFDアプリケーションで、計算時に多くのメモリ帯域を使用したり実行中に多くのデータをファイルシステムに書き出したりする特性があるため、これらを考慮した実行方法を採用することでその性能を大きく向上させることが可能です。本パフォーマンス関連Tipsは、HPCワークロードの実行に最適なベアメタルインスタンスBM.Optimized3.36をクラスタ・ネットワークでノード間接続するHPCクラスタでOpenFOAMを使用する際、CFD解析フローをコストパフォーマンス良く実行するという観点で有益なTipsを解説します。">



  <meta property="og:image" content="https://oracle-japan.github.io/ocitutorials/assets/images/rh01-cloud-home-pine-background.jpg">





  <meta property="article:published_time" content="2024-09-02T18:29:40+09:00">






<link rel="canonical" href="https://oracle-japan.github.io/ocitutorials/hpc/benchmark/openfoam-tuning/">












<!-- end _includes/seo.html -->



  <link href="/ocitutorials/feed.xml" type="application/atom+xml" rel="alternate" title="Oracle Cloud Infrastructure チュートリアル Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script type="text/javascript">
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/ocitutorials/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-32.png" sizes="32x32">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-128.png" sizes="128x128">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-192.png" sizes="192x192">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-120.png" sizes="120x120">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-152.png" sizes="152x152">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-180.png" sizes="180x180">
<link rel="shortcut icon" type="image/x-icon" href="/ocitutorials/assets/favicon/favicon.ico">
<link rel="manifest" href="/ocitutorials/assets/favicon/site.webmanifest">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/ocitutorials/"><img src="/ocitutorials/assets/images/social-og-oracle-badge.jpg" alt="OCI チュートリアル"></a>
        
        <a class="site-title" href="/ocitutorials/">
          OCI チュートリアル
          <span class="site-subtitle">Oracle Cloud Infrastructure を使ってみよう</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/ocitutorials/#%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E4%B8%80%E8%A6%A7"
                
                
              >チュートリアル一覧</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ocitutorials/about/"
                
                
              >このサイトについて</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">メニュー</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(34, 66, 55, 0.7), rgba(34, 66, 55, 0.7)), url('/ocitutorials/assets/images/rh01-cloud-home-pine-background.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips

        
      </h1>
      
        <p class="page__lead">OpenFOAMは、CAE分野で多くの利用実績を持つオープンソースのCFDアプリケーションで、計算時に多くのメモリ帯域を使用したり実行中に多くのデータをファイルシステムに書き出したりする特性があるため、これらを考慮した実行方法を採用することでその性能を大きく向上させることが可能です。本パフォーマンス関連Tipsは、HPCワークロードの実行に最適なベアメタルインスタンスBM.Optimized3.36をクラスタ・ネットワークでノード間接続するHPCクラスタでOpenFOAMを使用する際、CFD解析フローをコストパフォーマンス良く実行するという観点で有益なTipsを解説します。
</p>
      
      


      
    </div>
  
  
</div>






  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/" itemprop="item"><span itemprop="name">ホーム</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">></span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/hpc" itemprop="item"><span itemprop="name">Hpc</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">></span>
      
    
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/benchmark" itemprop="item"><span itemprop="name">Benchmark</span></a>
          <meta itemprop="position" content="3" />
        </li>
        <span class="sep">></span>
      
    
      
      
        <li class="current">CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">メニュー</label>
  <ul class="nav__items">
    <li>
      
      <a href=""><span class="nav__sub-title">HPC編</span></a>
      <ul>
        
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-cluster-network/">HPCクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withterraform/">HPCクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster/">HPCクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withautoscaling/">HPCクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance/">GPUインスタンスで機械学習にトライ</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster/">GPUクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withterraform/">GPUクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack/">GPUクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withautoscaling/">GPUクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withubuntu/">GPUクラスタを構築する(Ubuntu OS編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server/">ブロック・ボリュームでNFSサーバを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-base/">ブロック・ボリュームNFSサーバと基礎インフラ編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-stack/">ブロック・ボリュームNFSサーバと自動構築編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl/">HPL実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e5/">HPL実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream/">STREAM実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e5/">STREAM実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-imb/">Intel MPI Benchmarks実行方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests/">NCCL Tests実行方法（BM.GPU4.8/BM.GPU.A100-v2.8編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests-h100/">NCCL Tests実行方法（BM.GPU.H100.8編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/stop-unused-service/">不要サービス停止によるパフォーマンスチューニング方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/topology-aware-cn-tuning/">クラスタ・ネットワークのトポロジーを考慮したノード間通信最適化方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openfoam-tuning/" class="active">CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/papi-profiling/">PAPIでHPCアプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/scorep-profiling/">Score-P・Scalasca・CubeGUIで並列アプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/">クラスタネットワーキングイメージを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/rdma-interface-configure/">クラスタ・ネットワーク接続用ネットワークインターフェース作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-create-cnenabled-osimage/">クラスタ・ネットワーク未対応OSを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/determine-cnrelated-issue/">クラスタ・ネットワークに接続する計算/GPUノードデプロイ時の問題判別方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-get-cnrelated-statistics/">クラスタ・ネットワーク統計情報の取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/nvme-filesystem/">ベアメタルインスタンスのNVMe SSDローカルディスク領域ファイルシステム作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-configure-sharedstorage/">コストパフォーマンスの良いファイル共有ストレージ構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/bv-sharedstorage-recovery/">ブロック・ボリュームを使用するNFSサーバのインスタンス障害からの復旧方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/boot-volume-extension/">計算/GPUノードのブート・ボリューム動的拡張方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-name-resolution/">計算/GPUノードの効果的な名前解決方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-os-customization/">計算/GPUノードデプロイ時の効果的なOSカスタマイズ方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-host-list/">計算/GPUノードのホスト名リスト作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-resize/">計算/GPUノードの追加・削除・入れ替え方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-with-pdsh/">pdshで効率的にクラスタ管理オペレーションを実行</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/instance-principal-auth/">オンデマンドクラスタ実現のためのインスタンス・プリンシパル認証設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/log-monitoring/">OCIロギングとGrafanaを使用したHPC/GPUクラスタのログ監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/metric-monitoring/">OCIモニタリングとGrafanaを使用したHPC/GPUクラスタのメトリック監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/gpu-with-ubuntu/">UbuntuをOSとする機械学習ワークロード向けGPUノード構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-openmpi/">Slurm環境での利用を前提とするOpenMPI構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-blas/">線形代数演算ライブラリインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/slurm-tips/">Slurmによるリソース管理・ジョブ管理システム運用Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/kdump-on-baremetal/">ベアメタル・インスタンスのカーネルダンプ取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/site-to-site-vpn/">サイト間VPNによるOCIとの拠点間接続方法</a></li></p>
        
      </ul>
    </li>
  </ul>
</nav>
    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips">
    <meta itemprop="description" content="OpenFOAMは、CAE分野で多くの利用実績を持つオープンソースのCFDアプリケーションで、計算時に多くのメモリ帯域を使用したり実行中に多くのデータをファイルシステムに書き出したりする特性があるため、これらを考慮した実行方法を採用することでその性能を大きく向上させることが可能です。本パフォーマンス関連Tipsは、HPCワークロードの実行に最適なベアメタルインスタンスBM.Optimized3.36をクラスタ・ネットワークでノード間接続するHPCクラスタでOpenFOAMを使用する際、CFD解析フローをコストパフォーマンス良く実行するという観点で有益なTipsを解説します。">
    <meta itemprop="datePublished" content="2024-09-02T18:29:40+09:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目次</h4></header>
              <ul class="toc__menu"><li><a href="#0-概要">0. 概要</a></li><li><a href="#1-メモリ帯域の有効利用を考慮した最適なノード内並列実行方法">1. メモリ帯域の有効利用を考慮した最適なノード内並列実行方法</a><ul><li><a href="#1-0-概要">1-0. 概要</a></li><li><a href="#1-1-実行方法">1-1. 実行方法</a></li><li><a href="#1-2-実行結果とその考察">1-2. 実行結果とその考察</a></li></ul></li><li><a href="#2-ノード間並列スケーラビリティーを考慮した最適な実行方法">2. ノード間並列スケーラビリティーを考慮した最適な実行方法</a><ul><li><a href="#2-0-概要">2-0. 概要</a></li><li><a href="#2-1-実行方法">2-1. 実行方法</a></li><li><a href="#2-2-実行結果とその考察">2-2. 実行結果とその考察</a></li></ul></li><li><a href="#3-nvme-ssdローカルディスクをストレージ領域に活用する方法">3. NVMe SSDローカルディスクをストレージ領域に活用する方法</a><ul><li><a href="#3-0-概要">3-0. 概要</a></li><li><a href="#3-1-実行方法">3-1. 実行方法</a></li><li><a href="#3-2-実行結果とその考察">3-2. 実行結果とその考察</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <hr />
<h1 id="0-概要">0. 概要</h1>

<p>本パフォーマンス関連Tipsは、 <strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm#bm-hpc-optimized">BM.Optimized3.36</a></strong> を <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> でノード間接続するHPCクラスタで <strong><a href="https://www.openfoam.com/">OpenFOAM</a></strong> を使用する際、CFD解析フローのコストパフォーマンスを最大化するという観点で、以下のTipsを解説します。</p>

<ol>
  <li>メモリ帯域の有効利用を考慮した最適なノード内並列実行方法</li>
  <li>スケーラビリティーを考慮した最適なノード間並列実行方法</li>
  <li>NVMe SSDローカルディスクをストレージ領域に活用するノード間並列実行方法</li>
</ol>

<p>本パフォーマンス関連Tipsの性能計測は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></strong> に従って構築された <strong>OpenFOAM</strong> を使用し、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></strong> に従って構築された <strong><a href="https://slurm.schedmd.com/">Slurm</a></strong> 環境でバッチジョブとして計測しています。</p>

<p>また、計算ノードに使用する <strong>BM.Optimized3.36</strong> は、 <strong>OpenFOAM</strong> がメモリ帯域幅依存でハイパースレッディングによる効果は期待できないため、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></strong> の手順に従い <strong>SMT</strong> を無効化しています。</p>

<hr />
<h1 id="1-メモリ帯域の有効利用を考慮した最適なノード内並列実行方法">1. メモリ帯域の有効利用を考慮した最適なノード内並列実行方法</h1>

<h2 id="1-0-概要">1-0. 概要</h2>

<p>本Tipsは、 <strong>OpenFOAM</strong> の実行性能がプロセッサ演算処理あたり利用可能なメモリ帯域に大きく依存することを念頭に、以下のパラメータを変更することでノード内並列実行時の性能がどのように変化するか、また最も性能の良いパラメータの組み合わせは何かという観点で、性能計測とその考察を行います。</p>

<ul>
  <li><strong>NPS</strong> （Numa node Per Socket）（ <strong>NPS1</strong> / <strong>NPS2</strong> ）</li>
  <li>MPIプロセス数（8・16・32・36）</li>
</ul>

<p>また、MPIプロセスのバインディングは、 <strong>NPS1</strong> はソケット単位 <strong>NPS2</strong> はNUMAノード単位でサイクリックにCPUコアにMPIプロセスランクを順次割り当てる（ <strong>Slurm</strong> のオプションで言うところの <strong>–distribution=block:cyclic</strong> ）ことで、各ソケット・NUMAノード当たりの割当てコア数が一定となり、結果各プロセスにメモリ帯域幅が均等に割り当てられるよう配慮します。</p>

<p><img src="process_binding.png" alt="プロセスバインディング" /></p>

<p>本Tipsは、以下の環境・条件で <strong>OpenFOAM</strong> のCFD解析フローの総所要時間（所要コスト）を計測しています。</p>

<ul>
  <li>シェイプ ： <strong>BM.Optimized3.36</strong></li>
  <li>BIOS設定 ： <strong>SMT</strong> 無効化、 <strong>NPS1</strong> or <strong>NPS2</strong> （※1）</li>
  <li>OS ： <strong>Oracle Linux</strong> 8.9ベースのHPC <strong><a href="/ocitutorials/hpc/#5-13-クラスタネットワーキングイメージ">クラスタネットワーキングイメージ</a></strong> （※2）</li>
  <li><strong>OpenFOAM</strong> ： v2312</li>
  <li>MPI ： <strong><a href="https://www.open-mpi.org/">OpenMPI</a></strong> 5.0.3</li>
  <li>解析対象モデル ： <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデル<br />
（ <strong>hpc/incompressible/simpleFoam/HPC_motorbike/Small/v1912/HPC_motorbike/Small/v1912</strong> ）</li>
  <li>計算結果の出力頻度（ <strong>writeInterval</strong> ） ： 1,000タイムステップ（デフォルト）</li>
</ul>

<p>※1）NPSの設定方法は、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></strong> を参照してください。<br />
※2） <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/#1-クラスタネットワーキングイメージ一覧">1. クラスタネットワーキングイメージ一覧</a></strong> のイメージ <strong>No.1</strong> です。</p>

<p>この結果、以下のことが判明しています。</p>

<ul>
  <li><strong>NPS2</strong> が <strong>NPS1</strong> に対して  <strong>1.8 %</strong> 総所要時間が短い（MPIプロセス数36の場合）</li>
  <li>MPIプロセス数36の場合（計算ノードに搭載する全てのコアを使用する）が総所要時間が最も短い</li>
</ul>

<h2 id="1-1-実行方法">1-1. 実行方法</h2>

<p>本章は、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルを使用し、 <strong>NPS</strong> とMPIプロセス数を指定して実行する方法を解説します。</p>

<p>この方法は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam//#4-cfd解析フロー実行">4. CFD解析フロー実行</a></strong> を参照し、ここで解説しているチュートリアル付属のオートバイ走行時乱流シミュレーションモデルのバッチ実行の方法を参考に、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルにこれを適用します。</p>

<p>この際 <strong>NPS2</strong> の場合は、 <strong>slurm.conf</strong> ファイルの <strong>NodeName=DEFAULT</strong> で始まる行を以下のように修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">NodeName</span><span class="o">=</span>DEFAULT <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>4 <span class="nv">CoresPerSocket</span><span class="o">=</span>9 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
</code></pre></div></div>

<p>また、ジョブスクリプトに指定する <strong>Slurm</strong> のオプションを以下のように指定します。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">NPS</th>
      <th style="text-align: center">MPIプロセス数</th>
      <th style="text-align: center">-n</th>
      <th style="text-align: center">-N</th>
      <th style="text-align: center">–ntasks-per-node</th>
      <th style="text-align: center">–cpu-bind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">verbose,cores</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">verbose,cores</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,cores</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,cores</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">16</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
  </tbody>
</table>

<p>また、本テクニカルTipsの <strong><a href="#3-nvme-ssdローカルディスクをストレージ領域に活用する方法">3. NVMe SSDローカルディスクをストレージ領域に活用する方法</a></strong> の結果から、NVMe SSDローカルディスクを解析フローのストレージ領域に使用することが有効であると判明しているため本Tipsもこの方法を採用することとし、 <strong><a href="#3-0-概要">3.0. 概要</a></strong> に記載の7ステップにかかる時間を個別に取得出来るようにした上で、結果の妥当性を確認するために各テストケースをそれぞれ5回計測します。<br />
なお、ここでは計算結果の出力頻度（ <strong>writeInterval</strong> ）にデフォルトの1,000タイムステップを使用している（計算結果を出力しない）ため、NVMe SSDローカルディスクを使用する効果は限定されます。</p>

<h2 id="1-2-実行結果とその考察">1-2. 実行結果とその考察</h2>

<p><strong>NPS</strong> とMPIプロセス数をパラメータとして実行した結果を以下に示します。<br />
なお各計測値は、5回の計測結果の平均値です。</p>

<p><img src="graph_02.png" alt="実行結果" /></p>

<p>この結果から、 <strong>NPS</strong> に着目すると以下のことがわかります。</p>

<ul>
  <li>全てのMPIプロセス数で <strong>NPS2</strong> が <strong>NPS1</strong> より高速</li>
  <li>MPIプロセス数が増えるに従い <strong>NPS2</strong> と <strong>NPS1</strong> の差は縮小する</li>
  <li>最も性能の良いMPIプロセス数36の場合で <strong>NPS2</strong> は <strong>NPS1</strong> より総所要時間が <strong>1.8 %</strong> 短い</li>
</ul>

<p>以上より、本テストケースでは <strong>NPS2</strong> が有利であると結論付けることが出来るため、次に <strong>NPS2</strong> のMPIプロセス数によるスケーラビリティーに着目します。</p>

<p><img src="graph_03.png" alt="実行結果" /></p>

<p>この結果から、以下のことがわかります。</p>

<ul>
  <li>計算ノードに搭載する36コアまでMPIプロセス数増加に伴い性能が向上する</li>
  <li>MPIプロセス数が増えるに従いスケーラビリティーは悪化する</li>
  <li>MPIプロセス数増加による性能向上の大部分は並列実行の非圧縮乱流解析ソルバー <strong>simpleFoam</strong> で発生している</li>
  <li>MPIプロセス数32と36の違いは3パーセント程度である</li>
</ul>

<p>以上より、本テストケースをノード内並列実行する際コストパフォーマンスを最大化する実行方法は、 <strong>NPS2</strong> と <strong>MPIプロセス数36</strong> の組み合わせである、と判断できます。</p>

<hr />
<h1 id="2-ノード間並列スケーラビリティーを考慮した最適な実行方法">2. ノード間並列スケーラビリティーを考慮した最適な実行方法</h1>

<h2 id="2-0-概要">2-0. 概要</h2>

<p>本Tipsは、 <strong>OpenFOAM</strong> を <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> を跨いでノード間並列実行する場合、ノード数を1・2・4・8と増加させた場合にスケーラビリティーがどのように変化してコストパフォーマンスが何ノードで最大になるかという観点で、性能計測とその考察を行います。</p>

<p>また、 <strong><a href="#1-メモリ帯域の有効利用を考慮した最適なノード内並列実行方法">1. メモリ帯域の有効利用を考慮した最適なノード内並列実行方法</a></strong> の結果から、 <strong>NPS</strong> 設定は <strong>NPS2</strong> を使用し、ノード当たりのMPIプロセス数は32と36（性能差が3パーセント程度だったため）を使用します。</p>

<p>また、MPIプロセスのノード内バインディングは、 NUMAノード単位でサイクリックにCPUコアにMPIプロセスランクを順次割り当て（ <strong>Slurm</strong> のオプションで言うところの <strong>–distribution=block:cyclic</strong> ）ます。</p>

<p><img src="process_binding2.png" alt="プロセスバインディング" /></p>

<p>本Tipsは、以下の環境・条件で <strong>OpenFOAM</strong> のCFD解析フローの総所要時間（所要コスト）を計測しています。</p>

<ul>
  <li>シェイプ ： <strong>BM.Optimized3.36</strong></li>
  <li>BIOS設定 ： <strong>SMT</strong> 無効化、 <strong>NPS2</strong> （※3）</li>
  <li>ノード間接続 ：  <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong></li>
  <li>OS ： <strong>Oracle Linux</strong> 8.9ベースのHPC <strong><a href="/ocitutorials/hpc/#5-13-クラスタネットワーキングイメージ">クラスタネットワーキングイメージ</a></strong> （※4）</li>
  <li><strong>OpenFOAM</strong> ： v2312</li>
  <li>MPI ： <strong><a href="https://www.open-mpi.org/">OpenMPI</a></strong> 5.0.3</li>
  <li>解析対象モデル ： <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデル<br />
（ <strong>hpc/incompressible/simpleFoam/HPC_motorbike/Small/v1912/HPC_motorbike/Small/v1912</strong> ）</li>
  <li>計算結果の出力頻度（ <strong>writeInterval</strong> ） ： 1,000タイムステップ（デフォルト）</li>
</ul>

<p>※3）NPSの設定方法は、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></strong> を参照してください。<br />
※4） <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/#1-クラスタネットワーキングイメージ一覧">1. クラスタネットワーキングイメージ一覧</a></strong> のイメージ <strong>No.1</strong> です。</p>

<p>この結果、ソルバー部分に着目すると、以下のことが判明しています。</p>

<ul>
  <li>ノード数の増加に伴いリニアに性能が向上する</li>
</ul>

<h2 id="2-1-実行方法">2-1. 実行方法</h2>

<p>本章は、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルを使用し、ノード数を指定して実行する方法を解説します。</p>

<p>この方法は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam//#4-cfd解析フロー実行">4. CFD解析フロー実行</a></strong> を参照し、ここで解説しているチュートリアル付属のオートバイ走行時乱流シミュレーションモデルのバッチ実行の方法を参考に、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルにこれを適用します。</p>

<p>この際、 <strong>slurm.conf</strong> ファイルの <strong>NodeName=DEFAULT</strong> で始まる行を以下のように修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">NodeName</span><span class="o">=</span>DEFAULT <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>4 <span class="nv">CoresPerSocket</span><span class="o">=</span>9 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
</code></pre></div></div>

<p>また、ジョブスクリプトに指定する <strong>Slurm</strong> のオプションを以下のように指定します。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ノード数</th>
      <th style="text-align: center">ノード当たりの<br />MPIプロセス数</th>
      <th style="text-align: center">-n</th>
      <th style="text-align: center">-N</th>
      <th style="text-align: center">–ntasks-per-node</th>
      <th style="text-align: center">–cpu-bind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">64</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">72</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">128</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">144</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">256</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">32</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">288</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
  </tbody>
</table>

<p>また、本テクニカルTipsの <strong><a href="#3-nvme-ssdローカルディスクをストレージ領域に活用する方法">3. NVMe SSDローカルディスクをストレージ領域に活用する方法</a></strong> の結果から、NVMe SSDローカルディスクを解析フローのストレージ領域に使用することが有効であると判明しているため本Tipsもこの方法を採用することとし、 <strong><a href="#3-0-概要">3.0. 概要</a></strong> に記載の7ステップにかかる時間を個別に取得出来るようにした上で、結果の妥当性を確認するために各テストケースをそれぞれ5回計測します。<br />
なお、ここでは計算結果の出力頻度（ <strong>writeInterval</strong> ）にデフォルトの1,000タイムステップを使用している（計算結果を出力しない）ため、NVMe SSDローカルディスクを使用する効果は限定されます。</p>

<h2 id="2-2-実行結果とその考察">2-2. 実行結果とその考察</h2>

<p>ノード当たりのMPIプロセス数とノード数をパラメータとして実行した結果を以下に示します。<br />
なお各計測値は、5回の計測結果の平均値です。</p>

<p><img src="graph_04.png" alt="実行結果" /></p>

<p>この結果から、ノード当たりのMPIプロセス数に着目すると以下のことがわかります。</p>

<ul>
  <li>4ノードまではMPIプロセス数36が高速で8ノードはMPIプロセス数32が高速</li>
  <li>ノード数が増えるに従いMPIプロセス数36と32の差が縮小する傾向を示し8ノードで逆転する</li>
  <li>最も性能の良いノード数8の場合でMPIプロセス数32が36より総所要時間が <strong>1.3 %</strong> 短い</li>
</ul>

<p>以上より、8ノードでの差が1%程度であることから、本テストケースの8ノードまでの実行であれば総合的にノード当たりのMPIプロセス数36が有利であると結論付け、次にノード当たりのMPIプロセス数36のノード数によるスケーラビリティーに着目します。</p>

<p><img src="graph_05.png" alt="実行結果" /></p>

<p>この結果から、以下のことがわかります。</p>

<ul>
  <li>ノード数の増加に伴い性能が向上する</li>
  <li>ノード数が増えるに従いスケーラビリティーは悪化する</li>
  <li>ノード数増加による性能向上の大部分は並列実行の非圧縮乱流解析ソルバー <strong>simpleFoam</strong> で発生している</li>
  <li>ノード数の増加に伴い非並列実行の <strong>decomposePar</strong> の所要時間と全体に占める割合が増加する</li>
</ul>

<p>以上より、非並列実行の <strong>decomposePar</strong> を予め1コアの仮想マシンインスタンスで実行する等の工夫により <strong>Step 2</strong> までの実行をHPCクラスタから切り離し、 <strong>Step 3</strong> 以降の総所要時間を対象としたノード数によるスケーラビリティーに着目します。</p>

<p><img src="graph_06.png" alt="実行結果" /></p>

<p>この結果から、以下のことがわかります。</p>

<ul>
  <li>ノード数の増加に伴いほぼリニアに性能が向上する（並列化効率がほぼ100％）</li>
</ul>

<p>以上より、本テストケースを8ノードまでのノード間並列実行する際コストパフォーマンスを最大化する実行方法は、非並列実行の <strong>decomposePar</strong> をHPCクラスタから切り離して実行することを前提に、 <strong>ノード当たりのMPIプロセス数36</strong> で <strong>8ノード</strong> 実行する場合である、と判断できます。</p>

<hr />
<h1 id="3-nvme-ssdローカルディスクをストレージ領域に活用する方法">3. NVMe SSDローカルディスクをストレージ領域に活用する方法</h1>

<h2 id="3-0-概要">3-0. 概要</h2>

<p>本Tipsは、 <strong>OpenFOAM</strong> が実行中に計算結果をファイルシステムに書き出す際、 <strong>BM.Optimized3.36</strong> が搭載する高速なNVMe SSDローカルディスク上に作成したファイルシステムをその対象領域とすることで、CFD解析フロー全体の所要時間を短縮し解析コストを削減する方法を解説します。</p>

<p><strong>OpenFOAM</strong> が実行中に作成するファイルは、総容量のみならず総ファイル数が多いため、NFSでサービスする共有ストレージに対して高いIOPS性能を持つNVMe SSDローカルディスクが有効で、特に高並列実行のケースや計算結果の出力頻度が高いケースでその効果を顕著に得ることが出来ます。</p>

<p>本TipsのNVMe SSDローカルディスクの使用方法は、 <strong>OpenFOAM</strong> のケースディレクトリがCFD解析フロー開始時点で通常共有ストレージに存在することを考慮し、共有ストレージ・NMVe SSDローカルディスク間でrsyncを使用してデータを同期しながら以下のステップで実行、 <strong>OpenFOAM</strong> がストレージ領域にアクセスする際、NMVe SSDローカルディスクを極力使用するよう配慮します。</p>

<ol>
  <li>ヘッドノードで “共有ストレージ -&gt; NVMe SSDローカルディスク” 方向のケースディレクトリ内全ファイルの同期</li>
  <li>ヘッドノードのNVMe SSDローカルディスク上で <strong>decomposePar</strong> を実行</li>
  <li>“ヘッドノードのNVMe SSDローカルディスク -&gt; その他ノードのNVMe SSDローカルディスク” 方向のケースディレクトリ内全ファイルの同期</li>
  <li>全ノードがNVMe SSDローカルディスクを使用して <strong>potentialFoam</strong> を並列実行</li>
  <li>全ノードがNVMe SSDローカルディスクを使用して <strong>simpleFoam</strong> を並列実行</li>
  <li>“その他ノードのNVMe SSDローカルディスク -&gt; ヘッドノードのNVMe SSDローカルディスク” 方向のケースディレクトリ内一部ファイルの同期</li>
  <li>ヘッドノードで “NVMe SSDローカルディスク -&gt; 共有ストレージ” 方向のケースディレクトリ内一部ファイルの同期</li>
</ol>

<p>ここで <strong>ステップ 3.</strong> と <strong>ステップ 6.</strong> の同期は、その他ノードのノード数（並列計算に使用する総ノード数マイナス1）分だけ並列実行することで、NVMe SSDローカルディスクの高いIOPS性能（ここでは特にヘッドノードのNVMe SSDローカルディスク）を有効に活用して所要時間の短縮を図ります。</p>

<p>また <strong>ステップ 6.</strong> の同期は、ファイルの同期を同時実行することによるヘッドノード上でのファイル競合を避けるため、各MPIプロセスが解析結果を格納する <strong>processorxx</strong> ディレクトリとその配下のファイルは、当該ノードに割り当てられたプロセスディレクトリのみを対象とします。</p>

<p>また <strong>ステップ 7.</strong> の同期は、各MPIプロセスが解析結果を格納する <strong>processorxx</strong> ディレクトリとその配下のファイルを除外し、ポスト処理に必要なファイルだけを同期することで、所要時間の短縮を図ります。</p>

<p>共有ストレージを使用する実行方法は、 <strong>ステップ 1.</strong> ・ <strong>ステップ 3.</strong> ・ <strong>ステップ 6.</strong> ・ <strong>ステップ 7.</strong> に時間を消費しませんが、NVMe SSDローカルディスクを使用する実行方法が共有ストレージを使用する実行方法に対して <strong>ステップ 2.</strong> ・ <strong>ステップ 4.</strong> ・ <strong>ステップ 5.</strong> で所要時間を短縮することが出来るため、トータルの実行時間はNVMe SSDローカルディスクを使用する実行方法が短くなります。</p>

<p>また、 <strong><a href="#1-メモリ帯域の有効利用を考慮した最適なノード内並列実行方法">1. メモリ帯域の有効利用を考慮した最適なノード内並列実行方法</a></strong> と <strong><a href="#2-ノード間並列スケーラビリティーを考慮した最適な実行方法">2. ノード間並列スケーラビリティーを考慮した最適な実行方法</a></strong> の結果と最もストレージ領域に負荷のかかる条件を選定するという観点から、以下の条件で計測します。</p>

<ul>
  <li><strong>NPS</strong> ： <strong>NPS2</strong></li>
  <li>ノード当たりのMPIプロセス数 ： 36</li>
  <li>MPIプロセスのノード内バインディング ： NUMAノード単位サイクリック</li>
  <li>ノード数 ： 8</li>
</ul>

<p>本Tipsは、以下の環境・条件で <strong>OpenFOAM</strong> を実行し、CFD解析フローの所要時間（所要コスト）を計測しています。</p>

<ul>
  <li>シェイプ ： <strong>BM.Optimized3.36</strong></li>
  <li>BIOS設定 ： <strong>SMT</strong> 無効化、 <strong>NPS2</strong> （※5）</li>
  <li>ノード間接続 ：  <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong></li>
  <li>比較対象の共有ストレージ ： <strong>ファイル・ストレージ</strong> （NFS）</li>
  <li>OS ： <strong>Oracle Linux</strong> 8.9ベースのHPC <strong><a href="/ocitutorials/hpc/#5-13-クラスタネットワーキングイメージ">クラスタネットワーキングイメージ</a></strong> （※6）</li>
  <li><strong>OpenFOAM</strong> ： v2312</li>
  <li>MPI ： <strong><a href="https://www.open-mpi.org/">OpenMPI</a></strong> 5.0.3</li>
  <li>解析対象モデル ： <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデル<br />
（ <strong>hpc/incompressible/simpleFoam/HPC_motorbike/Small/v1912/HPC_motorbike/Small/v1912</strong> ）</li>
  <li>計算結果の出力頻度（ <strong>writeInterval</strong> ） ： 10タイムステップ（デフォルト値：1,000タイムステップ）</li>
</ul>

<p>※5）NPSの設定方法は、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></strong> を参照してください。<br />
※6） <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/#1-クラスタネットワーキングイメージ一覧">1. クラスタネットワーキングイメージ一覧</a></strong> のイメージ <strong>No.1</strong> です。</p>

<p>この結果、以下のことが判明しています。</p>

<ul>
  <li>NVMe SSDローカルディスクは共有ストレージに対して所要時間（所要コスト）が <strong>26.2 %</strong> 短い（安価）</li>
</ul>

<h2 id="3-1-実行方法">3-1. 実行方法</h2>

<p>本章は、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルを使用し、NVMe SSDローカルディスクをストレージ領域に活用して実行する方法を解説します。</p>

<p>この方法は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam//#4-cfd解析フロー実行">4. CFD解析フロー実行</a></strong> を参照し、ここで解説しているチュートリアル付属のオートバイ走行時乱流シミュレーションモデルのバッチ実行の方法を参考に、 <strong>OpenFOAM HPC Benchmark Suite</strong> の <strong>HPC_Motorbike</strong> の <strong>Small</strong> モデルにこれを適用します。</p>

<p>この際、 <strong>OpenFOAM</strong> の設定ファイル <strong>system/controlDict</strong> の <strong>writeInterval</strong> を <strong>10</strong> に変更します。<br />
この値がデフォルト値 <strong>1,000</strong> のままの場合、計算結果を出力しないため、NVMe SSDローカルディスクの効果を得ることが出来ません。</p>

<p>また、 <strong>Slurm</strong> の設定ファイル <strong>slurm.conf</strong> ファイルの <strong>NodeName=DEFAULT</strong> で始まる行を以下のように修正します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">NodeName</span><span class="o">=</span>DEFAULT <span class="nv">CPUs</span><span class="o">=</span>36 <span class="nv">Boards</span><span class="o">=</span>1 <span class="nv">SocketsPerBoard</span><span class="o">=</span>4 <span class="nv">CoresPerSocket</span><span class="o">=</span>9 <span class="nv">ThreadsPerCore</span><span class="o">=</span>1 <span class="nv">RealMemory</span><span class="o">=</span>500000 <span class="nv">TmpDisk</span><span class="o">=</span>10000 <span class="nv">State</span><span class="o">=</span>UNKNOWN
</code></pre></div></div>

<p>また、ジョブスクリプトに指定する <strong>Slurm</strong> のオプションを以下のように指定します。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">-n</th>
      <th style="text-align: center">-N</th>
      <th style="text-align: center">–ntasks-per-node</th>
      <th style="text-align: center">–cpu-bind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">288</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">verbose,rank_ldom</td>
    </tr>
  </tbody>
</table>

<p>また、 <strong><a href="#2-0-概要">2.0. 概要</a></strong> に記載の7ステップにかかる時間を個別に取得出来るようにした上で、結果の妥当性を確認するために各テストケースをそれぞれ5回計測します。</p>

<h2 id="3-2-実行結果とその考察">3-2. 実行結果とその考察</h2>

<p>共有ストレージを使用した場合とNVMe SSDローカルディスクを使用した場合の結果を以下に示します。<br />
なお各計測値は、5回の計測結果の平均値です。</p>

<p><img src="graph_01.png" alt="実行結果" /></p>

<p>このグラフから、NVMe SSDローカルディスクを使用する実行方法は、共有ストレージを使用する実行方法に対して、以下のことがわかります。</p>

<ul>
  <li><strong>simpleFoam</strong> の実行時間が <strong>40.4 %</strong> 短い</li>
  <li><strong>decomposePar</strong> の実行時間が <strong>34.2 %</strong> 短い</li>
  <li>rsyncのデータ転送総所要時間は <strong>46 秒</strong></li>
  <li>総所要時間（計算ノードの総所要コスト）が <strong>26.2 %</strong> 短い（安価）</li>
</ul>

<p>以上より、NVMe SSDローカルディスクを使用するために実行方法をひと手間掛けることで、CFD解析フローのコストを大幅に削減可能であることがわかります。<br />
またこのコスト削減は、高並列実行のケースや計算結果の出力頻度が高いケースでより大きな効果を得ることが出来ます。</p>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新日時:</strong> <time class="dt-published" datetime="2024-09-02T18:29:40+09:00">September 2, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">共有</h4>
  

  <a href="https://twitter.com/intent/tweet?text=CFD%E8%A7%A3%E6%9E%90%E3%83%95%E3%83%AD%E3%83%BC%E3%81%AE%E3%82%B3%E3%82%B9%E3%83%88%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%92%E5%90%91%E4%B8%8A%E3%81%95%E3%81%9B%E3%82%8BOpenFOAM%E9%96%A2%E9%80%A3Tips%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fbenchmark%2Fopenfoam-tuning%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fbenchmark%2Fopenfoam-tuning%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://oracle-japan.github.io/ocitutorials/hpc/benchmark/openfoam-tuning/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ocitutorials/hpc/benchmark/topology-aware-cn-tuning/" class="pagination--pager" title="クラスタ・ネットワークのトポロジーを考慮したノード間通信最適化方法
">前へ</a>
    
    
      <a href="/ocitutorials/hpc/benchmark/papi-profiling/" class="pagination--pager" title="PAPIでHPCアプリケーションをプロファイリング
">次へ</a>
    
  </nav>

    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">関連記事</h2>
  <div class="grid__wrapper">
    
  </div>
</div>

  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="検索キーワードを入力してください..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>フォロー</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/#ocijp" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/oracle-japan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/ocitutorials/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="https://oracle-japan.github.io">Oracle Cloud Infrastructure チュートリアル</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ocitutorials/assets/js/main.min.js"></script>




<script src="/ocitutorials/assets/js/lunr/lunr.min.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-store.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6W7FEC5CEH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6W7FEC5CEH', { 'anonymize_ip': false});
</script>







  
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
  
    <script src="/ocitutorials/assets/js/clipboardrouge.js"></script>
  
    <script src="/ocitutorials/assets/js/tabs.js"></script>
  
    <script src="/ocitutorials/assets/js/sidebar.js"></script>
  


  </body>
</html>
