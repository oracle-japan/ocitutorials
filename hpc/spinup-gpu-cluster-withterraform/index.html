<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.3 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="ja-JP" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>GPUクラスタを構築する(基礎インフラ自動構築編) | Oracle Cloud Infrastructure チュートリアル</title>
<meta name="description" content="GPUクラスタを構築してみましょう。このチュートリアルは、GPUクラスタのノード間接続に最適な高帯域・低遅延RDMA対応RoCEv2採用のクラスタ・ネットワークでベアメタルインスタンスをノード間接続するGPUクラスタを、予め用意されたTerraformスクリプトを活用してリソース・マネージャやTerraform CLIで自動構築します。">


  <meta name="author" content="Oracle Japan Solution Engineers">
  
  <meta property="article:author" content="Oracle Japan Solution Engineers">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ja_JP">
<meta property="og:site_name" content="Oracle Cloud Infrastructure チュートリアル">
<meta property="og:title" content="GPUクラスタを構築する(基礎インフラ自動構築編)">
<meta property="og:url" content="https://oracle-japan.github.io/ocitutorials/hpc/spinup-gpu-cluster-withterraform/">


  <meta property="og:description" content="GPUクラスタを構築してみましょう。このチュートリアルは、GPUクラスタのノード間接続に最適な高帯域・低遅延RDMA対応RoCEv2採用のクラスタ・ネットワークでベアメタルインスタンスをノード間接続するGPUクラスタを、予め用意されたTerraformスクリプトを活用してリソース・マネージャやTerraform CLIで自動構築します。">



  <meta property="og:image" content="https://oracle-japan.github.io/ocitutorials/hpc/spinup-hpc-cluster-withterraform/architecture_diagram.png">





  <meta property="article:published_time" content="2025-08-27T00:30:27+09:00">






<link rel="canonical" href="https://oracle-japan.github.io/ocitutorials/hpc/spinup-gpu-cluster-withterraform/">












<!-- end _includes/seo.html -->



  <link href="/ocitutorials/feed.xml" type="application/atom+xml" rel="alternate" title="Oracle Cloud Infrastructure チュートリアル Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/ocitutorials/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-32.png" sizes="32x32">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-128.png" sizes="128x128">
<link rel="icon" href="https://www.oracle.com/asset/web/favicons/favicon-192.png" sizes="192x192">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-120.png" sizes="120x120">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-152.png" sizes="152x152">
<link rel="apple-touch-icon" href="https://www.oracle.com/asset/web/favicons/favicon-180.png" sizes="180x180">
<link rel="shortcut icon" type="image/x-icon" href="/ocitutorials/assets/favicon/favicon.ico">
<link rel="manifest" href="/ocitutorials/assets/favicon/site.webmanifest">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/ocitutorials/"><img src="/ocitutorials/assets/images/social-og-oracle-badge.jpg" alt="OCI チュートリアル"></a>
        
        <a class="site-title" href="/ocitutorials/">
          OCI チュートリアル
          <span class="site-subtitle">Oracle Cloud Infrastructure を使ってみよう</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/ocitutorials/#%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E4%B8%80%E8%A6%A7"
                
                
              >チュートリアル一覧</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ocitutorials/about/"
                
                
              >このサイトについて</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">メニュー</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(34, 66, 55, 0.7), rgba(34, 66, 55, 0.7)), url('/ocitutorials/hpc/spinup-hpc-cluster-withterraform/architecture_diagram.png');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          GPUクラスタを構築する(基礎インフラ自動構築編)

        
      </h1>
      
        <p class="page__lead">GPUクラスタを構築してみましょう。このチュートリアルは、GPUクラスタのノード間接続に最適な高帯域・低遅延RDMA対応RoCEv2採用のクラスタ・ネットワークでベアメタルインスタンスをノード間接続するGPUクラスタを、予め用意されたTerraformスクリプトを活用してリソース・マネージャやTerraform CLIで自動構築します。
</p>
      
      


      
    </div>
  
  
</div>






  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/" itemprop="item"><span itemprop="name">ホーム</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">></span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/ocitutorials/hpc" itemprop="item"><span itemprop="name">Hpc</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">></span>
      
    
      
      
        <li class="current">GPUクラスタを構築する(基礎インフラ自動構築編)</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">メニュー</label>
  <ul class="nav__items">
    <li>
      
      <a href=""><span class="nav__sub-title">HPC編</span></a>
      <ul>
        
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-cluster-network/">HPCクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withterraform/">HPCクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster/">HPCクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-hpc-cluster-withautoscaling/">HPCクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance/">GPUインスタンスで機械学習にトライ</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-ml-instance-cntnd/">GPUインスタンスで分散機械学習環境を構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster/">GPUクラスタを構築する(基礎インフラ手動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withterraform/" class="active">GPUクラスタを構築する(基礎インフラ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack/">GPUクラスタを構築する(スタティッククラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withautoscaling/">GPUクラスタを構築する(オンデマンドクラスタ自動構築編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-gpu-cluster-withubuntu/">GPUクラスタを構築する(Ubuntu OS編)</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-fss/">ファイル・ストレージでファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-lustre-server-fswl/">File Storage with Lustreでファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server/">ブロック・ボリュームでファイル共有ストレージを構築する（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-e6/">ブロック・ボリュームでファイル共有ストレージを構築する（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-nfs-server-nvme/">短期保存データ用高速ファイル共有ストレージを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/spinup-backup-server/">ベア・メタル・インスタンスNFSサーバ向けバックアップサーバを構築する</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-base/">ブロック・ボリュームNFSサーバと基礎インフラ編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/cluster-with-bv-stack/">ブロック・ボリュームNFSサーバと自動構築編HPC/GPUクラスタを組み合わせる</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl/">HPL実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e5/">HPL実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-hpl-e6/">HPL実行方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream/">STREAM実行方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e5/">STREAM実行方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-stream-e6/">STREAM実行方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-imb/">Intel MPI Benchmarks実行方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests/">NCCL Tests実行方法（BM.GPU4.8/BM.GPU.A100-v2.8 Oracle Linux編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests-ubuntu/">NCCL Tests実行方法（BM.GPU4.8/BM.GPU.A100-v2.8 Ubuntu編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/run-nccltests-h100/">NCCL Tests実行方法（BM.GPU.H100.8編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベアメタルインスタンスのBIOS設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/stop-unused-service/">不要サービス停止によるパフォーマンスチューニング方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/topology-aware-cn-tuning/">クラスタ・ネットワークのトポロジーを考慮したノード間通信最適化方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openfoam-tuning/">CFD解析フローのコストパフォーマンを向上させるOpenFOAM関連Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftips/">OpenMPIのMPI通信性能に影響するパラメータとその関連Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding-e5/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/cpu-binding-e6/">パフォーマンスを考慮したプロセス・スレッドのコア割当て指定方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune/">OpenMPIのMPI集合通信チューニング方法（BM.Optimized3.36編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune-e5/">OpenMPIのMPI集合通信チューニング方法（BM.Standard.E5.192編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/openmpi-perftune-e6/">OpenMPIのMPI集合通信チューニング方法（BM.Standard.E6.256編）</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/papi-profiling/">PAPIでHPCアプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/scorep-profiling/">Score-P・Scalasca・CubeGUIで並列アプリケーションをプロファイリング</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/benchmark/profiling-tuning/">プロファイリング情報に基づく並列アプリケーションチューニング方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/">クラスタネットワーキングイメージを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/rdma-interface-configure/">クラスタ・ネットワーク接続用ネットワークインターフェース作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-create-cnenabled-osimage/">クラスタ・ネットワーク未対応OSを使ったクラスタ・ネットワーク接続方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/determine-cnrelated-issue/">クラスタ・ネットワークに接続する計算/GPUノード作成時の問題判別方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-get-cnrelated-statistics/">クラスタ・ネットワーク統計情報の取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/nvme-filesystem/">ベアメタルインスタンスのNVMe SSDローカルディスク領域ファイルシステム作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-configure-sharedstorage/">HPC/GPUクラスタ向けファイル共有ストレージの最適な構築手法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/bv-sharedstorage-recovery/">ブロック・ボリュームを使用するNFSサーバのインスタンス障害からの復旧方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/boot-volume-extension/">計算/GPUノードのブート・ボリューム動的拡張方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/howto-choose-osbackuptool/">ファイル共有ストレージ向けバックアップ環境の最適な構築手法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-name-resolution/">計算/GPUノードの効果的な名前解決方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-os-customization/">計算/GPUノードデプロイ時の効果的なOSカスタマイズ方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/compute-host-list/">計算/GPUノードのホスト名リスト作成方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-resize/">計算/GPUノードの追加・削除・入れ替え方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/cluster-with-pdsh/">pdshで効率的にクラスタ管理オペレーションを実行</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/instance-principal-auth/">オンデマンドクラスタ実現のためのインスタンス・プリンシパル認証設定方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/log-monitoring/">OCIロギングとGrafanaを使用したHPC/GPUクラスタのログ監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/metric-monitoring/">OCIモニタリングとGrafanaを使用したHPC/GPUクラスタのメトリック監視方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/gpu-with-ubuntu/">UbuntuをOSとするHPC/機械学習ワークロード向けGPUインスタンス構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-openmpi/">Slurm環境での利用を前提とするUCX通信フレームワークベースのOpenMPI構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/setup-slurm-cluster/">Slurmによるリソース管理・ジョブ管理システム構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-blas/">線形代数演算ライブラリインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/install-openfoam/">OpenFOAMインストール・利用方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/slurm-tips/">Slurmによるリソース管理・ジョブ管理システム運用Tips</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/build-oraclelinux-hpcenv/">Oracle Linuxプラットフォーム・イメージベースのHPCワークロード実行環境構築方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/kdump-on-baremetal/">ベアメタルインスタンスのカーネルダンプ取得方法</a></li></p>
        
          <p></p><li><a href="/ocitutorials/hpc/tech-knowhow/site-to-site-vpn/">サイト間VPNによるOCIとの拠点間接続方法</a></li></p>
        
      </ul>
    </li>
  </ul>
</nav>
    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="GPUクラスタを構築する(基礎インフラ自動構築編)">
    <meta itemprop="description" content="GPUクラスタを構築してみましょう。このチュートリアルは、GPUクラスタのノード間接続に最適な高帯域・低遅延RDMA対応RoCEv2採用のクラスタ・ネットワークでベアメタルインスタンスをノード間接続するGPUクラスタを、予め用意されたTerraformスクリプトを活用してリソース・マネージャやTerraform CLIで自動構築します。">
    <meta itemprop="datePublished" content="2025-08-27T00:30:27+09:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目次</h4></header>
              <ul class="toc__menu"><li><a href="#0-事前準備">0. 事前準備</a><ul><li><a href="#0-0-概要">0-0. 概要</a></li><li><a href="#0-1-リソースマネージャを使用する方法">0-1. リソース・マネージャを使用する方法</a><ul><li><a href="#0-1-1-構成ソースプロバイダ作成">0-1-1. 構成ソース・プロバイダ作成</a></li><li><a href="#0-1-2-スタック作成">0-1-2. スタック作成</a></li></ul></li><li><a href="#0-2-terraform-cliを使用する方法">0-2. Terraform CLIを使用する方法</a><ul><li><a href="#0-2-1-terraform実行環境構築">0-2-1. Terraform実行環境構築</a></li><li><a href="#0-2-2-terraformスクリプト概要">0-2-2. Terraformスクリプト概要</a></li><li><a href="#0-2-3-terraformスクリプト作成">0-2-3. Terraformスクリプト作成</a></li></ul></li></ul></li><li><a href="#1-gpuクラスタ構築">1. GPUクラスタ構築</a><ul><li><a href="#1-0-概要">1-0. 概要</a></li><li><a href="#1-1-リソースマネージャを使用する方法">1-1. リソース・マネージャを使用する方法</a></li><li><a href="#1-2-terraform-cliを使用する方法">1-2. Terraform CLIを使用する方法</a></li></ul></li><li><a href="#2-gpuクラスタ確認">2. GPUクラスタ確認</a><ul><li><a href="#2-0-概要">2-0. 概要</a></li><li><a href="#2-1-bastionノードログイン">2-1. Bastionノードログイン</a></li><li><a href="#2-2-cloud-init完了確認">2-2. cloud-init完了確認</a></li><li><a href="#2-3-gpuノードファイルシステム確認">2-3. GPUノードファイルシステム確認</a></li><li><a href="#2-4-gpuノードbios設定確認">2-4. GPUノードBIOS設定確認</a></li><li><a href="#2-5-gpuノードクラスタネットワーク用ネットワークインターフェース設定確認">2-5. GPUノードクラスタ・ネットワーク用ネットワークインターフェース設定確認</a></li></ul></li><li><a href="#3-コンテナ環境構築">3. コンテナ環境構築</a></li><li><a href="#4-nccl-tests実行">4. NCCL Tests実行</a></li><li><a href="#5-gpuクラスタ削除">5. GPUクラスタ削除</a><ul><li><a href="#5-0-概要">5-0. 概要</a></li><li><a href="#5-1-リソースマネージャを使用する方法">5-1. リソース・マネージャを使用する方法</a></li><li><a href="#5-2-terraform-cliの場合">5-2. Terraform CLIの場合</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <style>
table, th, td {
    font-size: 80%;
}
</style>

<p>このチュートリアルは、GPUクラスタのGPUノードに最適なベアメタルインスタンス（本チュートリアルでは <strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/References/computeshapes.htm#bm-gpu">BM.GPU4.8</a></strong> を使用）を <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> でノード間接続する、機械学習ワークロードを実行するためのGPUクラスタを構築する際のベースとなるインフラストラクチャを、予め用意された <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトを活用して自動構築し、Dockerコンテナ上で <strong><a href="https://developer.nvidia.com/nccl">NCCL（NVIDIA Collective Communication Library）</a></strong> のGPU間通信性能を <strong><a href="https://github.com/nvidia/nccl-tests">NCCL Tests</a></strong> で検証します。<br />
この自動構築は、 <strong>Terraform</strong> スクリプトを <strong><a href="/ocitutorials/hpc/#5-2-リソースマネージャ">リソース・マネージャ</a></strong> に読み込ませて作成する <strong><a href="/ocitutorials/hpc/#5-3-スタック">スタック</a></strong> を使用する方法と、 <strong>Terraform</strong> 実行環境を用意して <strong>Terraform</strong> CLIを使用する方法から選択することが出来ます。</p>

<p>このチュートリアルで作成する環境は、ユーザ管理、ホスト名管理、共有ファイルシステム、プログラム開発環境等、必要なソフトウェア環境をこの上に整備し、ご自身の要件に沿ったGPUクラスタを構築する際の基礎インフラストラクチャとして利用することが可能です。<br />
なお、これらのクラスタ管理に必要なソフトウェアの導入までを自動化する <strong><a href="/ocitutorials/hpc/#5-10-hpcクラスタスタック">HPCクラスタスタック</a></strong> も利用可能で、詳細は <strong><a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack">GPUクラスタを構築する(スタティッククラスタ自動構築編)</a></strong> を参照してください。</p>

<p>本チュートリアルで作成するGPUクラスタ構築用の <strong>Terraform</strong> スクリプトは、そのひな型が <strong>GitHub</strong> のパブリックレポジトリから公開されており、適用すると以下の処理を行います。</p>

<ul>
  <li><strong>VCN</strong> と関連するネットワークリソース作成</li>
  <li>Bastionノード作成</li>
  <li>GPUノード用 <strong><a href="/ocitutorials/hpc/#5-7-インスタンス構成">インスタンス構成</a></strong> 作成</li>
  <li><strong>クラスタ・ネットワーク</strong> とGPUノード作成</li>
  <li>GPUクラスタ内のノード間SSHアクセスに使用するSSH鍵ペア作成・配布</li>
  <li>GPUノードの全ホスト名を記載したホストリストファイル（ <strong>/home/opc/hostlist.txt</strong> ）作成</li>
  <li>作成したBastionノード・GPUノードのホスト名・IPアドレス出力</li>
</ul>

<p>Bastionノードは、接続するサブネットをパブリックとプライベートから選択することが可能（※1）で、以下のBastionノードへのログイン方法に合わせて選択します。</p>

<ul>
  <li>インターネット経由ログイン -&gt; パブリックサブネット接続</li>
  <li>拠点間接続経由ログイン &gt; プライベートサブネット接続</li>
</ul>

<p>※1）構築方法に <strong>Terraform</strong> CLIを採用する場合は、パブリックサブネット接続のみ選択可能です。</p>

<p>また <strong>VCN</strong> と関連するネットワークリソースは、既存のものを使用することも可能で、この場合はこれらが以下の条件を満たしているている必要があります。</p>

<ul>
  <li>プライベートサブネットが存在する</li>
  <li>パブリックサブネットが存在する（Bastionノードパブリック接続の場合）</li>
  <li>パブリックサブネット・プライベートサブネット間で <strong>セキュリティ・リスト</strong> によりアクセスが制限されていない（Bastionノードパブリック接続の場合）</li>
  <li>プライベートサブネットが <strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/Compute/Tasks/manage-plugins.htm">Oracle Cloud Agent</a></strong> HPCプラグインの動作条件を満たしている（※2）</li>
</ul>

<p>※2）この詳細は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/">クラスタネットワーキングイメージを使ったクラスタ・ネットワーク接続方法</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/howto-connect-clusternetwork/#1-2-接続サブネットのoca-hpcプラグイン動作条件充足確認">1-2. 接続サブネットのOCA HPCプラグイン動作条件充足確認</a></strong> を参照してください。</p>

<p><img src="/ocitutorials/hpc/spinup-cluster-network/architecture_diagram.png" alt="システム構成図（パブリック）" /></p>

<p><img src="/ocitutorials/hpc/spinup-cluster-network/architecture_diagram_private.png" alt="システム構成図（プライベート）" /></p>

<p>Bastionノード作成は、 <strong><a href="/ocitutorials/hpc/#5-11-cloud-init">cloud-init</a></strong> 設定ファイル( <strong>cloud-config</strong> )を含み、 <strong>cloud-init</strong> がBastionノード作成時に以下の処理を行います。</p>

<ul>
  <li>タイムゾーンをJSTに変更</li>
  <li>ホームディレクトリ領域のNFSエクスポート</li>
  <li>GPUノードのDNS名前解決をショートホスト名で行うための <strong>resolv.conf</strong> 修正</li>
</ul>

<p>またGPUノード用 <strong>インスタンス構成</strong> は、 <strong>cloud-config</strong> を含み、 <strong>cloud-init</strong> がGPUノード作成時に以下の処理を行います。</p>

<ul>
  <li>タイムゾーンをJSTに変更</li>
  <li>NVMe SSDローカルディスク領域ファイルシステム作成</li>
  <li><strong>firewalld</strong> 停止</li>
  <li>ルートファイルシステム拡張</li>
  <li>BastionノードのDNS名前解決をショートホスト名で行うための <strong>resolv.conf</strong> 修正</li>
  <li>Bastionノードホームディレクトリ領域のNFSマウント</li>
</ul>

<p><strong>所要時間 :</strong> 約2時間</p>

<p><strong>前提条件 :</strong> GPUクラスタを収容するコンパートメント(ルート・コンパートメントでもOKです)の作成と、このコンパートメントに対する必要なリソース管理権限がユーザーに付与されていること。</p>

<p><strong>注意 :</strong> チュートリアル内の画面ショットについては、OCIの現在のコンソール画面と異なっている場合があります。</p>

<hr />
<h1 id="0-事前準備">0. 事前準備</h1>

<h2 id="0-0-概要">0-0. 概要</h2>

<p>本章は、GPUクラスタを構築する際事前に用意しておく必要のあるリソースを作成します。<br />
この手順は、構築手法に <strong><a href="/ocitutorials/hpc/#5-2-リソースマネージャ">リソース・マネージャ</a></strong> を使用する方法を採用するか、 <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> CLIを使用する方法を採用するかで異なります。</p>

<ol>
  <li>
    <p><strong>リソース・マネージャ</strong> を使用する方法</p>

    <ul>
      <li><strong><a href="/ocitutorials/hpc/#5-14-構成ソースプロバイダ">構成ソース・プロバイダ</a></strong> 作成</li>
      <li><strong><a href="/ocitutorials/hpc/#5-3-スタック">スタック</a></strong> 作成</li>
    </ul>
  </li>
  <li>
    <p><strong>Terraform</strong> CLIを使用する方法</p>

    <ul>
      <li><strong>Terraform</strong> 実行環境構築</li>
      <li><strong>Terraform</strong> スクリプト作成</li>
    </ul>
  </li>
</ol>

<p>以降では、2つの異なる構築手法毎にその手順を解説します。</p>

<h2 id="0-1-リソースマネージャを使用する方法">0-1. リソース・マネージャを使用する方法</h2>

<h3 id="0-1-1-構成ソースプロバイダ作成">0-1-1. 構成ソース・プロバイダ作成</h3>

<p>本章は、ひな型となる <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトを <strong>GitHub</strong> パブリックレポジトリから取り込むための <strong><a href="/ocitutorials/hpc/#5-14-構成ソースプロバイダ">構成ソース・プロバイダ</a></strong> を作成します。</p>

<p><strong>構成ソース・プロバイダ</strong> の作成は、 <strong><a href="/ocitutorials/hpc/#5-14-構成ソースプロバイダ">ここ</a></strong> を参照してください。</p>

<h3 id="0-1-2-スタック作成">0-1-2. スタック作成</h3>

<p>本章は、GPUクラスタを構築するための <strong><a href="/ocitutorials/hpc/#5-2-リソースマネージャ">リソース・マネージャ</a></strong> 用 <strong><a href="/ocitutorials/hpc/#5-3-スタック">スタック</a></strong> を作成します。</p>

<p>OCIコンソールにログインし、GPUクラスタを構築するリージョンを選択後、 <strong>開発者サービス</strong> → <strong>リソース・マネージャ</strong> → <strong>スタック</strong> とメニューを辿ります。</p>

<p>次に、表示される以下画面で、<strong>スタックの作成</strong> ボタンをクリックします。</p>

<p><img src="console_page02.png" alt="画面ショット" /></p>

<p>次に、表示される以下 <strong>スタック情報</strong> 画面で、以下の情報を入力し、下部の <strong>次</strong> ボタンをクリックします。</p>

<ul>
  <li><strong>Terraformの構成のオリジン :</strong> ソース・コード制御システム</li>
  <li><strong>ソースコード管理タイプ :</strong> <strong>GitHub</strong></li>
  <li><strong>構成ソース・プロバイダ :</strong> 先に作成した <strong><a href="/ocitutorials/hpc/#5-14-構成ソースプロバイダ">構成ソース・プロバイダ</a></strong></li>
  <li><strong>リポジトリ :</strong> <strong>tutorial_cn_rm</strong></li>
  <li><strong>ブランチ :</strong> <strong>master</strong></li>
  <li><strong>名前 :</strong> スタックに付与する名前（任意）</li>
  <li><strong>説明 :</strong> スタックに付与する説明（任意）</li>
</ul>

<p><img src="stack_page01.png" alt="画面ショット" /></p>

<p>次に、表示される <strong>変数の構成</strong> 画面で、各画面フィールドに以下の情報を入力し、下部の <strong>次</strong> ボタンをクリックします。</p>

<ul>
  <li>
    <p><strong>General options</strong> フィールド</p>

    <ul>
      <li><strong>Compartment :</strong> GPUクラスタを構築する <strong>コンパートメント</strong></li>
      <li><strong>Availability Domain :</strong> GPUクラスタを構築する <strong>可用性ドメイン</strong></li>
      <li><strong>SSH public key :</strong> Bastionノードにログインする際使用するSSH秘密鍵に対応する公開鍵<br />
  （公開鍵ファイルのアップロード（ <strong>SSHキー・ファイルの選択</strong> ）と公開鍵のフィールドへの貼り付け（ <strong>SSHキーの貼付け</strong> ）が選択可能）</li>
      <li><strong>Private bastion :</strong> Bastionノードをプライベートサブネットに接続するかどうかを指定（デフォルト：パブリックサブネット接続）<br />
  （パブリックサブネットに接続する場合はチェックオフ/プライベートサブネットに接続する場合はチェック）</li>
      <li><strong>Use existing VCN :</strong> 既存の <strong>VCN</strong> を使用するかどうかを指定（デフォルト： <strong>VCN</strong> を新規作成）<br />
  （既存の <strong>VCN</strong> を使用する場合は、チェックすると表示される <strong>VCN</strong> ・パブリックサブネット・プライベートサブネットの各フィールドにOCIDを指定します。）</li>
    </ul>
  </li>
</ul>

<p><img src="stack_page02.png" alt="画面ショット" /></p>

<ul>
  <li>
    <p><strong>Compute/GPU node options</strong> フィールド</p>

    <ul>
      <li><strong>Display name postfix :</strong> GPUノードホスト名の接尾辞（※3）</li>
      <li><strong>Shape :</strong> <strong>BM.GPU4.8</strong></li>
      <li><strong>Node count :</strong> GPUノードのノード数（デフォルト：2）</li>
      <li><strong>Image OCID :</strong> GPUノードのイメージOCID（※4）</li>
      <li><strong>Boot volume size :</strong> GPUノードのブートボリュームサイズ（200GB以上）</li>
      <li><strong>cloud-config :</strong> GPUノードの <strong><a href="/ocitutorials/hpc/#5-11-cloud-init">cloud-init</a></strong> 設定ファイル( <strong>cloud-config</strong> )（※5）</li>
      <li><strong>NPS for BM.GPU4.8 :</strong> GPUノードの <strong>NPS</strong> 設定値 (デフォルト：NPS4) （※6）</li>
      <li><strong>SMT :</strong> GPUノードの <strong>SMT</strong> 設定値 (デフォルト：有効) （※6）</li>
    </ul>
  </li>
</ul>

<p><img src="stack_page03.png" alt="画面ショット" /></p>

<p>※3） 例えば <strong>gpu4-ol89</strong> と指定した場合、GPUノードのホスト名は <strong>inst-xxxxx-gpu4-ol89</strong> となります。（ <strong>xxxxx</strong> はランダムな文字列）<br />
※4）以下のOCIDを指定します。なおこのイメージは、Bastionノードにも使用されます。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">No.<br />（※7）</th>
      <th style="text-align: center"><strong>Oracle Linux</strong><br />バージョン</th>
      <th style="text-align: center">OCID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: center">8.9</td>
      <td style="text-align: center">ocid1.image.oc1..aaaaaaaag36bbqszitkjcnnuauf3tiu3dg6bg2q7goj2uaxbbgnszan66fna</td>
    </tr>
    <tr>
      <td style="text-align: center">9</td>
      <td style="text-align: center">8.8</td>
      <td style="text-align: center">ocid1.image.oc1..aaaaaaaaeka3qe2v5ucxztilltohgmsyr63s3cd55uidtve4mtietoafopeq</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: center">7.9</td>
      <td style="text-align: center">ocid1.image.oc1..aaaaaaaa42ozstmmllgevxjvcbompvj6632lwlsigaudh26os7rsmfbcoilq</td>
    </tr>
  </tbody>
</table>

<p>※5）以下をテキストファイルとして保存し、ブラウザから読み込みます。<br />
なお既存の <strong>VCN</strong> を使用する場合は、以下の <strong>cloud-config</strong> 中のDNSサーチパスにパブリックサブネット名（<strong>public.vcn.oraclevcn.com</strong>）を追加している箇所を、既存のパブリックサブネット名に変更します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#cloud-config</span>
timezone: Asia/Tokyo
runcmd:
<span class="c">#</span>
<span class="c"># Mount NVMe local storage</span>
    - vgcreate nvme /dev/nvme0n1 /dev/nvme1n1 /dev/nvme2n1 /dev/nvme3n1
    - lvcreate <span class="nt">-l</span> 100%FREE nvme
    - mkfs.xfs <span class="nt">-L</span> localscratch /dev/nvme/lvol0
    - <span class="nb">mkdir</span> <span class="nt">-p</span> /mnt/localdisk
    - <span class="nb">echo</span> <span class="s2">"LABEL=localscratch /mnt/localdisk/ xfs defaults,noatime 0 0"</span> <span class="o">&gt;&gt;</span> /etc/fstab
    - systemctl daemon-reload
    - mount /mnt/localdisk
<span class="c">#</span>
<span class="c"># Stop firewalld</span>
    - systemctl disable <span class="nt">--now</span> firewalld
<span class="c">#</span>
<span class="c"># Expand root file system to those set by instance configuration</span>
    - /usr/libexec/oci-growfs <span class="nt">-y</span>
<span class="c">#</span>
<span class="c"># Add public subnet to DNS search</span>
    - <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/^search/s/$/ public.vcn.oraclevcn.com/g'</span> /etc/resolv.conf
    - chattr <span class="nt">-R</span> +i /etc/resolv.conf
<span class="c">#</span>
<span class="c"># NFS mount setting</span>
    - <span class="nb">echo</span> <span class="s2">"bastion:/home /home nfs defaults,vers=3 0 0"</span> <span class="o">&gt;&gt;</span> /etc/fstab
    - systemctl daemon-reload
    - mount /home
</code></pre></div></div>

<p>※6）詳細は、 <strong><a href="/ocitutorials/hpc/#2-2-パフォーマンス関連tips集">パフォーマンス関連Tips集</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベア・メタル・インスタンスのBIOS設定方法</a></strong> を参照してください。</p>

<p>※7）<strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/#1-クラスタネットワーキングイメージ一覧">1. クラスタネットワーキングイメージ一覧</a></strong> のイメージNo.です。</p>

<p>次に、表示される <strong>確認</strong> 画面で、これまでの設定項目が意図したものになっているかを確認し、以下 <strong>作成されたスタックで適用を実行しますか。</strong> フィールドの <strong>適用の実行</strong> をチェックオフし、下部の <strong>作成</strong> ボタンをクリックします。</p>

<p><img src="stack_page04.png" alt="画面ショット" /></p>

<p>ここで <strong>適用の実行</strong> をチェックした場合、 <strong>作成</strong> ボタンのクリックと同時に <strong>スタック</strong> の適用が開始され、GPUクラスタの構築が始まりますが、このチュートリアルでは後の章で改めて <strong>スタック</strong> の適用を行います。</p>

<p>これで、以下画面のとおりGPUクラスタ構築用 <strong>スタック</strong> が作成されました。</p>

<p><img src="stack_page05.png" alt="画面ショット" /></p>

<h2 id="0-2-terraform-cliを使用する方法">0-2. Terraform CLIを使用する方法</h2>

<h3 id="0-2-1-terraform実行環境構築">0-2-1. Terraform実行環境構築</h3>

<p>本章は、 <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> CLIを使用してGPUクラスタのライフサイクル管理を実行する <strong>Terraform</strong> 実行環境を構築します。<br />
この実行環境は、インターネットに接続された <strong>Linux</strong> ・ <strong>Windows</strong> ・ <strong>Mac</strong> の何れかのOSが稼働している端末であればよく、以下のような選択肢が考えられます。</p>

<ul>
  <li>OCI上の <strong>Linux</strong> が稼働するVMインスタンス</li>
  <li>ご自身が使用する <strong>Windows</strong> / <strong>Mac</strong> パソコン</li>
  <li>ご自身が使用する <strong>Windows</strong> / <strong>Mac</strong> パソコンで動作する <strong>Linux</strong> ゲストOS</li>
</ul>

<p>本チュートリアルは、この <strong>Terraform</strong> 実行環境のOSに <strong>Oracle Linux</strong> 8.9を使用します。</p>

<p><strong>Terraform</strong> 実行環境は、以下のステップを経て構築します。</p>

<ul>
  <li><strong>Terraform</strong> インストール</li>
  <li><strong>Terraform</strong> 実行環境とOCI間の認証関係締結（APIキー登録）</li>
</ul>

<p>具体的な <strong>Terraform</strong> 実行環境構築手順は、チュートリアル <strong><a href="https://oracle-japan.github.io/ocitutorials/intermediates/terraform/">TerraformでOCIの構築を自動化する</a></strong> の <strong><a href="https://oracle-japan.github.io/ocitutorials/intermediates/terraform/#2terraform%E7%92%B0%E5%A2%83%E3%81%AE%E6%A7%8B%E7%AF%89">2. Terraform環境の構築</a></strong> を参照してください。<br />
また、関連するOCI公式ドキュメントは、 <strong><a href="https://docs.oracle.com/ja-jp/iaas/developer-tutorials/tutorials/tf-provider/01-summary.htm">ここ</a></strong> を参照してください。</p>

<h3 id="0-2-2-terraformスクリプト概要">0-2-2. Terraformスクリプト概要</h3>

<p>本チュートリアルで使用するGPUクラスタ構築用の <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトは、そのひな型を <strong>GitHub</strong> のパブリックレポジトリで公開しており、以下のファイル群で構成されています。</p>

<table>
  <thead>
    <tr>
      <th>ファイル名</th>
      <th>用途</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>cn.tf</td>
      <td><strong><a href="/ocitutorials/hpc/#5-7-インスタンス構成">インスタンス構成</a></strong> と <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> の定義</td>
    </tr>
    <tr>
      <td>outputs.tf</td>
      <td>作成したリソース情報の出力</td>
    </tr>
    <tr>
      <td>terraform.tfvars</td>
      <td><strong>Terraform</strong> スクリプト内で使用する変数値の定義</td>
    </tr>
    <tr>
      <td>variables.tf</td>
      <td><strong>Terraform</strong> スクリプト内で使用する変数の型の定義</td>
    </tr>
    <tr>
      <td>instance.tf</td>
      <td>Bastionノードの定義</td>
    </tr>
    <tr>
      <td>provider.tf</td>
      <td><strong>テナンシ</strong> ・ユーザ・ <strong>リージョン</strong> の定義</td>
    </tr>
    <tr>
      <td>vcn.tf</td>
      <td><strong>仮想クラウド・ネットワーク</strong> と関連するネットワークリソースの定義</td>
    </tr>
  </tbody>
</table>

<p>これらのうち自身の環境に合わせて修正する箇所は、基本的に <strong>terraform.tfvars</strong> と <strong>provider.tf</strong> に集約しています。</p>

<p>また、これらのファイルと同じディレクトリに <strong>user_data</strong> ディレクトリが存在し、 <strong><a href="/ocitutorials/hpc/#5-11-cloud-init">cloud-init</a></strong> 設定ファイル（ <strong>cloud-config</strong> ）を格納しています。<br />
この <strong>cloud-config</strong> を修正することで、構築するGPUクラスタのOSレベルのカスタマイズをご自身の環境に合わせて追加・変更することも可能でます。</p>

<h3 id="0-2-3-terraformスクリプト作成">0-2-3. Terraformスクリプト作成</h3>

<p><strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトの作成は、まず以下の <strong>GitHub</strong> レポジトリからひな型となる <strong>Terraform</strong> スクリプトを <strong>Terraform</strong> 実行環境にダウンロードしますが、</p>

<p><strong><a href="https://github.com/fwiw6430/tutorial_cn">https://github.com/fwiw6430/tutorial_cn</a></strong></p>

<p>これには、以下コマンドを <strong>Terraform</strong> 実行環境のopcユーザで実行するか、</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>dnf <span class="nb">install</span> <span class="nt">-y</span> git
<span class="nv">$ </span>git clone https://github.com/fwiw6430/tutorial_cn
</code></pre></div></div>

<p><strong>GitHub</strong> の <strong>Terraform</strong> スクリプトレポジトリのページからzipファイルを <strong>Terraform</strong> 実行環境にダウンロード・展開することで行います。</p>

<p>次に、ダウンロードした <strong>Terraform</strong> スクリプトのうち、 <strong>terraform.tfvars</strong> と <strong>provider.tf</strong> 内の以下 <strong>Terraform</strong> 変数を自身の環境に合わせて修正します。<br />
この際、これらファイル内の <strong>Terraform</strong> 変数は、予めコメント（ <strong>#</strong> で始まる行）として埋め込まれていたり、キーワード <strong>xxxx</strong> で仮の値が入力されているため、コメント行を有効化して自身の値に置き換える等の修正を行います。</p>

<p>[ <strong>provider.tf</strong> ]</p>

<table>
  <thead>
    <tr>
      <th>変数名</th>
      <th>設定値</th>
      <th>確認方法</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>tenancy_ocid</td>
      <td>使用するテナントのOCID</td>
      <td><strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/API/Concepts/apisigningkey.htm#five">ここ</a></strong> を参照</td>
    </tr>
    <tr>
      <td>user_ocid</td>
      <td>使用するユーザのOCID</td>
      <td><strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/API/Concepts/apisigningkey.htm#five">ここ</a></strong> を参照</td>
    </tr>
    <tr>
      <td>private_key_path</td>
      <td>OCIに登録したAPIキーの秘密キーのパス</td>
      <td>-</td>
    </tr>
    <tr>
      <td>fingerprint</td>
      <td>OCIに登録したAPIキーのフィンガープリント</td>
      <td><strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/API/Concepts/apisigningkey.htm#four">ここ</a></strong> を参照</td>
    </tr>
    <tr>
      <td>region</td>
      <td>GPUクラスタを構築するリージョン識別子</td>
      <td><strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/General/Concepts/regions.htm">ここ</a></strong> を参照</td>
    </tr>
  </tbody>
</table>

<p>[ <strong>terraform.tfvars</strong> ]</p>

<table>
  <thead>
    <tr>
      <th>変数名</th>
      <th>設定値</th>
      <th style="text-align: center">確認方法</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>compartment_ocid</td>
      <td>GPUクラスタを構築する <strong>コンパートメント</strong> のOCID</td>
      <td style="text-align: center"><strong><a href="https://docs.oracle.com/ja-jp/iaas/Content/GSG/Tasks/contactingsupport_topic-Finding_the_OCID_of_a_Compartment.htm">ここ</a></strong> を参照</td>
    </tr>
    <tr>
      <td>ad</td>
      <td>GPUクラスタを構築する <strong>可用性ドメイン</strong> 識別子</td>
      <td style="text-align: center">（※8）</td>
    </tr>
    <tr>
      <td>ssh_key</td>
      <td>Bastionノードログインに使用するSSH秘密鍵に対する公開鍵</td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td>exist_vcn</td>
      <td>既存の <strong>VCN</strong> を使用するかどうかの指定（true/false）</td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td>vcn_ocid</td>
      <td>既存の <strong>VCN</strong> を使用する場合の <strong>VCN</strong> のOCID（※12）</td>
      <td style="text-align: center">（※13）</td>
    </tr>
    <tr>
      <td>public_ocid</td>
      <td>既存の <strong>VCN</strong> を使用する場合のパブリックサブネットのOCID（※12）</td>
      <td style="text-align: center">（※13）</td>
    </tr>
    <tr>
      <td>private_ocid</td>
      <td>既存の <strong>VCN</strong> を使用する場合のプライベートサブネットのOCID（※12）</td>
      <td style="text-align: center">（※13）</td>
    </tr>
    <tr>
      <td>comp_shape</td>
      <td>GPUノードに使用するシェイプ<br />・ <strong>BM.GPU4.8</strong></td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td>comp_image</td>
      <td>GPUノードに使用するOSイメージのOCID</td>
      <td style="text-align: center">（※9）</td>
    </tr>
    <tr>
      <td>comp_boot_vol_size</td>
      <td>GPUノードの <strong>ブートボリューム</strong> のサイズ（GB）（最低200GB）</td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td>comp_cloud_config</td>
      <td><strong>user_data</strong> ディレクトリに格納するGPUノード用 <strong>cloud-config</strong> ファイル名<br />・ <strong>cloud-init_cngpu.cfg</strong></td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td>comp_nps_gpu40</td>
      <td>GPUノードの <strong>NPS</strong> BIOS設定値</td>
      <td style="text-align: center">（※10）</td>
    </tr>
    <tr>
      <td>comp_smt</td>
      <td>GPUノードの <strong>SMT</strong> BIOS設定値</td>
      <td style="text-align: center">（※10）</td>
    </tr>
    <tr>
      <td>cn_display_name</td>
      <td>GPUノードホスト名の接尾辞</td>
      <td style="text-align: center">（※11）</td>
    </tr>
    <tr>
      <td>cn_node_count</td>
      <td>GPUノードのノード数</td>
      <td style="text-align: center">-</td>
    </tr>
  </tbody>
</table>

<p>※8）OCIコンソールメニューから <strong>コンピュート</strong> → <strong>インスタンス</strong> を選択し <strong>インスタンスの作成</strong> ボタンをクリックし、表示される以下 <strong>配置</strong> フィールドで確認出来ます。</p>

<p><img src="console_page01.png" alt="画面ショット" /></p>

<p>※9）コメントとして埋め込まれているOSイメージOCIDから、コメント文の記載を参考に適切なOSイメージOCIDのコメントを外して使用します。詳細は、 <strong><a href="/ocitutorials/hpc/#3-oci-hpcテクニカルtips集">OCI HPCテクニカルTips集</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/">クラスタネットワーキングイメージの選び方</a></strong> の <strong><a href="/ocitutorials/hpc/tech-knowhow/osimage-for-cluster/#1-クラスタネットワーキングイメージ一覧">1. クラスタネットワーキングイメージ一覧</a></strong> を参照してください。<br />
※10）詳細は、 <strong><a href="/ocitutorials/hpc/#2-oci-hpcパフォーマンス関連情報">OCI HPCパフォーマンス関連情報</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/bios-setting/">パフォーマンスに関連するベア・メタル・インスタンスのBIOS設定方法</a></strong> を参照してください。<br />
※11）例えば <strong>gpu4-ol89</strong> と指定した場合、GPUノードのホスト名は <strong>inst-xxxxx-gpu4-ol89</strong> となります。（ <strong>xxxxx</strong> はランダムな文字列）<br />
※12）既存の <strong>VCN</strong> を使用する場合のみコメントを外して指定します。<br />
※13）OCIコンソール上で当該 <strong>VCN</strong> ・サブネットの詳細画面を表示して確認します。</p>

<hr />
<h1 id="1-gpuクラスタ構築">1. GPUクラスタ構築</h1>

<h2 id="1-0-概要">1-0. 概要</h2>

<p>本章は、先に作成した <strong><a href="/ocitutorials/hpc/#5-3-スタック">スタック</a></strong> / <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトを使用し、GPUクラスタを構築します。</p>

<p>この手順は、構築手法に <strong><a href="/ocitutorials/hpc/#5-2-リソースマネージャ">リソース・マネージャ</a></strong> を使用する方法を採用するか、 <strong>Terraform</strong> CLIを使用する方法を採用するかで異なり、以降では2つの異なる構築手法毎にその手順を解説します。</p>

<h2 id="1-1-リソースマネージャを使用する方法">1-1. リソース・マネージャを使用する方法</h2>

<p>以下 <strong>スタックの詳細</strong> 画面で、 <strong>適用</strong> ボタンをクリックします。</p>

<p><img src="stack_page06.png" alt="画面ショット" /></p>

<p>次に、表示される以下 <strong>適用</strong> サイドバーで、 <strong>適用</strong> ボタンをクリックします。</p>

<p><img src="stack_page07.png" alt="画面ショット" /></p>

<p>次に、表示される以下 <strong>ジョブ詳細</strong> ウィンドウで、左上のステータスが <strong>受入れ済</strong> → <strong>進行中</strong> と遷移すれば、 <strong>スタック</strong> の適用が実施されています。</p>

<p><img src="stack_page08.png" alt="画面ショット" /></p>

<p>表示される以下 <strong>ログ</strong> フィールドで、リソースの作成状況を確認します。</p>

<p><img src="stack_page09.png" alt="画面ショット" /></p>

<p>この適用が完了するまでの所要時間は、GPUノードのノード数が2ノードの場合で15分程度です。</p>

<p>ステータスが <strong>成功</strong> となれば、GPUクラスタの構築が完了しており、以下のように <strong>ログ</strong> フィールドの最後にBastionノードとGPUノードのホスト名とIPアドレスが出力されます。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Outputs:

Bastion_instances_created <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"bastion"</span>
    <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.1.138"</span>
    <span class="s2">"public_ip"</span> <span class="o">=</span> <span class="s2">"123.456.789.123"</span>
<span class="o">}</span>
Compute_in_cn_created <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"inst-9fhuq-gpu4-ol89"</span> <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"inst-9fhuq-gpu4-ol89"</span>
    <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.2.10"</span>
    <span class="o">}</span>
    <span class="s2">"inst-dz99s-gpu4-ol89"</span> <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"inst-dz99s-gpu4-ol89"</span>
    <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.2.73"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<h2 id="1-2-terraform-cliを使用する方法">1-2. Terraform CLIを使用する方法</h2>

<p><strong>Terraform</strong> 実行環境で、以下コマンドを実行します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>tutorial_cn
<span class="nv">$ </span>terraform init
<span class="nv">$ </span>terraform apply <span class="nt">--auto-approve</span>
</code></pre></div></div>

<p>最後のコマンドによる <strong>Terraform</strong> スクリプトの適用完了までの所要時間は、GPUノードのノード数が2ノードの場合で15分程度です。</p>

<p><strong>Terraform</strong> スクリプトの適用が正常に完了すると、以下のようにコマンド出力の最後にBastionノードとGPUノードのホスト名とIPアドレスが出力されます。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Apply <span class="nb">complete</span><span class="o">!</span> Resources: 16 added, 0 changed, 0 destroyed.

Outputs:

Bastion_instances_created <span class="o">=</span> <span class="o">{</span>
  <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"bastion"</span>
  <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.1.138"</span>
  <span class="s2">"public_ip"</span> <span class="o">=</span> <span class="s2">"123.456.789.123"</span>
<span class="o">}</span>
Compute_in_cn_created <span class="o">=</span> <span class="o">{</span>
  <span class="s2">"inst-9fhuq-gpu4-ol89"</span> <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"inst-9fhuq-gpu4-ol89"</span>
    <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.2.10"</span>
  <span class="o">}</span>
  <span class="s2">"inst-dz99s-gpu4-ol89"</span> <span class="o">=</span> <span class="o">{</span>
    <span class="s2">"display_name"</span> <span class="o">=</span> <span class="s2">"inst-dz99s-gpu4-ol89"</span>
    <span class="s2">"private_ip"</span> <span class="o">=</span> <span class="s2">"10.0.2.73"</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<hr />
<h1 id="2-gpuクラスタ確認">2. GPUクラスタ確認</h1>

<h2 id="2-0-概要">2-0. 概要</h2>

<p>本章は、構築されたGPUクラスタ環境を確認します。</p>

<p>この際、作成されたGPUノードの全ホスト名を記載したホストリストファイルを使用し、BastionノードからGPUクラスタ内の全GPUノードにSSHでコマンドを発行、その環境を確認します。<br />
なおこのホストリストファイルは、Bastionノードと全GPUノードに <strong>/home/opc/hostlist.txt</strong> として存在します。</p>

<h2 id="2-1-bastionノードログイン">2-1. Bastionノードログイン</h2>

<p>Bastionノードは、パブリックサブネット接続の場合はGPUクラスタ構築完了時に表示されるパブリックIPアドレスに対してインターネット経由SSHログインし、プライベートサブネット接続の場合はGPUクラスタ構築完了時に表示されるプライベートIPアドレスに対して拠点間接続経由SSHログインしますが、これには構築時に指定したSSH公開鍵に対応する秘密鍵を使用して以下コマンドで行います。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ssh <span class="nt">-i</span> path_to_ssh_secret_key opc@123.456.789.123
</code></pre></div></div>

<h2 id="2-2-cloud-init完了確認">2-2. cloud-init完了確認</h2>

<p><strong><a href="/ocitutorials/hpc/#5-11-cloud-init">cloud-init</a></strong> は、GPUノードが起動してSSHログインできる状態であっても、その処理が継続している可能性があるため、以下コマンドをBastionノードのopcユーザで実行し、そのステータスが <strong>done</strong> となっていることで <strong>cloud-init</strong> の処理完了を確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>hname <span class="k">in</span> <span class="sb">`</span><span class="nb">cat</span> /home/opc/hostlist.txt<span class="sb">`</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="nv">$hname</span><span class="p">;</span> ssh  <span class="nt">-oStrictHostKeyChecking</span><span class="o">=</span>accept-new <span class="nv">$hname</span> <span class="s2">"sudo cloud-init status"</span><span class="p">;</span> <span class="k">done
</span>inst-xxxxx-gpu4-ol89
Warning: Permanently added <span class="s1">'inst-xxxxx-gpu4-ol89,10.0.2.117'</span> <span class="o">(</span>ECDSA<span class="o">)</span> to the list of known hosts.
status: <span class="k">done
</span>inst-yyyyy-gpu4-ol89
Warning: Permanently added <span class="s1">'inst-yyyyy-gpu4-ol89,10.0.2.17'</span> <span class="o">(</span>ECDSA<span class="o">)</span> to the list of known hosts.
status: <span class="k">done</span>
<span class="err">$</span>
</code></pre></div></div>

<p>ステータスが <strong>running</strong> の場合は、 <strong>cloud-init</strong> の処理が継続中のため、処理が完了するまで待ちます。</p>

<h2 id="2-3-gpuノードファイルシステム確認">2-3. GPUノードファイルシステム確認</h2>

<p>GPUノードは、以下のようにルートファイルシステムがデフォルトの50 GBから指定したサイズに拡張され、NVMe SSDローカルディスクが <strong>/mnt/localdisk</strong> にマウントされ、Bastionノードの <strong>/home</strong> が <strong>/home</strong> としてマウントされています。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>hname <span class="k">in</span> <span class="sb">`</span><span class="nb">cat</span> /home/opc/hostlist.txt<span class="sb">`</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="nv">$hname</span><span class="p">;</span> ssh <span class="nv">$hname</span> <span class="s2">"df -h / /mnt/localdisk /home"</span><span class="p">;</span> <span class="k">done
</span>inst-xxxxx-gpu4-ol89
Filesystem              Size  Used Avail Use% Mounted on
/dev/sda3               192G   23G  170G  12% /
/dev/mapper/nvme-lvol0   25T   34M   25T   1% /mnt/localdisk
bastion:/home            36G  9.1G   27G  26% /home
inst-yyyyy-gpu4-ol89
Filesystem              Size  Used Avail Use% Mounted on
/dev/sda3               192G   23G  170G  12% /
/dev/mapper/nvme-lvol0   25T   34M   25T   1% /mnt/localdisk
bastion:/home            36G  9.1G   27G  26% /home
<span class="err">$</span>
</code></pre></div></div>

<h2 id="2-4-gpuノードbios設定確認">2-4. GPUノードBIOS設定確認</h2>

<p>以下コマンドをBastionノードのopcユーザで実行し、GPUノードのBIOSで指定した <strong>NPS</strong> と <strong>SMT</strong> 設定が指定したとおりになっていることを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>hname <span class="k">in</span> <span class="sb">`</span><span class="nb">cat</span> /home/opc/hostlist.txt<span class="sb">`</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="nv">$hname</span><span class="p">;</span> ssh <span class="nv">$hname</span> <span class="s2">"lscpu | grep -i -e numa -e thread"</span><span class="p">;</span> <span class="k">done
</span>inst-xxxxx-gpu4-ol89
Thread<span class="o">(</span>s<span class="o">)</span> per core:  2
NUMA node<span class="o">(</span>s<span class="o">)</span>:        8
NUMA node0 CPU<span class="o">(</span>s<span class="o">)</span>:   0-7,64-71
NUMA node1 CPU<span class="o">(</span>s<span class="o">)</span>:   8-15,72-79
NUMA node2 CPU<span class="o">(</span>s<span class="o">)</span>:   16-23,80-87
NUMA node3 CPU<span class="o">(</span>s<span class="o">)</span>:   24-31,88-95
NUMA node4 CPU<span class="o">(</span>s<span class="o">)</span>:   32-39,96-103
NUMA node5 CPU<span class="o">(</span>s<span class="o">)</span>:   40-47,104-111
NUMA node6 CPU<span class="o">(</span>s<span class="o">)</span>:   48-55,112-119
NUMA node7 CPU<span class="o">(</span>s<span class="o">)</span>:   56-63,120-127
inst-yyyyy-gpu4-ol89
Thread<span class="o">(</span>s<span class="o">)</span> per core:  2
NUMA node<span class="o">(</span>s<span class="o">)</span>:        8
NUMA node0 CPU<span class="o">(</span>s<span class="o">)</span>:   0-7,64-71
NUMA node1 CPU<span class="o">(</span>s<span class="o">)</span>:   8-15,72-79
NUMA node2 CPU<span class="o">(</span>s<span class="o">)</span>:   16-23,80-87
NUMA node3 CPU<span class="o">(</span>s<span class="o">)</span>:   24-31,88-95
NUMA node4 CPU<span class="o">(</span>s<span class="o">)</span>:   32-39,96-103
NUMA node5 CPU<span class="o">(</span>s<span class="o">)</span>:   40-47,104-111
NUMA node6 CPU<span class="o">(</span>s<span class="o">)</span>:   48-55,112-119
NUMA node7 CPU<span class="o">(</span>s<span class="o">)</span>:   56-63,120-127
<span class="err">$</span>
</code></pre></div></div>

<h2 id="2-5-gpuノードクラスタネットワーク用ネットワークインターフェース設定確認">2-5. GPUノードクラスタ・ネットワーク用ネットワークインターフェース設定確認</h2>

<p>以下コマンドをBastionノードのopcユーザで実行し、GPUノードの <strong><a href="/ocitutorials/hpc/#5-1-クラスタネットワーク">クラスタ・ネットワーク</a></strong> 接続に使用する16個のネットワークインターフェースに正しくIPアドレスが設定されていることを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>hname <span class="k">in</span> <span class="sb">`</span><span class="nb">cat</span> /home/opc/hostlist.txt<span class="sb">`</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="nv">$hname</span><span class="p">;</span> ssh <span class="nv">$hname</span> <span class="s2">"ip a | grep -e eth0 -e rdma | grep inet"</span><span class="p">;</span> <span class="k">done
</span>inst-xxxxx-gpu4-ol89
    inet 10.0.2.117/24 brd 10.0.2.255 scope global dynamic eth0
    inet 10.224.0.117/12 brd 10.239.255.255 scope global noprefixroute rdma0
    inet 10.224.1.117/12 brd 10.239.255.255 scope global noprefixroute rdma1
    inet 10.224.2.117/12 brd 10.239.255.255 scope global noprefixroute rdma2
    inet 10.224.3.117/12 brd 10.239.255.255 scope global noprefixroute rdma3
    inet 10.224.4.117/12 brd 10.239.255.255 scope global noprefixroute rdma4
    inet 10.224.5.117/12 brd 10.239.255.255 scope global noprefixroute rdma5
    inet 10.224.6.117/12 brd 10.239.255.255 scope global noprefixroute rdma6
    inet 10.224.7.117/12 brd 10.239.255.255 scope global noprefixroute rdma7
    inet 10.224.8.117/12 brd 10.239.255.255 scope global noprefixroute rdma8
    inet 10.224.9.117/12 brd 10.239.255.255 scope global noprefixroute rdma9
    inet 10.224.10.117/12 brd 10.239.255.255 scope global noprefixroute rdma10
    inet 10.224.11.117/12 brd 10.239.255.255 scope global noprefixroute rdma11
    inet 10.224.12.117/12 brd 10.239.255.255 scope global noprefixroute rdma12
    inet 10.224.13.117/12 brd 10.239.255.255 scope global noprefixroute rdma13
    inet 10.224.14.117/12 brd 10.239.255.255 scope global noprefixroute rdma14
    inet 10.224.15.117/12 brd 10.239.255.255 scope global noprefixroute rdma15
inst-yyyyy-gpu4-ol89
    inet 10.0.2.17/24 brd 10.0.2.255 scope global dynamic eth0
    inet 10.224.0.17/12 brd 10.239.255.255 scope global noprefixroute rdma0
    inet 10.224.1.17/12 brd 10.239.255.255 scope global noprefixroute rdma1
    inet 10.224.2.17/12 brd 10.239.255.255 scope global noprefixroute rdma2
    inet 10.224.3.17/12 brd 10.239.255.255 scope global noprefixroute rdma3
    inet 10.224.4.17/12 brd 10.239.255.255 scope global noprefixroute rdma4
    inet 10.224.5.17/12 brd 10.239.255.255 scope global noprefixroute rdma5
    inet 10.224.6.17/12 brd 10.239.255.255 scope global noprefixroute rdma6
    inet 10.224.7.17/12 brd 10.239.255.255 scope global noprefixroute rdma7
    inet 10.224.8.17/12 brd 10.239.255.255 scope global noprefixroute rdma8
    inet 10.224.9.17/12 brd 10.239.255.255 scope global noprefixroute rdma9
    inet 10.224.10.17/12 brd 10.239.255.255 scope global noprefixroute rdma10
    inet 10.224.11.17/12 brd 10.239.255.255 scope global noprefixroute rdma11
    inet 10.224.12.17/12 brd 10.239.255.255 scope global noprefixroute rdma12
    inet 10.224.13.17/12 brd 10.239.255.255 scope global noprefixroute rdma13
    inet 10.224.14.17/12 brd 10.239.255.255 scope global noprefixroute rdma14
    inet 10.224.15.17/12 brd 10.239.255.255 scope global noprefixroute rdma15
<span class="err">$</span>
</code></pre></div></div>

<p>なお、後に実行する <strong>NCCL Tests</strong> の起動コマンドで設定している <strong>NCCL_IB_HCA</strong> 環境変数に指定のRDMAリンク名（ <strong>mlx5_xx</strong> ）は、以下のように先の <strong>クラスタ・ネットワーク</strong> 接続用のネットワークインターフェースに対応しています。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>hname <span class="k">in</span> <span class="sb">`</span><span class="nb">cat</span> /home/opc/hostlist.txt<span class="sb">`</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="nv">$hname</span><span class="p">;</span> ssh <span class="nv">$hname</span> <span class="s2">"rdma link show | grep rdma"</span><span class="p">;</span> <span class="k">done
</span>inst-xxxxx-gpu4-ol89
<span class="nb">link </span>mlx5_6/1 state ACTIVE physical_state LINK_UP netdev rdma0 
<span class="nb">link </span>mlx5_7/1 state ACTIVE physical_state LINK_UP netdev rdma1 
<span class="nb">link </span>mlx5_8/1 state ACTIVE physical_state LINK_UP netdev rdma2 
<span class="nb">link </span>mlx5_9/1 state ACTIVE physical_state LINK_UP netdev rdma3 
<span class="nb">link </span>mlx5_0/1 state ACTIVE physical_state LINK_UP netdev rdma4 
<span class="nb">link </span>mlx5_1/1 state ACTIVE physical_state LINK_UP netdev rdma5 
<span class="nb">link </span>mlx5_2/1 state ACTIVE physical_state LINK_UP netdev rdma6 
<span class="nb">link </span>mlx5_3/1 state ACTIVE physical_state LINK_UP netdev rdma7 
<span class="nb">link </span>mlx5_14/1 state ACTIVE physical_state LINK_UP netdev rdma8 
<span class="nb">link </span>mlx5_15/1 state ACTIVE physical_state LINK_UP netdev rdma9 
<span class="nb">link </span>mlx5_16/1 state ACTIVE physical_state LINK_UP netdev rdma10 
<span class="nb">link </span>mlx5_17/1 state ACTIVE physical_state LINK_UP netdev rdma11 
<span class="nb">link </span>mlx5_10/1 state ACTIVE physical_state LINK_UP netdev rdma12 
<span class="nb">link </span>mlx5_11/1 state ACTIVE physical_state LINK_UP netdev rdma13 
<span class="nb">link </span>mlx5_12/1 state ACTIVE physical_state LINK_UP netdev rdma14 
<span class="nb">link </span>mlx5_13/1 state ACTIVE physical_state LINK_UP netdev rdma15 
inst-yyyyy-gpu4-ol89
<span class="nb">link </span>mlx5_6/1 state ACTIVE physical_state LINK_UP netdev rdma0 
<span class="nb">link </span>mlx5_7/1 state ACTIVE physical_state LINK_UP netdev rdma1 
<span class="nb">link </span>mlx5_8/1 state ACTIVE physical_state LINK_UP netdev rdma2 
<span class="nb">link </span>mlx5_9/1 state ACTIVE physical_state LINK_UP netdev rdma3 
<span class="nb">link </span>mlx5_0/1 state ACTIVE physical_state LINK_UP netdev rdma4 
<span class="nb">link </span>mlx5_1/1 state ACTIVE physical_state LINK_UP netdev rdma5 
<span class="nb">link </span>mlx5_2/1 state ACTIVE physical_state LINK_UP netdev rdma6 
<span class="nb">link </span>mlx5_3/1 state ACTIVE physical_state LINK_UP netdev rdma7 
<span class="nb">link </span>mlx5_14/1 state ACTIVE physical_state LINK_UP netdev rdma8 
<span class="nb">link </span>mlx5_15/1 state ACTIVE physical_state LINK_UP netdev rdma9 
<span class="nb">link </span>mlx5_16/1 state ACTIVE physical_state LINK_UP netdev rdma10 
<span class="nb">link </span>mlx5_17/1 state ACTIVE physical_state LINK_UP netdev rdma11 
<span class="nb">link </span>mlx5_10/1 state ACTIVE physical_state LINK_UP netdev rdma12 
<span class="nb">link </span>mlx5_11/1 state ACTIVE physical_state LINK_UP netdev rdma13 
<span class="nb">link </span>mlx5_12/1 state ACTIVE physical_state LINK_UP netdev rdma14 
<span class="nb">link </span>mlx5_13/1 state ACTIVE physical_state LINK_UP netdev rdma15 
</code></pre></div></div>

<hr />
<h1 id="3-コンテナ環境構築">3. コンテナ環境構築</h1>

<p>本章は、 <strong>Docker Community Edition</strong> と <strong>NVIDIA Container Toolkit</strong> を使用し、GPU利用可能なコンテナ環境を構築します。</p>

<p>以下コマンドを全てのGPUノードのopcユーザで実行し、 <strong>Docker Community Edition</strong> と <strong><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/index.html">NVIDIA Container Toolkit</a></strong> をインストール・起動します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>yum-config-manager <span class="nt">--add-repo</span> https://download.docker.com/linux/centos/docker-ce.repo
<span class="nv">$ </span><span class="nb">sudo </span>dnf <span class="nb">install</span> <span class="nt">-y</span> docker-ce nvidia-container-toolkit
<span class="nv">$ </span><span class="nb">sudo </span>systemctl <span class="nb">enable</span> <span class="nt">--now</span> docker
</code></pre></div></div>

<p>次に、以下コマンドを全てのGPUノードのopcユーザで実行し、コンテナ上で <strong>BM.GPU4.8</strong> が搭載する8個のGPUにアクセスできることを確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>docker run <span class="nt">--rm</span> <span class="nt">--gpus</span> all nvcr.io/nvidia/base/ubuntu:22.04_20240212 nvidia-smi
Unable to find image <span class="s1">'nvcr.io/nvidia/base/ubuntu:22.04_20240212'</span> locally
22.04_20240212: Pulling from nvidia/base/ubuntu
d66d6a6a3687: Pull <span class="nb">complete 
</span>24c2d4f7ea40: Pull <span class="nb">complete 
</span>9d30336abbd7: Pull <span class="nb">complete 
</span>feb1277c15aa: Pull <span class="nb">complete 
</span>3cf0dbeda93a: Pull <span class="nb">complete 
</span>99fc1e9ef206: Pull <span class="nb">complete 
</span>a8f7f8dfd4e2: Pull <span class="nb">complete 
</span>Digest: sha256:2a9f71d82aa4daac444c1b4b74d5d7b01f93eb23662c1236f89d817f083abecd
Status: Downloaded newer image <span class="k">for </span>nvcr.io/nvidia/base/ubuntu:22.04_20240212
Mon Jul  1 02:58:34 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|<span class="o">=========================================</span>+<span class="o">========================</span>+<span class="o">======================</span>|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   38C    P0             81W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   37C    P0             85W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-40GB          On  |   00000000:51:00.0 Off |                    0 |
| N/A   34C    P0             81W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-40GB          On  |   00000000:54:00.0 Off |                    0 |
| N/A   36C    P0             82W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-40GB          On  |   00000000:8D:00.0 Off |                    0 |
| N/A   35C    P0             79W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-40GB          On  |   00000000:92:00.0 Off |                    0 |
| N/A   35C    P0             81W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-40GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   34C    P0             78W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-40GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   36C    P0             85W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|<span class="o">=========================================================================================</span>|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
<span class="err">$</span>
</code></pre></div></div>

<hr />
<h1 id="4-nccl-tests実行">4. NCCL Tests実行</h1>

<p>本章は、 <strong><a href="https://catalog.ngc.nvidia.com/">NGC Catalog</a></strong> から提供される <strong><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow">TensorFlow NGC Container</a></strong> を起動し、このコンテナに含まれる <strong>NCCL</strong> とコンテナ上でビルドする <strong>NCCL Tests</strong> を使用し、Dockerコンテナ上で <strong>NCCL</strong> のGPU間通信性能を <strong>NCCL Tests</strong> で検証します。</p>

<p>この <strong>NCCL Tests</strong> 実行方法は、 <strong><a href="/ocitutorials/hpc/#2-1-標準ベンチマーク実行方法">標準ベンチマーク実行方法</a></strong> の <strong><a href="/ocitutorials/hpc/benchmark/run-nccltests/">NCCL Tests実行方法</a></strong> を参照してください。</p>

<hr />
<h1 id="5-gpuクラスタ削除">5. GPUクラスタ削除</h1>

<h2 id="5-0-概要">5-0. 概要</h2>

<p>本章は、先に作成した <strong><a href="/ocitutorials/hpc/#5-3-スタック">スタック</a></strong> / <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトを使用し、GPUクラスタを削除します。<br />
この手順は、構築手法に <strong><a href="/ocitutorials/hpc/#5-2-リソースマネージャ">リソース・マネージャ</a></strong> を使用する方法を採用するか、 <strong>Terraform</strong> CLIを使用する方法を採用するかで異なり、以降では2つの異なる構築手法毎にその手順を解説します。</p>

<h2 id="5-1-リソースマネージャを使用する方法">5-1. リソース・マネージャを使用する方法</h2>

<p>以下 <strong>スタックの詳細</strong> 画面で、 <strong>破棄</strong> ボタンをクリックします。</p>

<p><img src="stack_page10.png" alt="画面ショット" /></p>

<p>次に、表示される以下 <strong>破棄</strong> サイドバーで、 <strong>破棄</strong> ボタンをクリックします。</p>

<p><img src="stack_page11.png" alt="画面ショット" /></p>

<p>次に、表示される以下 <strong>ジョブ詳細</strong> ウィンドウで、左上のステータスが <strong>受入れ済</strong> → <strong>進行中</strong> と遷移すれば、 <strong>スタック</strong> の破棄が実施されています。</p>

<p><img src="stack_page12.png" alt="画面ショット" /></p>

<p>表示される以下 <strong>ログ</strong> フィールドで、リソースの削除状況を確認します。</p>

<p><img src="stack_page09.png" alt="画面ショット" /></p>

<p>この破棄が完了するまでの所要時間は、GPUノードのノード数が2ノードの場合で5分程度です。</p>

<p>ステータスが <strong>成功</strong> となれば、GPUクラスタの削除が完了しています。</p>

<h2 id="5-2-terraform-cliの場合">5-2. Terraform CLIの場合</h2>

<p>本章は、 <strong><a href="/ocitutorials/hpc/#5-12-terraform">Terraform</a></strong> スクリプトを <strong>Terraform</strong> CLIで破棄し、GPUクラスタを削除します。</p>

<p><strong>Terraform</strong> 実行環境の <strong>tutorial_cn</strong> ディレクトリで以下コマンドを実行し、削除が正常に完了したことをメッセージから確認します。</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>terraform destroy <span class="nt">--auto-approve</span>
:
Destroy <span class="nb">complete</span><span class="o">!</span> Resources: 18 destroyed.
<span class="err">$</span>
</code></pre></div></div>

<p>この破棄が完了するまでの所要時間は、GPUノードのノード数が2ノードの場合で5分程度です。</p>

<p>これで、このチュートリアルは終了です。</p>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新日時:</strong> <time class="dt-published" datetime="2025-08-27T00:30:27+09:00">August 27, 2025</time></p>

      </footer>

      <section class="page__share">
  <h4 class="page__share-title">共有</h4>

  <a href="https://x.com/intent/tweet?text=GPU%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B%28%E5%9F%BA%E7%A4%8E%E3%82%A4%E3%83%B3%E3%83%95%E3%83%A9%E8%87%AA%E5%8B%95%E6%A7%8B%E7%AF%89%E7%B7%A8%29%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fspinup-gpu-cluster-withterraform%2F" class="btn btn--x" aria-label="Share on X" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 X">
    <i class="fab fa-fw fa-x-twitter" aria-hidden="true"></i><span> X</span>
  </a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fspinup-gpu-cluster-withterraform%2F" class="btn btn--facebook" aria-label="Share on Facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Facebook">
    <i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span>
  </a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://oracle-japan.github.io/ocitutorials/hpc/spinup-gpu-cluster-withterraform/" class="btn btn--linkedin" aria-label="Share on LinkedIn" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 LinkedIn">
    <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span>
  </a>

  <a href="https://bsky.app/intent/compose?text=GPU%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B%28%E5%9F%BA%E7%A4%8E%E3%82%A4%E3%83%B3%E3%83%95%E3%83%A9%E8%87%AA%E5%8B%95%E6%A7%8B%E7%AF%89%E7%B7%A8%29%20https%3A%2F%2Foracle-japan.github.io%2Focitutorials%2Fhpc%2Fspinup-gpu-cluster-withterraform%2F" class="btn btn--bluesky" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="共有 Bluesky">
    <i class="fab fa-fw fa-bluesky" aria-hidden="true"></i><span> Bluesky</span>
  </a>
</section>


      
  <nav class="pagination">
    
      <a href="/ocitutorials/hpc/spinup-gpu-cluster/" class="pagination--pager" title="GPUクラスタを構築する(基礎インフラ手動構築編)">前へ</a>
    
    
      <a href="/ocitutorials/hpc/spinup-gpu-cluster-withstack/" class="pagination--pager" title="GPUクラスタを構築する(スタティッククラスタ自動構築編)">次へ</a>
    
  </nav>


    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">関連記事</h2>
  <div class="grid__wrapper">
    
  </div>
</div>

  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="検索キーワードを入力してください..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>フォロー</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/#ocijp" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/oracle-japan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/ocitutorials/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>


<div class="page__footer-copyright">&copy; 2025 <a href="https://oracle-japan.github.io">Oracle Cloud Infrastructure チュートリアル</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ocitutorials/assets/js/main.min.js"></script>




<script src="/ocitutorials/assets/js/lunr/lunr.min.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-store.js"></script>
<script src="/ocitutorials/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6W7FEC5CEH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6W7FEC5CEH', { 'anonymize_ip': false});
</script>







  
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
  
    <script src="/ocitutorials/assets/js/clipboardrouge.js"></script>
  
    <script src="/ocitutorials/assets/js/tabs.js"></script>
  
    <script src="/ocitutorials/assets/js/sidebar.js"></script>
  


  </body>
</html>
